{"71758":{"abstract":"This collaborative project focuses on network-level solutions for exploiting the time-varying nature of the wireless environment to increase the overall performance of the system taking into account quality of service (QoS) and fairness for Multimedia Wireless Systems. The proposed algorithms are classified \"opportunistic\" since they consider channel conditions (and related definitions of per-user utility). The following research activities will be particularly pursued: opportunistic scheduling with and without explicit delay requirements as well as opportunistic scheduling in the frequency domain. The objective related to opportunistic scheduling without explicit delay requirements is to develop scheduling algorithms that exploit the time-varying nature of the wireless channel to optimize network performance under different fairness requirements. In particular, the channel estimation problem will be explored for which fast methodologies to effectively track the system parameters through stochastic approximation types of techniques will be developed. For opportunistic scheduling with explicit delay requirements, the goal will be to develop scheduling mechanisms for real-time applications such as voice and video where the objective is not only to schedule users based on their channel conditions and fairness constraints, but also based on their deadlines. In particular, the problems of opportunistic scheduling without individual QoS constraints and problems of opportunistic scheduling with individual QoS requirements will be studied. For that purpose, the off-line optimal scheduling solutions that provide benchmarks in evaluating other schemes will be developed. On the other hand, the on-line algorithms that take into account network traffic statistics will be developed and proven on practicability. Finally, the activities related to opportunistic scheduling in the frequency domain will consider taking advantage of both time-domain and frequency-domain diversity in wireless systems. In particular, the problems will be explored where the objective will be to maximize the system performance where power could be an explicit constraint or a penalty function. Other types of problems that will be explored here will deal with minimizing the transmitted power subject to performance constraints.","title":"Collaborative Research: Opportunistic Scheduling for Multimedia Wireless Systems","awardID":"0207728","effectiveDate":"2002-07-01","expirationDate":"2006-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"4097","name":"NETWORKING RESEARCH"}}],"PIcoPI":["548182"],"PO":["565090"]},"72517":{"abstract":"This proposal was received in response to the Nanoscale Science and Engineering Initiative, Program Solicitation NSF 01-157, in the NER category. The proposal focuses on the fabrication of nanoscale silicide quantum dots. Silicide dots are potentially useful for fabrication of quantum cellular automata and other quantum dot devices. Quantum cellular automata are assemblies of quantum dots which can perform the basic information-processing functions of interconnect, digital logic, and memory. A major motivation for the exploration of silicide quantum dots in particular is the fact that they will be compatible with silicon devices which will probably remain useful as an interface between nanoelectronics and the outside world. This research will explore novel nanoscale fabrication processes and will develop improved understanding of surface chemical reactions and phase transitions on the nanoscale. We wish to demonstrate the integration of in situ lithography, selective deposition of metals, silicide formation, and epitaxial layer overgrowth. In particular, lithography will be performed by exposing thin silicon dioxide layers with an electron beam, thereby enhancing thermal desorption of oxide from the exposed regions. Subsequently the quantum dots will be formed by chemical vapor deposition and reaction to form a metallic silicide. One particularly attractive approach is selective deposition of the silicide-forming metal from an organometallic source, although other approaches may also be explored. This research will be performed using a recently constructed apparatus which combines electron beam patterning with the deposition and characterization of quantum dots. All process steps, including epitaxial overgrowth of the quantum dots, can be performed without exposing the substrates to atmosphere. Characterization tools to be used in the work include reflection high energy electron diffraction, thermal desorption mass spectrometry, and atomic force microscopy. Within this one-year exploratory program, we expect to fabricate patterned silicide quantum dots in the 20-40 nm size range. We will also obtain improved scientific understanding of selective growth which will be broadly useful in the fabrication of nanoscale devices.","title":"NER: Silicide Quantum Dots for Nanoelectronics","awardID":"0210647","effectiveDate":"2002-07-15","expirationDate":"2003-12-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2878","name":"SPECIAL PROJECTS - CCF"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0701","name":"Division of ELECTRICAL, COMMUN & CYBER SYS","abbr":"ECCS"},"pgm":{"id":"1517","name":"ELECT, PHOTONICS, & MAG DEVICE"}}],"PIcoPI":["524886"],"PO":["219912"]},"70845":{"abstract":"EIA-0204316<br\/>Llewllyn, Donna C., Foley, James D., Hoey, J. Joseph, Moore, S. Gordon Jr., Usselman, Marion<br\/>Georgia Institute of Technology <br\/><br\/>Title: APSIT: Alternate Pathways to success in Information Technology<br\/><br\/>This ITWF award provides support for the Alternate Pathways to Success in Information Technology (APSIT) program which seeks to explore the nature of the IT and engineering educational and career pathways used by successful female and minority Georgia Tech alumni. The objectives of the project are:<br\/><br\/>1. To determine, through the use of paper and telephone surveys, face-to-face interviews, and institute records of Georgia Tech alumni, whether the educational and career strategies used by white women and by men and women from underrepresented ethnic groups differ from the strategies used by white men in their successful pursuit of IT and engineering degrees and careers. <br\/><br\/>2. To explore correlations between high school and college educational success (as measured by grade point average, and standardized test scores) with indices of later success in the IT and engineering work force, and to analyze these correlations by gender and ethnicity. <br\/><br\/>3. To explore IT and engineering field-specific differences in educational and career success for women and minorities.","title":"ITWF: APSIT: Alternate Pathways to Success in Information Technology","awardID":"0204316","effectiveDate":"2002-07-01","expirationDate":"2006-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1359","name":"RES EXP FOR TEACHERS(RET)-SITE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1713","name":"WORKFORCE"}}],"PIcoPI":[183382,"422915","526181",183385,183386],"PO":["564181"]},"70856":{"abstract":"ABSTRACT<br\/>0204355<br\/>Greg Turk<br\/>GA Tech Res Corp GIT<br\/><br\/>Methods of data capture such as range scanning, still photography, video and motion capture have begun to alter the manner in which computer graphics modelling, rendering and animation is performed. We propose to widen the applicability of captured data for model creation by develop-ing methods for re-use of geometry and images. We plan to pursue two related research directions. The first of these is to improve methods of performing texture synthesis. We plan to address a num-ber of the shortcomings of current texture synthesis methods, including the loss or mis-registration of fine features, the lack of variation in synthetic textures, the tuning of the parameters of the algo-rithms and the lack of user control. Two of the ideas that we plan to draw upon for this work are image metrics for human visual perception and the evaluation of the quality of synthesized images. Surprisingly little attention has been paid to these issues with regard to texture synthesis. Our second goal is the adaptation of texture synthesis methods to the creation of 3D geometry. Specifically, we plan to address the problems of creating height fields, displacement maps, and<br\/>arbitrary 3D volumetric geometry. There are many challenges to extending texture synthesis ideas<br\/>into 3D, so we plan to approach this increasingly difficult list of representations in a methodical<br\/>fashion. Of course, our work in texture synthesis will inform much of the geometry synthesis work.<br\/>Geometry re-use should allow a user to create synthetic terrain with the locations of mountains,<br\/>rivers and hills specified by the user. Natural erosion and other characteristic features will come not<br\/>from costly simulations, but from geometry synthesis from examples. Examples of terrain data are<br\/>easily found from the USGS, and other digital geometry can be captured through range scanning<br\/>and merging techniques.","title":"Geometry and Texture Synthesis","awardID":"0204355","effectiveDate":"2002-07-01","expirationDate":"2006-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2865","name":"NUMERIC, SYMBOLIC & GEO COMPUT"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7453","name":"GRAPHICS & VISUALIZATION"}}],"PIcoPI":["456660"],"PO":["532791"]},"70867":{"abstract":"ABSTRACT<br\/>0204388<br\/>Ming Gu<br\/>U of Calif - Berkeley<br\/><br\/>The San Andreas Fault zone Observatory at Depth (SAFOD) Pilot Hole will provide an<br\/>excellent opportunity for exploring the relationship between fault slip and the thermal evolution<br\/>of the crust by studying core samples from varying depths using two complementary<br\/>thermochronologic methods. The Pilot Hole, located in Parkfield less than two kilometers from<br\/>the San Andreas fault will reach a depth of 2.1 km. The borehole will intersect Salinian granitic<br\/>rocks at a depth of less than 1 km and similar granitic rocks outcrop at the surface within a few<br\/>kilometers of the Pilot Hole. We will analyze samples from borehole cuttings at depth intervals<br\/>of 100 - 200 m and from the surface outcrops. We will determine the thermal history of the<br\/>samples using apatite fission track and U\/Th-He thermochronometers.","title":"Fast Numerically Stable Matrix Algorithms","awardID":"0204388","effectiveDate":"2002-07-01","expirationDate":"2006-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2865","name":"NUMERIC, SYMBOLIC & GEO COMPUT"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0507","name":"Division of SCIENCE EDUCATION RESOURCES IM","abbr":"SER"},"pgm":{"id":"1264","name":"ALGEBRA,NUMBER THEORY,AND COM"}}],"PIcoPI":["550348"],"PO":["381214"]},"70835":{"abstract":"The research component of the proposal is to devise automatic macromodeling procedures that extract higher-level models from detailed lower-level ones for automated design of Systems-on-Chip. An important aspect of this process, particularly for analog, mixed-signal and RF modules, is the incorporation of nonlinearities. This is essential for distortion and intermodulation characteristics. <br\/><br\/>This work is concerned chiefly with modeling weak circuit nonlinearities. A significane increase in the predicted fidelity over current (essentially linear theory-based) procedures is expected. The proposed work is based on Volterra non-linear series expansion that captures essential non-linearities of a broad class of devices which include power amplifiers, mixers, frequency doublers, and switched-capacitor filters. The work is likely to be expandable to companding filters and Analog-to-Digital converters.","title":"CAD Algorithms for Automated Nonlinear Macromodelling","awardID":"0204278","effectiveDate":"2002-07-01","expirationDate":"2007-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4710","name":"DES AUTO FOR MICRO & NANO SYS"}}],"PIcoPI":["520671"],"PO":["562984"]},"70846":{"abstract":"Effective processes are of fundamental importance to manufacturing,<br\/>government, engineering, and management. In all of these areas greater<br\/>understanding and control of key processes can lead to improved<br\/>effectiveness. For the past 15 years, it has also been recognized that<br\/>processes are fundamental to software development, and that effective<br\/>control of processes can lead to similar benefits, such as improved<br\/>understanding, coordination, efficiency, and automation. It has been hoped<br\/>that this would lead to reductions in software development cost,<br\/>improvements in software product quality, and reductions in software<br\/>development time. Our hypothesis is that progress towards these goals can<br\/>be speeded by establishing a scientific basis upon which to build the<br\/>process technologies that will support more effective software production.<br\/>This research project will lead to the development of needed improvements<br\/>to the Little-JIL process definition language, and the Juliette<br\/>interpreter. These improvements will be validated by programming and<br\/>running multiuser, iterative software design processes that are effective<br\/>in integrating the activities of humans and computer automation. These<br\/>processes should be of considerable value in themselves. Their<br\/>development, moreover, will sharpen and validate the Little-JIL process<br\/>language, resulting in clearer understandings of the underlying<br\/>requirements for effective process definition languages.","title":"A Process Definition Language For Guiding Multiuser Design","awardID":"0204321","effectiveDate":"2002-07-15","expirationDate":"2004-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2880","name":"SOFTWARE ENGINEERING AND LANGU"}}],"PIcoPI":["536737"],"PO":["564388"]},"70857":{"abstract":"As intrinsic leakage in transistor increases with technology scaling the effectiveness of quiescent current (IDDQ) testing reduces significantly. Transient current (IDD) based testing has been often cited and investigated as an alternative and\/or supplement to IDDQ testing in Digital CMOS circuits. While the potential of IDD testing for fault detection has been established for digital and analog circuits, there is no known efficient method for fault diagnosis using IDD analysis. We propose a novel integrated method for fault detection and diagnosis in digital CMOS circuits using IDD waveform analysis using wavelet transform. We use wavelet transform to decompose the IDD waveform in both time and frequency domain. The time-frequency resolution of the IDD signal helps us detect as well as localize faults. Initial experimental results on an 8-bit ALU show that wavelet based IDD analysis has the potential to efficiently detect and localize faults considering practical issues like effect of process variation and measurement noise. <br\/><br\/>Transient current (IDD) analysis can also be effective for defect oriented testing of analog circuits. We observe that wavelet transform renders an efficient way for analyzing IDD for fault detection in analog circuits. The property of wavelet for resolving events in both time and frequency domain simultaneously and the property of better sub-banding than Fourier analysis, makes it a effective tool for IDD analysis. Moreover wavelet transform can be easily adapted to current waveforms from different circuits. We have observed that for equivalent number of spectral components, sensitivity of wavelet based fault detection in analog circuits is much higher than fourier or time-domain analysis for both catastrophic and parametric faults. Initial experimental results on a benchmark circuit show that wavelet based method is on average 25 times more sensitive than DFT for parametric faults and can be considered as a promising alternative for analog fault detection amidst measurement hardware noise and process variation. In the proposed research we will develop an integrated fault detection and diagnosis methodology using wavelet based transient current analysis for mixed-signal circuits.<br\/><br\/>We will present the results of our research in domestic and international conferences. International conferences include (International Conference on CAD and CG in Macau, December 2003, and International Conference on CAD and CG 2005; IEEE Design and Test in Europe).","title":"Fault Detection and Diagnosis for Mixed-Signal Circuits Using Wavelet Based Transient Current Analysis","awardID":"0204356","effectiveDate":"2002-07-01","expirationDate":"2008-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4710","name":"DES AUTO FOR MICRO & NANO SYS"}}],"PIcoPI":["551012"],"PO":["562984"]},"70868":{"abstract":"ABSTRACT<br\/>0204389<br\/>Zena Ariola<br\/>U of Oregon Eugene<br\/><br\/>The general objective of this proposal is to gain a more robust understanding of the semantics and<br\/>logical foundations of programming languages. The activities will be based on the close correspon-dence<br\/>between syntactic theories for realistic programming languages and sequent calculi for logic.<br\/>This correspondence is a generalization of the Curry-Howard isomorphism that relates the simply<br\/>typed calculus and intuitionistic natural-deduction logic, and is at the heart of many automated<br\/>proof systems for reasoning about programs. The specific objectives and their potential impact are:<br\/><br\/>Algorithms and Tools: Our experience has shown that the proposed study of syntactic the-ories<br\/>and associated logics is tedious and error-prone: it requires many mundane but fun-damental<br\/>tasks to be repeatedly performed. Such tasks include verifying that the syntactic heory is well-formed, that evaluation is a well-defined partial function, and that subject re-duction holds. On the logical side, these properties are related to the consistency of the logic and the soundness of the proof simplication rules. Hence, to enable the study of non-trivial syntactic theories and logics, previous work by the investigators included the design and im-plementation of algorithms and theorem-proving techniques suitable for the automation of<br\/>the manipulation of syntactic theories. This effort has led to a prototype system (SL) for lightweight description and reasoning about syntactic theories. This proposal includes ac-tivities to extend and refine the current prototype and to make it available to all interested researchers and students.","title":"Syntactic Theories: Their Automation and Logical Foundation","awardID":"0204389","effectiveDate":"2002-07-15","expirationDate":"2006-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2880","name":"SOFTWARE ENGINEERING AND LANGU"}}],"PIcoPI":["517796","489107"],"PO":["564388"]},"73729":{"abstract":"EIA-0215887<br\/>Pai, Dinesh<br\/>DeCarlo, Douglas M.<br\/>Mataxas, Dimitris N.<br\/>Nguyen, Thu D.<br\/>Rutgers University - New Brunswick <br\/><br\/>MRI: Multisensory Human Interaction Measurement and Synthesis for Computer Graphics and Interactive Virtual Environments <br\/><br\/>This proposal, measuring multisensory human interaction with everyday objects and with other humans, develops an integrated facility in which it will be possible to acquire synchronized measurements of visual, auditory, and haptic behavior with low latency. The work includes measuring motion at up to 250Hz using a marker-based motion capture system, acquiring dense range images, recording speech and contact sounds, and measuring forces and pressure distributions due to human contact. The facility will make a broad range of research activity possible. Multisensory models of objects will be developed; it will then be possible not only to see images of a virtual object, but to feel its stiffness and surface texture using a force feedback haptic device, and to hear its sound when hit. Multisensory models of human conversational behavior will be developed by tracking lip and arm movements at the same time as recording voice. \"Interaction capture\" will extend motion capture, the current state of the art for realistic computer animation. Hence, it will be possible to not only transfer and transform the motion of an animated character, but also the forces and sounds produced when the character interacts with the world. Moreover, the computing infrastructure needed to support interaction will be investigated. Multisensory interaction imposes new constraints on system behavior, particularly latency, and could lead to new designs of computer operating systems and communication networks. The instrumentation will enable more students to be educated about multisensory simulation and interaction, and to use multisensory environments in new ways to stimulate learning and discovery. Funds are requested for<br\/>1. Sensor systems for interaction and measurement,<br\/>2. Acoustical environment of experiment,<br\/>3. Audiovisual displays, and<br\/>4. Computing.","title":"MRI: Multisensory Human Interaction Measurement and Synthesis for Computer Graphics and Interactive Virtual Environments","awardID":"0215887","effectiveDate":"2002-07-01","expirationDate":"2005-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1189","name":"MAJOR RESEARCH INSTRUMENTATION"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2890","name":"CISE RESEARCH RESOURCES"}}],"PIcoPI":["486839","355043","455506","522465"],"PO":["557609"]},"71804":{"abstract":"Aloysius K. Mok<br\/>CCR-0207853 <br\/>\"REAL-TIME VIRTUAL RESOURCES\"<br\/><br\/>As embedded systems become more complex, a typical embedded system<br\/>will probably involve a mix of soft and hard real-time applications<br\/>that share the same embedded run-time platform. In general, an<br\/>application may consist of one or more tasks. For example, on a<br\/>hand-held sensor-computer, a user may want to fix his own location<br\/>with respect to a target landmark and also be warned of the power<br\/>consumption status of the sensor-computer. While the power consumption<br\/>warning task may have very loose timing constraints, the location<br\/>fixing task has fairly stringent timing and other QOS (quality of<br\/>service) requirements. Ideally, an application developer should be<br\/>able to write his application program as if it were running on a<br\/>dedicated computer and not have to worry about interference from<br\/>other applications. This illusion can be maintained if global<br\/>knowledge of the QOS requirements of all the applications is<br\/>accessible to the operating system scheduler, so that a global<br\/>schedulability analysis can be performed to ensure that every task<br\/>meets its QOS requirements. However, this is not possible in the<br\/>environment of \"open systems\" where the operating system may not<br\/>know about the timing requirements of all the application tasks,<br\/>as is the case with most commercial embedded and real-time kernels.<br\/><br\/>A simplistic solution is to assign a higher priority to timing-<br\/>critical applications and let the non-real-time applications run<br\/>only when the timing-critical ones are finished. This approach is<br\/>viable only for the simplest embedded systems where there is only<br\/>one real-time task and there is no interaction among the real-time<br\/>and the non-real-time tasks. If all the applications are to various<br\/>degrees timing-critical (hard or soft), then the distinction between<br\/>real-time and non-real-time applications becomes blurry. In the<br\/>sensor-computer example, if the power consumption warning task is<br\/>assigned a low priority because of its laxer timing constraint, then<br\/>it is possible that power may run out while the high-priority location<br\/>fixing task is monopolizing the CPU. This may in turn cause a sensor<br\/>reset that may affect the validity of the location fixing result.<br\/><br\/>The goal of this project is to enable the design of robust embedded<br\/>real-time systems that must function in an open systems environment.<br\/>The innovation we are investigating is an elegant software abstraction<br\/>called RTVR (real-time virtual resource). This abstraction allows<br\/>application programmers to design embedded real-time systems as if<br\/>each application had exclusive access to a set of dedicated physical<br\/>resources which provide service at a roughly constant rate. The key<br\/>to the RTVR concept is that of a \"delay bound\" parameter on the rate<br\/>of service provision. The delay bound specification enables a<br\/>programmer to specify the jitter allowance of his\/her application.<br\/>As a result, we can simplify the verification of the timing correctness<br\/>of individual applications as if there is no timing interference<br\/>among application tasks. The RTVT concept also simplifies the issue<br\/>of guaranteeing the timing\/QOS requirements of a mixture of hard<br\/>and soft real-time applications. To realize this abstraction, we<br\/>must make major advances in both theory and engineering in operating<br\/>system design and real-time scheduling theory. Of particular interest<br\/>to this project are the issues of partition composition and the<br\/>hierarchical decomposition of multiple real-time virtual resources.","title":"Real-Time Virtual Resources","awardID":"0207853","effectiveDate":"2002-07-01","expirationDate":"2005-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2801","name":"EMBEDDED & HYBRID SYSTEMS(EHS)"}}],"PIcoPI":["527002"],"PO":["561889"]},"70858":{"abstract":"Applications of Data Grouping for Effective Mobility<br\/>Darrell D. E. Long<br\/><br\/>The problem of reducing a mobile computer's communication and power<br\/>requirements will be investigated. Specifically, this research will address<br\/>both issues through improved storage management. Based on successes with<br\/>automated data grouping and predictive power conservation, research will be<br\/>conducted into improved data hoarding and disk power management techniques.<br\/>Effective grouping of data will make it possible to improve the automation<br\/>of mobile file hoarding, and decrease the effects of network latency and<br\/>disconnections on the mobile user. Similarly, through the grouping and<br\/>retrieval of related on-disk data, it is possible to improve disk power<br\/>management beyond the theoretical limits of any previously attempted scheme.<br\/>This will be done by actively modifying the access sequence to minimize<br\/>power requirements. Through transformation of data access workloads, this<br\/>novel approach reshapes disk idle times to effectively increase the amount<br\/>of time a disk can be spun down. Improving the battery life of mobile<br\/>computing devices is critical to their usefulness, and such power efficiency<br\/>is clearly an environmentally responsible goal. This research will establish<br\/>the effectiveness of on-line data grouping techniques to increase the amount<br\/>of data accessed per operation, while simultaneously reducing the total<br\/>number of disk operations.","title":"Applications of Data Grouping for Effective Mobility","awardID":"0204358","effectiveDate":"2002-07-01","expirationDate":"2008-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2876","name":"DISTRIBUTED SYSTEMS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["540846"],"PO":["560587"]},"70759":{"abstract":"Scalable Distributed Real-Time Simulation of<br\/> Embedded Systems and Environments<br\/><br\/> Kane Kim<br\/> University of California -Irvine<br\/> 0204050<br\/><br\/><br\/> Major improvements in the validation technology for embedded systems are under increasing demands from industry. Not only description but also simulation of non-computer parts and application environments of embedded systems is needed in validating many embedded system software designs and implementations. Here the desired types of simulators are real-time (RT) simulators which exhibit the timing behavior that are the same as or sufficiently close to the timing behavior of the simulation targets. Such simulators can enable highly cost-effective testing of the embedded system software and such testing can be a lot cheaper that the testing performed in actual application environments while being much more effective than the testing based on non-RT simulators of environments.<br\/><br\/> In this research, the joint university-industry research team intends to establish the scientific foundation for the DTS scheme in a sound form, thereby realizing fundamental advances in the state of the art in RT simulation. Development of support middleware and other tool prototypes is planned. Successful accomplishment of these will mean that the validation technology for embedded systems will be advanced in fundamental ways. Case studies for evaluating the improvements in simulation performance and validation effectiveness realized by use of the DTS scheme in practical contexts will be conducted with the assistance of industry partners. Advanced instrumentation and performance measurement technologies and graphic interface technologies developed by international collaborations partners will also be incorporated and integrated with the DTS scheme. More specifically, the proposing team intends to establish:<br\/>(1) Scientific foundation for DTS, including that related to consistency among distributed simulator nodes and maximization of concurrency, (2) Middleware and application programming interfaces that support DTS and simulator programming, (3) A methodology for validation of RT object-structured distributed software for embedded systems, which is centered around the use of RT simulators of the non-computer parts and environments and additionally uses performance measurement and graphic visualization tools, and (4) Case studies involving an RT simulation of immune buildings designed to protect inhabitants against bio-weapon attacks and that of miliary command-control environments.","title":"Next Generation Software: Scalable Real-Time Simulation of Embedded Systems and Environments","awardID":"0204050","effectiveDate":"2002-07-15","expirationDate":"2006-06-30","fundingAgent":[{"dir":{"id":"04","name":"Directorate for DIRECT FOR SOCIAL, BEHAV & ECONOMIC SCIE","abbr":"SBE"},"div":{"id":"0406","name":"Office of INTL SCIENCE & ENGINEERING","abbr":"OISE"},"pgm":{"id":"5978","name":"EAST ASIA AND PACIFIC PROGRAM"}},{"dir":{"id":"04","name":"Directorate for DIRECT FOR SOCIAL, BEHAV & ECONOMIC SCIE","abbr":"SBE"},"div":{"id":"0406","name":"Office of INTL SCIENCE & ENGINEERING","abbr":"OISE"},"pgm":{"id":"5980","name":"WESTERN EUROPE PROGRAM"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2884","name":"NEXT GENERATION SOFTWARE PROGR"}}],"PIcoPI":["217949","296371","534923"],"PO":["301532"]},"70815":{"abstract":"ABSTRACT<br\/>0204193<br\/>Kreitz, Christoph<br\/>Cornell U <br\/><br\/>Interactively guided proof assistants have been successfully used in the formal design, verification,<br\/>and optimization of software and hardware systems. Because of their expressive logics, they are<br\/>more generally applicable than fully automated tools, yet at a much lesser degree of automation.<br\/>The main goal of this project is to combine the expressive power of proof assistants with the<br\/>automatic reasoning capabilities of proof search procedures, proof planners, decision procedures,<br\/>model checkers, etc. and to use the enhanced system in the formal design of reliable software.<br\/>In particular we aim at providing proof automation for the Nuprl proof development system,<br\/>a tactical proof environment that has been used in numerous applications. It offers a proven basis<br\/>for solving mathematical problems and for designing reliable hardware and software systems. The<br\/>newest release of Nuprl features one of the most exible architectures for interacting with external<br\/>problem solving devices. Our experience with connecting Nuprl with JProver, a theorem prover<br\/>for first-order intuitionistic logic, has shown that Nuprl supports interoperability between formalsystems in a way that makes our goal feasible.","title":"Proof Automation in Constructive Type Theory","awardID":"0204193","effectiveDate":"2002-07-01","expirationDate":"2006-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2865","name":"NUMERIC, SYMBOLIC & GEO COMPUT"}}],"PIcoPI":[183304],"PO":["321058"]},"70859":{"abstract":"ABSTRACT<br\/>0204362<br\/>Beeson, Michael<br\/>San Jose State Univ Fdn<br\/><br\/>This award will enhance the theorem-prover Otter to cope better with second-order logic. It will use this enhanced version of Otter to formalize a small amount of elementary number theory, a small amount of set theory, and theorems about the cardinality of finite sets, as required to proceed to theorems in group theory as usually presented in an undergraduate course in algebra, up to and perhaps (but not necessarily) including the Sylow theorems. It will also enhance Otter by adding a capability for polynomial simplification, which in turn will enable it to proceed further in number theory. Although first-order group theory has been a source of many test problems for automated deduction, the material in an undergraduate course typically begins with theorems about subgroups and homomorphisms, and uses the concept of a prime number, so second-order logic (or set theory) and induction are essential ingredients to even sophomore-level mathematics. It is high time that theorem-provers be made able to cope with these fundamental areas of mathematics, which are naturally multi-sorted (elements, numbers, functions, and sets) and second-order (elements, cosets, subgroups).<br\/><br\/><br\/>The long-term aim of automated deduction is to make the computer useful as a \"mathematician's assistant\". The goal is that the computer could check proofs, filling in any missing details, and verify their correctness. Perhaps the computer could carry out some of the simpler parts of the mathematics mechanically. Maybe (in the distant future) the computer might even prove interesting new theorems on a regular basis. At present computers can be used for some kinds of calculations, but their use for helping with proofs is in its infancy, in spite of half a century of research. Part of the problem is the richness of mathematical language; part of the problem is the complicated relationship between calculations and proofs; and part of the problem is the \"needle-in-the-haystack\" difficulty of finding a proof or disproof of an unsolved conjecture. Otter is a theorem-proving program developed at Argonne National Laboratories. This research will provide some enhancements to Otter that should help it deal with the \"richness of language\" problem and the \"calculations within proofs\" problem. To test the effectiveness of our efforts, the PI will try to \"computerize\" some theorems in mathematics that are usually taught in the sophomore or junior year to mathematics majors. These are theorems in an area of mathematics called \"group theory\", which usually comes after calculus and is widely used in many branches of mathematics and physics. Many of the theorems found in the first course in this subject have so far resisted attempts to get computers to prove them.","title":"Second-order Automated Deduction","awardID":"0204362","effectiveDate":"2002-07-01","expirationDate":"2006-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2865","name":"NUMERIC, SYMBOLIC & GEO COMPUT"}}],"PIcoPI":[183415],"PO":["565272"]},"71817":{"abstract":"This collaborative project focuses on network-level solutions for exploiting the time-varying nature of the wireless environment to increase the overall performance of the system taking into account quality of service (QoS) and fairness for Multimedia Wireless Systems. The proposed algorithms are classified \"opportunistic\" since they consider channel conditions (and related definitions of per-user utility). The following research activities will be particularly pursued: opportunistic scheduling with and without explicit delay requirements as well as opportunistic scheduling in the frequency domain. The objective related to opportunistic scheduling without explicit delay requirements is to develop scheduling algorithms that exploit the time-varying nature of the wireless channel to optimize network performance under different fairness requirements. In particular, the channel estimation problem will be explored for which fast methodologies to effectively track the system parameters through stochastic approximation types of techniques will be developed. For opportunistic scheduling with explicit delay requirements, the goal will be to develop scheduling mechanisms for real-time applications such as voice and video where the objective is not only to schedule users based on their channel conditions and fairness constraints, but also based on their deadlines. In particular, the problems of opportunistic scheduling without individual QoS constraints and problems of opportunistic scheduling with individual QoS requirements will be studied. For that purpose, the off-line optimal scheduling solutions that provide benchmarks in evaluating other schemes will be developed. On the other hand, the on-line algorithms that take into account network traffic statistics will be developed and proven on practicability. Finally, the activities related to opportunistic scheduling in the frequency domain will consider taking advantage of both time-domain and frequency-domain diversity in wireless systems. In particular, the problems will be explored where the objective will be to maximize the system performance where power could be an explicit constraint or a penalty function. Other types of problems that will be explored here will deal with minimizing the transmitted power subject to performance constraints.","title":"Collaborative Research: Opportunistic Scheduling for Multimedia Wireless Systems","awardID":"0207892","effectiveDate":"2002-07-01","expirationDate":"2006-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"4097","name":"NETWORKING RESEARCH"}}],"PIcoPI":["487976"],"PO":["565090"]},"70739":{"abstract":"ABSTRACT<br\/>Adamchik, Victor<br\/>0204003<br\/>Carnegie Mellon U<br\/><br\/>Great progress has been made in recent years in the construction of software for numeric and symbolic computation of transcendental functions. The algorithms have been implemented in the most widely used symbolic algebra systems such as Maple and Mathemat-ica. Recently, the National Institute of Standards and Technology started a project of creating the Digital Library of Mathematical Functions (http:\/\/dlmf.nist.gov\/). The goal of the project is to collect all recent scientific results regarding theory and computational algorithms of the well-known special functions and make them available to the public in electronic form. How-ever, enormous gaps remain for \"new\" transcendental functions. One of such functions is the multiple gamma (also called Barnes) Gn-function. The Gn function, defined by a recurrence-functional<br\/>equation as a generalization of the Euler gamma function, was originally intro-duced (but in different forms) by Kinkelin, Glaisher, and Barnes around 1900. Today, due to the pioneer work of Peter Sarnak of Princeton University, the interest to the Barnes function is revived. Sarnak has been pushing the idea that zeros of certain \"zeta functions\" (L-functions) can be understood in terms of the distribution of eigenvalues from classes of random matrices. It has been conjectured that the limiting distribution of the non-trivial zeros of the Riemann zeta function is the same as that of the eigenphases of matrices in the CUE (the circulat uni-tary<br\/>ensemble) It has been shown in works by Mehta, Sarnak, Conrey, Keating, Snaith that the Barnes function naturally appeares there as a closed representation for statistical averages over CUE of N x N unitary matrices (as well as some other classical compact groups), when","title":"Algorithms for the Multiple Gamma and Related Functions","awardID":"0204003","effectiveDate":"2002-07-01","expirationDate":"2006-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2865","name":"NUMERIC, SYMBOLIC & GEO COMPUT"}}],"PIcoPI":[183122],"PO":["321058"]},"70806":{"abstract":"ABSTRACT<br\/>0204174<br\/>Marian Neamtu<br\/>Verderbilt University<br\/><br\/>The final properties of polymer products are largely determined by process conditions such a low rate, shape of processing die and cooling temperature, which are represented as condition parameters in mathematical models. In this sense, modeling viscoelastic fluid behavior provides a fundamental explanation of the structure of polymer products such as fibers and films. Advances in the finite element computational methodologies for simulating the fiber and film process is a recent development in polymer industries.<br\/>The goal of this work is to introduce mathematical optimization techniques into the nu-merical simulation of viscoelastic fluid, in order to determine optimal process conditions for polymer products. Two research projects are involved in the proposal: film casting and a vorticity minimization problem. The overall strategy will be to integrate recently developed viscoelastic models and optimization techniques in order to meet objectives through various control mechanisms such as shape control and boundary control. As an equation solver for the film casting problem, the commercial software package Poly ow, which simulates film and fiber processing in various settings, will be used. For the other problem, a finite element code<br\/>currently under development will be used. In solving the optimization problems, recent results<br\/>from current research will be extended to the more general and high dimensional viscoelastic<br\/>regime.","title":"Bivariate Splines for Geometric Modeling","awardID":"0204174","effectiveDate":"2002-07-01","expirationDate":"2006-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2865","name":"NUMERIC, SYMBOLIC & GEO COMPUT"}}],"PIcoPI":["420797"],"PO":["321058"]},"71709":{"abstract":"Wang, Xiaodong<br\/>Columbia University<br\/><br\/>Objectives and Significance: The turbo principle [27 ],namely,the strategy that exploits the iterated<br\/>exchange of soft information between di .erent blocks in a communication receiver,has grown to be a powerful<br\/>tool in attacking a diverse set of problems in communications.In particular,the turbo multiuser detection<br\/>(MUD)paradigm [59 ]has attracted signi .cant recent attention as an e .ective technique for joint decoding<br\/>in multiuser communication systems.However to date the performance of various turbo MUD schemes<br\/>is largely demonstrated via simulations,and the impact of turbo MUD on the network performance (e.g.,<br\/>throughput and delay)has not been explored systematically.It also remains unclear at this time how the<br\/>upper-layer functionalities (such as ARQ protocol,power control,and admission control)should be designed<br\/>to exploit the physical-layer turbo MUD.The objective of the proposed project is to develop analytical tools to<br\/>assess and optimize the performance of various turbo MUD methods,and to apply these esults to c oss-layer<br\/>design in wireless networks.<br\/>Recently a technique known as density evolution [66,67 ]has been developed in the coding community that<br\/>permits analysis of iterative decoding algorithm for in .nite-length codewords.In this proposal,under the<br\/>density evolution framework,we outline a research plan aimed at understanding of the design and analysis of<br\/>turbo multiuser detection for a variety of channel conditions and receiver structures,and the design of some<br\/>upper-layer functionalities which takes into account the physical layer turbo MUD.While in this study we<br\/>focus on multiuser CDMA systems,the general principle is applicable to several systems,such as space-time<br\/>coding systems,OFDM systems,and intersymbol interference systems.","title":"Turbo Multiuser Detection: Analysis, Optimization and Applications","awardID":"0207550","effectiveDate":"2002-07-15","expirationDate":"2006-12-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4720","name":"SIGNAL PROCESSING SYS PROGRAM"}}],"PIcoPI":["475040"],"PO":["564898"]},"76170":{"abstract":"Ahmed H. Tewfik<br\/>University of Minnesota-Twin Cities<br\/><br\/>The 2002 International Conference On Multimedia & Expo (ICME) is the third IEEE multimedia conference to take place in joint collaboration with four IEEE societies: the Circuits and Systems Society, the Computer Society, the Signal Processing Society, and the Communications Society. This year, the conference will take place in Lausanne, Switzerland, from August 26 to August 29. ICME serves as a forum for the dissemination of state-of-the-art IEEE as well as non-IEEE research, development, and implementations of multimedia systems, technologies and applications. It brings together researchers, developers and practitioners from<br\/>academia and industry working in all areas in multimedia. It is arguably the most inter-disciplinary of all IEEE conferences. Furthermore, it provides industry an opportunity to showcase products. Typical topics covered by ICME include signal processing for media integration, components and technologies for multimedia systems, human-machine interface and interaction, multimedia databases and file systems, multimedia<br\/>communication and networking, system integration, applications, standards (e.g., MPEG) and related issues.","title":"Funding for Graduate Student Travel to ICME, August 26 - 29, 2002","awardID":"0227561","effectiveDate":"2002-07-01","expirationDate":"2002-12-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4720","name":"SIGNAL PROCESSING SYS PROGRAM"}}],"PIcoPI":["515560"],"PO":["564898"]},"67360":{"abstract":"This is a Faculty Early Career Development (CAREER) award. The research component will employ eye tracking and other means to infer the cognitive processes of people engaged in particular tasks, and will develop a computational framework, called mind-tracking architecture, for mapping observed actions to the unobserved thoughts that produce them. This work will draw upon existing psychology and engineering research and synthesize these efforts into a unified methodology. The project will employ two frameworks at different levels to achieve mind tracking: the production-system architecture ACT-R and cognitive grammars that represent behavior as rules from intentions to actions. Three specific application areas will motivate, demonstrate, and test the methodology: intelligent tutoring, automobile driver assistance, and assistive technology for the disabled. The educational component will develop a new human-computer interaction curriculum and an outreach program to foster communication among students, researchers and industry professionals.<br\/><br\/>This CAREER award recognizes and supports the early career-development activities of a teacher-scholar who is likely to become an academic leader of the twenty-first century. Each of the three application areas has the potential for significant benefit to members of the general public: students, drivers, and the disabled.","title":"CAREER: A Computational Architecture for Tracking Cognitive Processes","awardID":"0133083","effectiveDate":"2002-07-01","expirationDate":"2007-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6845","name":"HUMAN COMPUTER INTER PROGRAM"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6846","name":"UNIVERSAL ACCESS"}}],"PIcoPI":["444122"],"PO":["565227"]},"68186":{"abstract":"We propose running a five day conference in July 2002 on the use of symbolic computation in algebra, geometry, and analysis, preceded by a two day workshop for graduate students and non-specialists. This will be a joint U.S. and Canadian event and will take place at the University of Western Ontario, London, Ontario, Canada. We request funds from the NSF to provide travel and support costs for participants from the U.S.<br\/>The conference is intended to bring together researchers from a broad variety of areas within symbolic computation. The topics included will be computational algebra (both commutative and non-commutative) and algebraic geometry, solving polynomial equations, differential algebra, coding theory and geometric invariant theory.<br\/>The conference will consist of approximately 10 one hour talks and 20 half hour talks. The one hour talks will be designed for an audience of nonspecialists, in particular, for students and researchers wishing to learn about the area. The shorter talks will be designed to discuss current developments in the field. In addition, the PIs plan to hold a two-day workshop before the start of the conference featuring coding theory and geometric invariant theory. The workshop will be aimed at graduate students and non-specialists.<br\/>The conference is modeled in its scope, program and organization after the AMS-IMS-SIAM joint summer research conference Symbolic Computation: Solving Equations in Algebra, Geometry, and Engineering that was held at Mount Holyoke College in June 2000 and organized by the PIs. The Mount Holyoke meeting in turn was inspired by the special semester on Symbolic Computation in Algebra, Geometry and Analysis that was held at MSRI in the Fall of 1998. The proposed conference will serve as a platform to present the most exciting results obtained since the summer of 2000.<br\/>We already have approved funding from the Fields Institute, Ontario Research Center for Computational Algebra (ORCCA), and the University of Western Ontario. The organizers plan to make a special effort to attract graduate students and recent Ph.Ds, as well as women working in the areas within the scope of the conference. A substantial portion of the requested funds would be used for support of graduate students and recent PH.Ds from the U.S.","title":"Symbolic Computational Algebra 2002 Conference","awardID":"0136990","effectiveDate":"2002-07-01","expirationDate":"2003-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2865","name":"NUMERIC, SYMBOLIC & GEO COMPUT"}}],"PIcoPI":[176513,"500891","564098","260375"],"PO":["201974"]},"67395":{"abstract":"Two key developments in networking are that the Internet is (1) increasingly used for the streaming of continuous media, a large portion of which is prerecorded, and (2) increasingly accessed by wireless (and possibly mobile) clients. The stringent Quality of Service requirements of continuous media, such as video, combined with the unreliability of wireless links make the real-time streaming over wireless links a very challenging problem. To address the trend towards wireless streaming, the researcher proposes to develop a comprehensive theory and a framework of practical protocols and mechanisms for the real-time streaming of prerecorded continuous media to wireless clients. To overcome the challenges of real-time streaming of continuous media over wireless links the proposed protocols and mechanisms will rely on the following key insights:<br\/><br\/>1. For prerecorded continuous media (i) the exact traffic characteristics are known before the streaming commences, and (ii) while the stream is being played out, segments of the stream can be prefetched into a prefetch buffer in the client.<br\/>2. Channel probing techniques can identify the wireless links with good transmission conditions in the face of location-dependent, time-varying, and bursty wireless link errors.<br\/>3. Rate adaptation techniques of modern wireless systems (e.g., third and fourth generation wireless systems) allow to dynamically allocate transmission capacities to the individual ongoing flows.<br\/><br\/>The novel idea of the streaming protocols is to overcome the variability of the wireless links by prefetching segments of the continuous media stream into the client buffer. The prefetching is done by dynamically allocating transmission capacities to the ongoing streams according to (1) the prefetch buffer contents in the clients, and (2) the wireless link conditions (determined through channel probing). Through prefetching (i.e.,work-ahead) prefetched reserves are built up in the clients that allow the clients to continue playback during adverse transmission conditions on the wireless links. The preliminary simulation results for prefetching using a Join-the-Shortest-Queue (JSQ) policy in conjunction with a simple channel probing scheme indicate that prefetching brings dramatic performance improvements.<br\/><br\/>The researcher proposes to develop a comprehensive framework for the real-time streaming of continuous media to wireless clients. The specific objectives of the proposed project are to develop:<br\/><br\/>1. optimal prefetching mechanisms for a single wireless cell, e.g., mechanisms that for given client buffers minimize the client starvation probability while maximizing the number of supported streams. The researcher will analyze the fundamental trade-offs in prefetching over wireless links and develop call admission rules.<br\/>2. prefetching mechanisms for scalable encoded media that enable heterogeneous multimedia streaming services.<br\/>3. seamless end-to-end streaming mechanism, for the real-time delivery of continuous media over networks consisting of wired and wireless links to mobile clients.<br\/><br\/>In the preliminary work for the proposed project, the researcher has developed a prefetching protocol for the real-time streaming of continuous media between the base station and multiple wireless clients in a wireless cell.<br\/><br\/>The proposed research is closely integrated with two educational initiatives. These are (1) outreach and extended education, and (2) the development of a wireless multimedia streaming testbed based on a 802.11 wireless LAN. The goals of the outreach and extended education initiative are to attract traditionally underrepresented minorities to engineering, and to provide high-quality networking instruction to underrepresented students, e.g., working adults. This will be achieved by (i) developing on-line networking labs for K-12 students and teachers in the Arizona MESA and the NSF funded WISE programs, (ii) enhancing the networking courses in ASU's Extended Education program with web-based teaching aids, and (iii) integrating networking courses into the exclusively web-based tri-university Master of Engineering program in Arizona. The streaming testbed will serve as a platform for integrating research, industrial collaborations, and students' education. Protocols for wireless QoS, such as the proposed prefetch protocol will be implemented in undergraduate (senior) design projects to complement and deepen the classroom knowledge.","title":"CAREER: Streaming Prerecorded Continuous Media in Wireless Environments","awardID":"0133252","effectiveDate":"2002-07-15","expirationDate":"2008-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"4095","name":"SPECIAL PROJECTS IN NET RESEAR"}}],"PIcoPI":["455149"],"PO":["565090"]},"79033":{"abstract":"Award #0139398<br\/>Tarokh, Vahid<br\/><br\/>Dr. Vahid Tarokh, a recognized leader in the research field of wireless communications, will receive the National Science Foundation's (NSF) Alan T. Warterman award for his work as the primary inventor of \"space time coding\", a new technique that significantly improves the speed and reliability of wireless data transmission.<br\/><br\/>These innovations helped form international standards for the latest cell phones, personal digital assistants and other wireless devices. By some estimates, more than one billion handsets might be employing the space-time codes within five years.","title":"Alan T. Waterman Award","awardID":"0240625","effectiveDate":"2002-07-01","expirationDate":"2004-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4720","name":"SIGNAL PROCESSING SYS PROGRAM"}},{"dir":{"id":"14","name":"Office of OFFICE OF POLAR PROGRAMS                ","abbr":"OPP"},"div":{"id":"1400","name":"Division of A\/D FUND","abbr":"A\/D"},"pgm":{"id":"9170","name":"NSF PLANNING & EVALUATION"}}],"PIcoPI":["347677"],"PO":["564898"]},"69144":{"abstract":"The investigator has discovered that, for extremely large input<br\/> sizes, modern factorization algorithms such as the number-field sieve<br\/> can be carried out with far less memory per processor than was<br\/> previously believed. Consequently, for extremely large values of d,<br\/> the number-field sieve can factor 3d-digit numbers at the same cost<br\/> that was previously believed to be required for d-digit numbers. The<br\/> investigator is studying the practical effectiveness of this<br\/> discovery for small input sizes, such as 1024 bits and 1536 bits. The<br\/> investigator is also continuing his research into the fundamental<br\/> computational tools in commutative rings of Krull dimension 1.<br\/><br\/> The number-field sieve is the best known attack on many public-key<br\/> cryptosystems used to protect the secrecy and authenticity of<br\/> Internet communications. Understanding the power of this algorithm is<br\/> essential in choosing safe key sizes for the cryptosystems. If, for<br\/> example, criminals can factor integers as large as 1024 bits, then<br\/> users must choose key sizes larger than 1024 bits.<br\/><br\/> This award is being cofunded by the Algebra, Number Theory, and <br\/> Combinatorics Program and the Numeric, Symbolic, and Geometric<br\/> Computation Program.","title":"Algorithmic Problems in Number Theory","awardID":"0140542","effectiveDate":"2002-07-01","expirationDate":"2007-06-30","fundingAgent":[{"dir":{"id":"03","name":"Directorate for DIRECT FOR MATHEMATICAL & PHYSICAL SCIEN","abbr":"MPS"},"div":{"id":"0304","name":"Division of MATHEMATICAL SCIENCES","abbr":"DMS"},"pgm":{"id":"1264","name":"ALGEBRA,NUMBER THEORY,AND COM"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2865","name":"NUMERIC, SYMBOLIC & GEO COMPUT"}}],"PIcoPI":["548359"],"PO":["565286"]},"68088":{"abstract":"The investigator and his colleagues organize the third<br\/>Conference on Foundations of Computational Mathematics at the<br\/>Institute for Mathematics and its Applications (IMA), University<br\/>of Minnesota on 5-14 August 2002. Deepening the understanding of<br\/>the mathematical processes that underlie fast computation and<br\/>computer simulation is the principal goal of the meeting. The<br\/>mathematical content covers fields of research at the interface<br\/>of engineering, computer science, and pure mathematics, but<br\/>focused on computation. The program includes 18 3-day workshops<br\/>and 18 plenary speakers. The plenary talks and workshops span<br\/>subjects of vital interest to the nation's infrastructure,<br\/>economy, and defense. The project supports participation by<br\/>postdocs, graduate students, junior participants, women and<br\/>minorities as well as plenary and semi-plenary speakers and<br\/>workshop organizers.<br\/> Large-scale computation and the implementation of<br\/>mathematical models for complex physical and societal phenomena<br\/>are of fundamental importance to the nation's economy.<br\/>Computation is also the backbone of the sciences supporting the<br\/>nation's defense. Large-scale computation is the engine of<br\/>numerical models for complex physical phenomena occurring at many<br\/>scales. Fast computation and processing of the ever-increasing<br\/>data sets obtained from various sensors is critical to the new<br\/>military. The purpose of this major meeting, held only every<br\/>three years, is to further the understanding of the deep<br\/>relationships between mathematical theory: analysis, topology,<br\/>geometry and algebra, and computational processes as they are<br\/>evolving in tandem with the modern computer. The topics to be<br\/>addressed include large scale computation and high performance<br\/>computing as occurs in atmospheric and groundwater modeling,<br\/>computer aided design and animation, data, image and signal<br\/>processing, modeling network traffic, quantum computing, learning<br\/>theory, optimization and control. Sustaining the nation's<br\/>advantage in these vital areas relies on understanding the<br\/>foundations of computational science. The meeting involves<br\/>350-500 researchers in 18 workshops over a 10-day period, with<br\/>special plenary sessions attended by everyone. A large contingent<br\/>of graduate students and other young scientists are<br\/>participating, and the program is designed to promote intensive<br\/>interaction among the participants. Several panels are devoted to<br\/>identifying the most promising directions for future research.<br\/>Published proceedings, web-based materials, and the conference<br\/>sessions themselves serve as launching pads for focus and special<br\/>interest groups for future interactions in a range of subjects at<br\/>the interface of mathematics and computation.","title":"Foundations of Computational Mathematics Conference, August 5 - 14, 2002","awardID":"0136607","effectiveDate":"2002-07-01","expirationDate":"2003-06-30","fundingAgent":[{"dir":{"id":"03","name":"Directorate for DIRECT FOR MATHEMATICAL & PHYSICAL SCIEN","abbr":"MPS"},"div":{"id":"0304","name":"Division of MATHEMATICAL SCIENCES","abbr":"DMS"},"pgm":{"id":"1268","name":"FOUNDATIONS"}},{"dir":{"id":"03","name":"Directorate for DIRECT FOR MATHEMATICAL & PHYSICAL SCIEN","abbr":"MPS"},"div":{"id":"0304","name":"Division of MATHEMATICAL SCIENCES","abbr":"DMS"},"pgm":{"id":"1271","name":"COMPUTATIONAL MATHEMATICS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"2860","name":"THEORY OF COMPUTING"}}],"PIcoPI":["482233","506278"],"PO":["562372"]},"71190":{"abstract":"One of the difficulties facing computer security systems is getting users and administrators to adopt them. The project studies a new approach to deploying security services called Deployment-Oriented<br\/>Security. The first question is how to deploy security services in a viral-like fashion. The idea is that once a small set of users adopt a security system, they gradually get their friends to adopt the<br\/>system and as a result the service propagates through the population. The project studies how this meme-like strategy applies to various security services such as secure e-mail, anonymity mechanisms,<br\/>electronic voting, secure file systems, e-cash, etc. Another approach to promoting the deployment of security systems is to deploy the required infrastructure on the fly. For example, can one deploy an<br\/>anonymizing server or a fair-exchange service on the fly to enable that service? How does one identify trusted hosts to deploy the service and how does one revoke corrupt or misbehaving hosts? The<br\/>third topic studied in this project is how to deploy protection mechanisms in environments where information is being shared. The project will use new cryptographic tools to develop efficient key <br\/>management techniques for broadcast data.","title":"ITR: Deployment-Oriented Security and Content Protection","awardID":"0205733","effectiveDate":"2002-07-15","expirationDate":"2007-12-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1687","name":"ITR MEDIUM (GROUP) GRANTS"}}],"PIcoPI":["521488","382002","553884"],"PO":["521752"]},"72092":{"abstract":"Frazzoli - Branicky Abstract<br\/><br\/>This project is aimed at the development of new tools and techniques for the design and analysis of high-confidence software for complex, distributed, reconfigurable aerospace embedded systems, and to transfer these methods to undergraduate and graduate students, other researchers, and industry. <br\/>Problems of direct interest include those arising in the control and coordination of multiple autonomous air and space vehicles, and in the detection and resolution of conflicts in Air Traffic Control. The techniques developed in this project are also applicable to other systems which require similar levels of reliability and performance, such as highway traffic automation systems, health care systems, power networks, and<br\/>financial services.<br\/><br\/>The primary goal of this project is a better understanding of the interactions between real-time software and dynamical systems. This will lead to new and powerful tools and techniques for the design and analysis of embedded systems, as well as an improved approach to the requirement specification for real-time systems.<br\/>The core of the research is aimed at dramatically reducing the complexity of embedded and hybrid systems design and verification by exploiting the geometric structure of the underlying physical system in the modelling effort, and by preserving this structure in the design of control laws and algorithms. This will make feasible the analysis of the complete system (including its physical and software components) by otherwise poorly scalable techniques such as abstract interpretation and model checking, and will provide<br\/>the means for the effective use of techniques based on compositional reasoning. For example, group symmetries in vehicle dynamics give rise to families of equivalent controlled trajectories: such sets are called motion primitives for single vehicles, and motion coordination primitives for groups of vehicles. A maneuver automaton is a collection of a finite number of motion primitives. It provides a discrete model of the vehicle dynamics, which leads to a dramatic reduction of the complexity of describing and controlling the vehicle behavior, by providing a high level of abstraction, and at the same time providing invariants which ensure that the physical state remains within some known bounds.<br\/><br\/>The educational part of the project is implemented through new course and curriculum development, and student mentoring. The main educational objective is to provide both undergraduate and graduate students with the knowledge and the skills to understand the key issues and to ensure technical leadership in the current and future aerospace information technology arenas. Finally, an interactive web site is being developed, where it is possible to access information and software developed in the research project and for the courses.","title":"Collaborative Research: Geometric and Algorithmic Techniques for Design and Verification of Hybrid Control Systems","awardID":"0208891","effectiveDate":"2002-07-15","expirationDate":"2006-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2801","name":"EMBEDDED & HYBRID SYSTEMS(EHS)"}}],"PIcoPI":["553248","553248","526913","526913"],"PO":["561889"]},"68287":{"abstract":"0137347\/Julien<br\/><br\/>The main aims of this proposal are to develop a better understanding of mixing during the active phase of deep open-ocean convection and to obtain parameterizations of temperature and salinity changes occurring during convection. Its physical novelty is that it includes the study of physical processes not previously examined in detail, including: (a) vortical interactions between plumes and (b) slant-wise convection. The study will use ambitious numerical simulations to examine the dynamics of turbulent ensembles of convective plumes and will include the effect of the horizontal component of the Earth's rotation vector. Simulations will use both the full Boussinesq equations as well as less stiff, asymptotically reduced sets of dynamical equations developed by the PIs. The information on the lateral stirring and penetration of strong convective events in the upper ocean that will be developed in this project will be used to improve parameterizations of open-ocean convection in large-scale ocean models of the sort used to study global ocean circulation and climate.","title":"Collaborative Research: Rotationally Constrained Convection","awardID":"0137347","effectiveDate":"2002-07-01","expirationDate":"2005-10-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0503","name":"Division of SHARED CYBERINFRASTRUCTURE","abbr":"SCI"},"pgm":{"id":"1271","name":"COMPUTATIONAL MATHEMATICS"}},{"dir":{"id":"06","name":"Directorate for DIRECTORATE FOR GEOSCIENCES             ","abbr":"GEO"},"div":{"id":"0604","name":"Division of OCEAN SCIENCES","abbr":"OCE"},"pgm":{"id":"1610","name":"PHYSICAL OCEANOGRAPHY"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0703","name":"Division of CIVIL, MECHANICAL, & MANUFACT","abbr":"CMMI"},"pgm":{"id":"1266","name":"APPLIED MATHEMATICS"}}],"PIcoPI":["551086"],"PO":["563981"]},"67077":{"abstract":"EIA-0131824<br\/>Gary J. Marchionini<br\/>Stephanie Haas<br\/>University of North Carolina Chapel Hill<br\/><br\/>Digital Government: Collaborative Research: Integration of Data and Interfaces to Enhance Human Understanding of Government Statistics - Toward the National Statistical Knowledge Network<br\/><br\/>This award will support collaborative research with several Federal statistical agencies to develop better statistical data models, to explore the use of SML, to develop better map-querying tools and to integrate other available tools for manipulating, browsing and visualizing tabular data. The goal is to develop better human\/computer interfaces for expert users to novices, to increase general statistical literacy, and to provide seamless access to data held by multiple Federal agencies and agencies at other levels of government, in particular state and local data.","title":"Digital Govt. Collaborative Research: Integration of Data and Interfaces to Enhance Human Understanding of Government Statistics: Toward the National Statistical Knowledge Network","awardID":"0131824","effectiveDate":"2002-07-01","expirationDate":"2006-06-30","fundingAgent":[{"dir":{"id":"04","name":"Directorate for DIRECT FOR SOCIAL, BEHAV & ECONOMIC SCIE","abbr":"SBE"},"div":{"id":"0403","name":"Division of SCIENCE RESOURCES","abbr":"NCSE"},"pgm":{"id":"8806","name":"INFO & TECHNOLOGY SVCES PRGM"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1706","name":"DIGITAL GOVERNMENT"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"V840","name":"SSA-DIGITAL GOVT RES PROG"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"V950","name":"SSA-DIGITAL GOVT RES"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0506","name":"Division of EXPERIMENTAL & INTEG ACTIVIT","abbr":"EIA"},"pgm":{"id":"V341","name":"ENERGY-SURVEY METHODOLOGY PROG"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0506","name":"Division of EXPERIMENTAL & INTEG ACTIVIT","abbr":"EIA"},"pgm":{"id":"V342","name":"SSA-DIGITAL GOVT RESEARCH PROG"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0506","name":"Division of EXPERIMENTAL & INTEG ACTIVIT","abbr":"EIA"},"pgm":{"id":"W191","name":"ENERGY-DIGITAL GOVT PROGRAM"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0506","name":"Division of EXPERIMENTAL & INTEG ACTIVIT","abbr":"EIA"},"pgm":{"id":"W460","name":"AGRIC-DIGITAL GOVT PROGRAM"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0506","name":"Division of EXPERIMENTAL & INTEG ACTIVIT","abbr":"EIA"},"pgm":{"id":"W466","name":"SSA-DIGITAL GOVT RES PROGRAM"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0506","name":"Division of EXPERIMENTAL & INTEG ACTIVIT","abbr":"EIA"},"pgm":{"id":"W549","name":"ENERGY-DIGITAL GOVT PROGRAM"}}],"PIcoPI":["531548",173907],"PO":["371077"]},"72170":{"abstract":"This project will investigate bidding strategies using agents which can buy goods and services from multiple auctions while satisfying user preferences and budgetary constraints. Of particular interest is the study and development of bundle bidding strategies, which will allow agents to put together preferred bundles of goods for users from online auctions selling only individual items. Automated bundle bidding procedures with well-understood performance expectations will allow users to form bundles with significantly less effort and much more success. The bundle bidding problem presents challenging and interesting research problems that involve asynchronous events, uncertainty about future auctions, and the widely varying valuations and bidding strategies of users and their proxies. Several variations of the bundle-bidding problem will be identified and studied. The project will also investigate the usage of auctions in conjunction with other forms of information processing within a broader context of coordination between self-interested autonomous agents representing individuals, organizations and supply chains.","title":"Agent-based bidding in electronic auctions","awardID":"0209208","effectiveDate":"2002-07-01","expirationDate":"2007-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6850","name":"DIGITAL SOCIETY&TECHNOLOGIES"}}],"PIcoPI":["362927"],"PO":["564456"]},"72060":{"abstract":"Handheld computing devices with wireless network connections<br\/> have a great potential to be powerful mobile tools to<br\/> access information and software resources in the networked<br\/> world. Unfortunately, the computing power<br\/> and connection time of current handheld devices<br\/> are severely constrained by the short battery life.<br\/> Moreover, the battery issue also places constraints on<br\/> various design aspects including program memory and secondary<br\/> storage, CPU, and operating system.<br\/> <br\/> With connection to computing servers through wireless networks,<br\/> there exist many opportunities for handheld devices to<br\/> save battery by carefully utilizing the power of the servers.<br\/> This project explores compiler and run-time techniques<br\/> to assist the partitioning of application programs into<br\/> server tasks and client tasks. The optimal partition<br\/> depends on available network bandwidth and on the nature<br\/> of applications. In order for handheld devices to optimally<br\/> exploit servers for a wide range of applications, careful<br\/> tradeoff is made between energy consumed by network communication<br\/> versus computation.<br\/> <br\/> The proposed compiler techniques and run-time support<br\/> include compile-time and run-time analysis of work and<br\/> communication requirement, exploitation<br\/> of low-power networking states on handhelds, run-time<br\/> decision-making, and a light-weight software coherence mechanism.","title":"Compiler Schemes for Server-assisted Energy-efficient Mobile Computing on Handheld Devices","awardID":"0208760","effectiveDate":"2002-07-01","expirationDate":"2006-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2876","name":"DISTRIBUTED SYSTEMS"}}],"PIcoPI":["408878"],"PO":["565272"]},"71092":{"abstract":"This research involves the discovery and development of scalable algorithms for solving hard computational problems that routinely arise in engineering. In particular, the investigators observe that man-made artifacts have innate structures that make those artifacts tractable for design, synthesis, and verification independent of their absolute size. Artifacts such as the Internet, integrated circuit chips, and large distributed software systems, continue to increase in size at a breath-taking pace. Algorithms that deal with such artifacts (e.g., searching the Internet, synthesizing integrated circuits, or verifying the correctness of software systems) but which are oblivious to their inherent structure and regularity are unable to cope with their ever-increasing complexity. Scalable algorithms, on the other hand, recognize, and take advantage of, the structure and regularity of the objects they manipulate in order to bring computational complexity down. The study and development of scalable algorithms, thus, is essential for maintaining progress in our fast-changing technological world.<br\/>Despite the fact that many of the computational tasks employed in designing, synthesizing, and verifying human-engineered objects are worst-case NP-hard, such objects continue to increase in complexity and are routinely made and deployed. Well-known examples range from aircraft crew scheduling to microprocessor verification and the routing of field-programmable gate arrays, yet the sheer complexity of problem instances often defies modern solution methods. Reuse of intellectual property does not always imply reductions of computational problem instances to smaller ones, and even when such reductions are applied they may lead to sub-optimality's. The ability to solve large instances of hard problems is critical to the design of leading-edge computer hardware, and instance size will increase rapidly with advances in silicon lithography (EUV, X-ray, electron beam, etc.), nano-manufacturing (molecular electronics) and integration complexity (system-on-a-chip). Therefore, empirical improvements in solving mainstream NP-complete problems are critical to sustained increase in sophistication of Information Technologies. This project aims at significantly extending the performance envelope of practical algorithms in order to handle very large hard problem instances through intelligent utilization of problem structure. The investigators are pursuing this goal through generic and fundamental results with applicability beyond currently popular worst-case bounds that are at variance with empirically observed performance.","title":"ITR: Scalable Algorithms Enabled by Problem Structure and Applications to Computer Hardware","awardID":"0205288","effectiveDate":"2002-07-15","expirationDate":"2008-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1687","name":"ITR MEDIUM (GROUP) GRANTS"}}],"PIcoPI":["370281","549712","508348"],"PO":["474792"]},"72082":{"abstract":"This research is about using the \"provable-security approach\" in the design and analysis of high-level cryptographic protocols. The aim is to gain assurance for practical cryptographic schemes by finding the right definitions, and then using modern techniques (reductions and their concrete-security analysis) to analyze selected schemes. <br\/><br\/>Specific problems to be investigated include: (1) Storing a user's private information on an untrusted server. Here one wants to store user data in such a way that the user can recover it by presenting a password, but an adversary must invest an amount of interaction proportional to the guessing-complexity of the password. (2) The authenticated-encryption scheme in SSH. Though the method used by SSH is not, in general, correct, the situation for SSH itself is far from clear. (3) Delegation of authority to a secondary signature key by a primary one. A well-known approach in security practice, the problem that this solution aims to solve is without any provable-security treatment. (4) Relating the \"prescriptive\" approach to formalizing authenticated key exchange and the simulation-based approach. (5) Moving to an enriched model of computation, an envelope model, to investigate authenticated key exchange. (6) A systematic investigation of the \"game walking\" approach to analyzing cryptographic scenarios. Here two adversarial views are compared by writing out a sequence of pseudocode \"games\" each of which may set some Boolean flag. One bounds the difference in adversarial views by bounding the probability that the flag gets set.","title":"Practice-Oriented Provable Security for Higher-Layer Protocols: Models, Analyses and Solutions","awardID":"0208842","effectiveDate":"2002-07-15","expirationDate":"2007-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2802","name":"TRUSTED COMPUTING"}}],"PIcoPI":["548342"],"PO":["543507"]},"67550":{"abstract":"CCR-0133991<br\/>CAREER: Automatic Generation of Software Configuration Management Repositories<br\/>Emmet James Whitehead<br\/><br\/>Twenty-five years of research and development on Configuration Management<br\/>(CM) systems has bequeathed a rich legacy of data models, system<br\/>architectures, and implementation approaches. This existing knowledge about<br\/>CM systems is analyzed to distill out the key lessons, and then leveraged<br\/>for advanced research on CM. The research advances the maturity of CM<br\/>knowledge by performing a comprehensive domain analysis of CM systems, and<br\/>by developing specification languages and technology to permit automatic<br\/>generation of CM repositories.<br\/><br\/>A domain model permits the characterization of an existing CM system as a<br\/>point in a multidimensional design tradeoff space. This research describes<br\/>key design spaces in sufficient detail to permit the specification of a<br\/>single point in design tradeoff space. This specification can be fed to a<br\/>generator that automatically generates a matching CM system. Research<br\/>challenges include the creation of a repository specification language; a<br\/>language for creating detailed CM system specifications that identify<br\/>specific design choices, and resolve design tradeoffs; and the development<br\/>of generator technology that automatically creates source code to implement<br\/>a given repository specification. This auto-generation technology provides a<br\/>valuable tool for exploring advanced data models for CM systems.","title":"CAREER: Automatic Generation of Software Configuration Management Repositories","awardID":"0133991","effectiveDate":"2002-07-01","expirationDate":"2007-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2880","name":"SOFTWARE ENGINEERING AND LANGU"}}],"PIcoPI":["443290"],"PO":["564388"]},"77021":{"abstract":"This project focuses on the physical layer of digital communication<br\/>system design - in particular on the design of graph-based error<br\/>control coding techniques for noisy, fading channels, such as those<br\/>encountered in wireless communication systems. The research<br\/>addresses those issues that have made practical implementation of<br\/>graph-based coding techniques problematic. Those issues include:<br\/><br\/>The development of LDPC and turbo codes with algebraic structure,<br\/>suitable for high speed implementation.<br\/>The development of LDPC and turbo codes with moderate block length,<br\/>suitable for practical real-time applications.<br\/>The design of bandwidth efficient coded modulation schemes<br\/>incorporating these new code constructions in order to \"fatten the<br\/>bit pipe\" in high data rate applications.<br\/>The adaptation of these new coding schemes for use in the fading<br\/>environment that characterizes wireless channels.","title":"ITR: Collaborative Research: Towards Practical Graph -Based Coding Schemes for Realiable Wireless Communications","awardID":"0231099","effectiveDate":"2002-07-15","expirationDate":"2007-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1687","name":"ITR MEDIUM (GROUP) GRANTS"}}],"PIcoPI":[200875],"PO":["348215"]},"72160":{"abstract":"Project Summary<br\/><br\/><br\/><br\/>The objective of the proposed activity is the development of <br\/>a high-assurance function, called a classloader. This function <br\/>carries out the static aspects associated with the execution <br\/>of Java classfiles as it is defined by a concrete implementation <br\/>of the Java Virtual Machine (JVM). The implementation <br\/>being targeted is called the Sandia Secure Processor (SSP). To <br\/>date, a prototype of the SSP has been developed in VHDL which <br\/>synthesized to < 40K gates and is capable of operating near 75MHz.<br\/><br\/>The goal is to compose the classloader and the SSP to produce a <br\/>Java-centric computational component capable of being used in <br\/>embedded system development. Intended application areas for this <br\/>technology encompass high to ultra-high consequence embedded systems.<br\/><br\/>A primary application domain for which this technology is targeted <br\/>has imposed the following constraints on the system:<br\/><br\/> 1.There must be the option of building the processor <br\/> using rad-hard technology.<br\/><br\/> 2.An open source for the system must be available allowing <br\/> detailed design analysis and testing of all aspects of <br\/> the system (possibly down to the gate level).<br\/><br\/> 3.Certification evidence should be provided by formal <br\/> mathematical proofs of correctness to the extent possible, <br\/> and strongly convincing evidence must be provided in all <br\/> other cases where mathematical proofs have not been achieved.<br\/><br\/> 4.A security policy must be strictly enforced ensuring that <br\/> any program is either rejected as incorrect by compile-time <br\/> or run-time checks, or its behavior must be understandable by <br\/> reasoning based entirely on the language semantics, independent <br\/> of the implementation. In particular, no security violation must <br\/> be permitted to succeed regardless whether it is the result <br\/> of an inadvertent error, or a malevolent well thought out attack.<br\/><br\/><br\/>Correctness-preserving program transformation is the method that is being <br\/>employed to implement a high-assurance classloader function. In this approach, <br\/>the functionality of the classloader is realized via a lengthy sequence of <br\/>small \"intellectually manageable\" rewrite steps. Here, a rewrite step is <br\/>considered to be intellectually manageable if its correctness can be formally <br\/>verified in practice. In order to achieve this goal, novel transformation <br\/>techniques are being explored and developed.<br\/><br\/>This project will significantly impact the computer science community <br\/>by (1) advancing knowledge in the area of program transformation, <br\/>(2) demonstrating to industry that formal methods (in this case program <br\/>transformation) can be effectively applied to real-world problems, and <br\/>(3) providing a computational infrastructure (i.e., the SSP) that is <br\/>suitable for embedded high-consequence system development.","title":"A Computational Infrastructure for Embedded High Consequence System Development","awardID":"0209187","effectiveDate":"2002-07-01","expirationDate":"2004-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2801","name":"EMBEDDED & HYBRID SYSTEMS(EHS)"}},{"dir":{"id":"11","name":"Directorate for DIRECT FOR EDUCATION AND HUMAN RESOURCES","abbr":"EHR"},"div":{"id":"1108","name":"Division of EXPER PROG TO STIM COMP RSCH","abbr":"EPS"},"pgm":{"id":"9150","name":"EXP PROG TO STIM COMP RES"}}],"PIcoPI":["218438"],"PO":["561889"]},"72061":{"abstract":"Space-Time Coding for Optical MIMO ChannelsStephen G. Wilson and Maite Brandt-PearceDept. of Electrical and Computer EngineeringUniversity of Virginia, Charlottesville, VA 22906Phone: (434) 924-6091, (sgw,mb-p)@virginia.eduAbstract:<br\/><br\/>Free-space optical links are an emerging technology for wideband access to networks because of the tremendous bandwidth potential they offer. Outdoor atmospheric channels are hampered by signal fading effects due to particulate scattering in a line-of-sight path, clear-air turbulence, or merely static index-of-refraction inhomogeneities. Similarly, indoor IR systems are faced with fading arising from the intrinsic multipath environment. One powerful method of improving the performance of wireless communication systems is through the use of transmit and receive antennas, creating a so-called multiple-input\/multiple-output (MIMO) channel. MIMO channel models, provided by transmit and receive antenna arrays, have attracted enormous attention for RF wireless systems in the past five years, owing to the very large potential throughput in bits\/second\/Hertz and increased protection against fading associated with single antenna designs. <br\/><br\/>This research addresses the design and performance analysis of space-time codes that can be applied to MIMO channels for application to the wireless optical communications environment. The research focuses on several aspects of this problem: <br\/><br\/>--development of relevant MIMO models for outdoor line-of-sight optical channels, with particular attention to modeling of source and detector physics; --examination of the information-theoretic potential of this channel, particularly in the context of growing array size, and the analysis of bounding techniques on error probability to aid in the development of code design rules; --formulation and evaluation of space-time coding approaches for the optical free-space regime that are efficient in the channel capacity sense; <br\/>--block-coded, trellis-coded, and concatenated approaches. <br\/><br\/>Also, the application of space-time codes to the indoor wireless infrared channel and the examination of their performance are addressed.","title":"Space-Time Coding for Optical MIMO Channels","awardID":"0208763","effectiveDate":"2002-07-15","expirationDate":"2005-12-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4096","name":"COMMUNICATIONS RESEARCH"}}],"PIcoPI":["556971","523508"],"PO":["348215"]},"72072":{"abstract":"Moulin, Pierre<br\/>U of Ill Urbana- Champaign<br\/><br\/>The enormous growth in electronic commerce has led to an urgent need for the protection and<br\/>authentication of information, which now is stored and transmitted in massive amounts. There is a<br\/>multitude of applications where a signal (typically audio, image or video) is to be communicated to<br\/>a receiver, along with information such as ownership identification or a timestamp authenticating<br\/>the signal. The communication channel on which the signal is transmitted may be insecure, i.e.,<br\/>an adversary may modify the signal in such a way that it can no longer be reliably authenticated.<br\/>In some applications (e.g., wireless video transmission) the channel is considered to be insecure<br\/>not due to the presence of an adversary, but because of the significant degradations introduced<br\/>by the transmission medium. A secret message necessary for authentication may be embedded<br\/>in the signal (watermarking-based authentication) or transmitted on a separate channel (hashing-<br\/>based authentication). In watermarking, the host data set is intentionally corrupted, but in a covert<br\/>way, designed to be imperceptible to a casual analysis. Hashing does not require the signal to be<br\/>modified, but requires the transmission of side information about the signal (authentication tag)<br\/>on a separate channel.<br\/>Signal authentication encompasses applications such as forgery detection and analysis, copyright<br\/>protection for digital media, copy control, fingerprinting (traitor tracing), and database query and<br\/>retrieval [1]|[30]. Watermarking and authentication are now major activities in audio, image, and<br\/>video processing, and standardization efforts for JPEG-2000, MPEG-4, and Digital Video Disks<br\/>are well underway. Commercial products are being developed. Annual International Workshops<br\/>on information hiding have been held in 1996, and every year since 1998. Special issues of major<br\/>technical journals have recently been recently devoted to information protection [31, 32, 33, 34],<br\/>and comprehensive surveys of image and multimedia watermarking techniques are available from<br\/>[35, 36].","title":"Statistical Theory and Algorithms for Signal Authentication","awardID":"0208809","effectiveDate":"2002-07-15","expirationDate":"2006-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4720","name":"SIGNAL PROCESSING SYS PROGRAM"}}],"PIcoPI":["518625"],"PO":["564898"]},"72083":{"abstract":"The objective of the proposed research is to improve network security through an innovative approach to vulnerability and resiliency analysis. Even well administered networks are vulnerable to attacks due to the security ramifications of offering a variety of combined services. That is, services that are secure when offered in isolation nonetheless provide an attacker with combined vulnerabilities to exploit when offered simultaneously. Security tools such as COPS, System Scanner, and CyberCop, are excellent at identifying specific, known, individual host vulnerabilities in services, software packages, and configurations. What these methods do not address is the compound effect of multiple vulnerabilities. The result is a serious problem because interactions between vulnerabilities can easily cascade across a network. The risk posed by each vulnerability may be judged either necessary or acceptable in isolation, but the combination of these vulnerabilities can still turn out to compromise the network as a whole in an unacceptable way. A limited amount of existing work in vulnerability analysis addresses this problem, but the existing work falls short in three key areas, namely resiliency analysis, all-paths analysis, and inference engine analysis. The proposed work will improve network security by addressing systematically each of these three areas.","title":"Network Vulnerability and Resiliency Analysis","awardID":"0208848","effectiveDate":"2002-07-15","expirationDate":"2006-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2802","name":"TRUSTED COMPUTING"}}],"PIcoPI":[186658],"PO":["521752"]},"72094":{"abstract":"This research investigates the ways geographic mobility and communications, including computer-mediated communication, influence the formation, maintenance, and dissolution of personal and work relationships and the ways these factors influence people's ability to extract social resources from them. Maintaining personal relationships requires significant investment in time and money. Physical proximity makes building personal relationships easier, while geographic mobility puts relationships at risk. Large numbers of Americans are now using the Internet, with electronic mail and other services for interpersonal communication. The Internet can potentially reduce the constraints that geography imposes on social relationships. It may also influence the quality of relationships conducted online. This research examines whether use of Internet communication changes the number and quality of social relationships and the social support derived from them. By examining the content of communication conducted over different modalities (visits, phone calls, email and instant messaging), it will help identify the mechanisms through which communication leads to social support. The research will simultaneously be of interest to social scientists concerned with the basic processes underlying social and work relationships and to more applied researchers and policy makers interested in the impact of the Internet on social life.","title":"The Evolution of Social Ties in the Age of the Internet","awardID":"0208900","effectiveDate":"2002-07-01","expirationDate":"2006-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6850","name":"DIGITAL SOCIETY&TECHNOLOGIES"}}],"PIcoPI":["499499","560995"],"PO":["564456"]},"73470":{"abstract":"Keshab K. Parhi<br\/>Institue of Electrical & Electronics Engineers, Inc.<br\/><br\/>The IEEE 2002 Workshop on Signal Processing Systems (SIPS02) will be held at the Catamaran Resort Hotel from October 16-18, 2002. SIPS02 focuses on topics at the convergence of signal processing theory, VLSI architectures, and integrated circuit implementation of multimedia communications. The conference theme this year reflects the critical role played by signal processing microsystems in the deployment of next<br\/>generation communications infrastructure including wireless, optical and wireline systems. SIPS02 is requesting the National Science Foundation to provide a travel grant to provide travel funds to U.S. students who would otherwise not be able to attend this workshop.","title":"Student Travel Grant: IEEE 2002 Workshop on Signal Processing Systems (SIPS'02), Oct. 16-18, 2002","awardID":"0215043","effectiveDate":"2002-07-15","expirationDate":"2003-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4720","name":"SIGNAL PROCESSING SYS PROGRAM"}}],"PIcoPI":["550262"],"PO":["564898"]},"72040":{"abstract":"As modern memory architectures grow in complexity, it is becoming<br\/>increasingly important to design algorithms with high data locality.<br\/>Standard approaches parameterize algorithms by aspects of the memory<br\/>hierarchy, such as the size and block size of each memory level.<br\/>Unfortunately, this parameterization often leads to complex algorithms<br\/>that are tuned to particular architectures. A promising new line of<br\/>research is to develop memory-hierarchy-sensitive algorithms that avoid<br\/>any memory-specific parameterization. Such platform-independent algorithms<br\/>are said to be \"cache-oblivious.\" If a cache-oblivious algorithm works<br\/>optimally on a two-level hierarchy, then it works optimally on all levels<br\/>of a multilevel memory hierarchy; cache-oblivious algorithms automatically<br\/>tune to arbitrary memory architectures.<br\/><br\/>This research involves maintaining data locality in irregular and dynamic<br\/>settings, where the data flow is continually changing and unpredictable.<br\/>The investigator will design cache-oblivious solutions for a variety of<br\/>fundamental algorithms and data-structures problems. New algorithmic<br\/>models of aspects of the memory hierarchy will be proposed and integrated.<br\/>The investigator will emphasize solutions that are simple and elegant<br\/>enough to implement. Two verification tools under development at Stony<br\/>Brook will provide testbeds for the project's empirical component.","title":"Data Structures and Algorithms for Maintaining Data Locality","awardID":"0208670","effectiveDate":"2002-07-15","expirationDate":"2006-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2860","name":"THEORY OF COMPUTING"}}],"PIcoPI":["533341"],"PO":["499399"]},"68520":{"abstract":"Abstract for DMS - 0138374<br\/><br\/>This incubation project plans to start an interdisciplinary collaboration<br\/>whose goal is the understanding of folding and unfolding processes for<br\/>polygonal linkages and other related structures.<br\/><br\/>We plan to investigate the topology and the algebraic-geometric structure<br\/>of configuration spaces of two- and three-dimensional serial linkages, via<br\/>generalizations of recent successful rigidity-theoretic approaches based<br\/>on pseudo-triangulation mechanisms, and to advance the understanding of<br\/>the global structure of the associated configuration spaces. The<br\/>rigidity-theoretic techniques have allowed the definition of 2-d motions<br\/>that are purely expansive or contractive: the former can guarantee that a<br\/>chain will not self-collide. We plan to extend these techniques to three<br\/>dimensions and subsequently develop efficient data structures and<br\/>algorithms for planning, analyzing, approximating, tracking and querying<br\/>such motions.<br\/><br\/>We expect that folding problems, beyond their intrinsic mathematical<br\/>interest, will lead to techniques that will impact areas such as molecular<br\/>biology, where the protein folding problem is of central significance, as<br\/>well as robotics and micromechanics, where modular kinematic mechanisms<br\/>(with possibly large numbers of links) are often employed. The common<br\/>denominator of these endeavors, and our main theme, is the general<br\/>question of planning and reasoning about collision free motions for serial<br\/>linkages of various kinds.","title":"Computational and Algorithmic Representations of Geonetric Objects - CARGO: Folding and Unfolding Processes for Polygonal Linkages, with Applications to Robotics and Biology","awardID":"0138374","effectiveDate":"2002-07-01","expirationDate":"2004-06-30","fundingAgent":[{"dir":{"id":"03","name":"Directorate for DIRECT FOR MATHEMATICAL & PHYSICAL SCIEN","abbr":"MPS"},"div":{"id":"0304","name":"Division of MATHEMATICAL SCIENCES","abbr":"DMS"},"pgm":{"id":"1260","name":"INFRASTRUCTURE PROGRAM"}},{"dir":{"id":"03","name":"Directorate for DIRECT FOR MATHEMATICAL & PHYSICAL SCIEN","abbr":"MPS"},"div":{"id":"0304","name":"Division of MATHEMATICAL SCIENCES","abbr":"DMS"},"pgm":{"id":"X871","name":"DARPA-COMP & ALGORITHMIC  REP"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2865","name":"NUMERIC, SYMBOLIC & GEO COMPUT"}}],"PIcoPI":["264576","312372","521232","550373"],"PO":["565211"]},"79542":{"abstract":"Level of Detail Selection Using a Perceptual Error Metric<br\/><br\/>This grant will investigate the use of visual difference metrics in<br\/>level of detail calculations. The research will make it possible to<br\/>evaluate the visual detectability of changes to an object<br\/>representation in addition to the geometric difference that such<br\/>modifications make to the object's surface definition. Factors that<br\/>will be taken into account using a single visual metric include<br\/>eyepoint position and surface texture. The context in which the<br\/>object is placed, including the effect of lighting, will also be<br\/>evaluated. The research will explore the impact that each dimension<br\/>has on the final level of detail and will derive an efficient visual<br\/>difference metric that can be used in conjunction with existing<br\/>geometric measures.","title":"Level of Detail Selection Using a Perceptual Error Metric","awardID":"0242757","effectiveDate":"2002-07-01","expirationDate":"2004-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2865","name":"NUMERIC, SYMBOLIC & GEO COMPUT"}}],"PIcoPI":["426498"],"PO":["532791"]},"68553":{"abstract":"ECS-0138518<br\/>Arpad Bergh<br\/><br\/><br\/>The Optoelectronics Industry Development Association is establishing under NSF and DARPA support the Photonics Technology Access Program (PTAP), where government funds are used to procure pre-commercial photonics experimental research prototypes (hereinafter referred to as \"prototypes\") to be made available to qualified researchers in a competitive solicitation and evaluation process. These pre-commerical prototypes may comprise novel materials, material structures, devices and device arrays, circuits and modules. Academic researchers can use the prototypes to advance discovery and understanding in photonics and provide feedback to the industry. Professors may also use the prototypes to enhance teaching, training and learning in class demonstrations and teaching laboratories. The goal of the program is to improve the availability of novel experimental research prototypes to universities. New prototypes are evolving at increasing rate and frequency, and if researchers have access to them only when they are available commercially, they are one or two generations behind leading edge technology.<br\/><br\/>The program is modeled after the successful parts of the U.S.-Japan Joint Optoelectronics Project (JOP). Although the proposed program is domestic in nature, it has the potential to be expanded internationally at a later date to include Japan, Europe and others. Such an expansion might be considered to enrich the offerings of the program to include prototypes that are not available in the U.S. and to collect feedback from academic researchers from outside the U.S. who might have different perspectives. OIDA is well qualified to provide the broker function for this program based on its five years of experience with the JOP, including managing the domestic competitive solicitation and evaluation process supported with NSF and DARPA funds. OIDA also has strong interactions with large and small photonics companies and photonics-active academic institutions. To further strengthen its ties with PTAP constituencies, OIDA would assemble an Advisory Board for this program comprising leading researchers and educators from academia, industry and government.<br\/><br\/>Photonics is a key enabling technology for the information age and it complements the goals of the National Nanotechnology Initiative and the National Information Technology Initiative. The proposed Photonics Technology Access Program also contributes to workforce development in science, engineering and technology and benefits numerous existing photonics programs thoughout the government. The program also helps industry, especially small companies who might find new applications for their leading prototypes.","title":"Photonics Technology Access Program - PTAP","awardID":"0138518","effectiveDate":"2002-07-01","expirationDate":"2006-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0506","name":"Division of EXPERIMENTAL & INTEG ACTIVIT","abbr":"EIA"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0701","name":"Division of ELECTRICAL, COMMUN & CYBER SYS","abbr":"ECCS"},"pgm":{"id":"1385","name":"SPECIAL STUDIES AND ANALYSES"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0701","name":"Division of ELECTRICAL, COMMUN & CYBER SYS","abbr":"ECCS"},"pgm":{"id":"1517","name":"ELECT, PHOTONICS, & MAG DEVICE"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0701","name":"Division of ELECTRICAL, COMMUN & CYBER SYS","abbr":"ECCS"},"pgm":{"id":"T001","name":"DARPA-PTAP"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0701","name":"Division of ELECTRICAL, COMMUN & CYBER SYS","abbr":"ECCS"},"pgm":{"id":"T002","name":"DARPA-PTAP"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0701","name":"Division of ELECTRICAL, COMMUN & CYBER SYS","abbr":"ECCS"},"pgm":{"id":"T003","name":"DARPA-PTAP"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0701","name":"Division of ELECTRICAL, COMMUN & CYBER SYS","abbr":"ECCS"},"pgm":{"id":"V245","name":"DARPA-PTAP"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0701","name":"Division of ELECTRICAL, COMMUN & CYBER SYS","abbr":"ECCS"},"pgm":{"id":"V551","name":"DARPA-PTAP"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0701","name":"Division of ELECTRICAL, COMMUN & CYBER SYS","abbr":"ECCS"},"pgm":{"id":"V661","name":"DARPA-PHOTONICS TECH ACCESS"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0701","name":"Division of ELECTRICAL, COMMUN & CYBER SYS","abbr":"ECCS"},"pgm":{"id":"W327","name":"DARPA-PHOTONICS TECH ACCESS PR"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0701","name":"Division of ELECTRICAL, COMMUN & CYBER SYS","abbr":"ECCS"},"pgm":{"id":"W328","name":"DARPA-PTAP"}}],"PIcoPI":["270247","419929"],"PO":["508629"]},"69115":{"abstract":"This U.S.-Czech-Hungarian research project involves three teams led by Fred Roberts of Rutgers University's Center for Discrete Mathematics and Theoretical Computer Science (DIMACS) with partners in Prague and Budapest. His counterparts are Jaroslav Nesetril of the Czech Center for Discrete Mathematics, Theoretical Informatics and Applications (DIMATIA) at Charles University and Gyula Katona of the Hungarian Academy of Sciences' Alfred Renyi Institute for Mathematics. Their collaborative research plan involves the formation of multinational \"working groups\" in research areas of discrete mathematics and theoretical computer science. These \"working groups\" will consist of a complementary mix of expertise from each center and include graduate students as well as senior and junior faculty. New members may be added as projects progress. Some participants may be drawn from other institutions, when appropriate. Additionally, smaller team collaborations resulting from working group interaction will be fostered through a visit program that allows researchers and graduate students from the partner centers to work together more intensively, with emphasis on a senior researcher in one center and a junior researcher or student at another. <br\/><br\/>The topics to be studied include: 1) extremal combinatorics, 2) graph colorings and their generalizations, and 3) algebraic and geometric methods in combinatorics. Our knowledge of the interactions between algebraic geometry and combinatorics will be extended through examination of power series, hidden convexity phenomenon, and combinatorial characterizations of algebraic sets. Results should lead to advances in discrete mathematics which may be applicable to problems in group testing, communications, and statistical physics. Additionally, the involvement of outstanding junior researchers in this international network of excellence should have a significant and long-lasting influence on human resource development in all three countries. <br\/><br\/>This international project linking three leading mathematics research centers fulfills the program objective of advancing scientific knowledge by enabling experts in the United States and Central Europe to combine complementary talents and share research resources in areas of strong mutual interest and competence.","title":"U.S.-Czech-Hungarian Collaboration on Discrete Mathematics and Theoretical Computer Science Involving DIMACS-DIMATIA-Renyi Centers","awardID":"0140431","effectiveDate":"2002-07-01","expirationDate":"2007-06-30","fundingAgent":[{"dir":{"id":"01","name":"Office of OFFICE OF THE DIRECTOR                  ","abbr":"O\/D"},"div":{"id":"0109","name":"Office of INTL SCIENCE & ENGINEERING","abbr":"OISE"},"pgm":{"id":"5979","name":"CENTRAL & EASTERN EUROPE PROGR"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0507","name":"Division of SCIENCE EDUCATION RESOURCES IM","abbr":"SER"},"pgm":{"id":"1264","name":"ALGEBRA,NUMBER THEORY,AND COM"}}],"PIcoPI":["264120"],"PO":["561352"]},"73680":{"abstract":"EIA 02-15753<br\/>Collins, Oliver<br\/>University of Notre Dame<br\/><br\/>MRI: Acquisition of High Speed Mixed Signal Test Equipment <br\/><br\/>This proposal, studying quadrature and Sigma Delta modulation\/demodulation, supports communications\/signal processing research for experimental validation using simulators. Experimental verification of new ideas in Sigma Delta digital-to-analog and analog-to-digital conversion will be explored. Sigma Delta modulation allows an intrinsically linear two level quantizer to reproduce a high resolution signal by shifting the quantization noise away from the signal band for removal by filtering. The Sigma Delta modulator tries to find the optimal sequence of +1's and -1's such that, after filtering, the squared Euclidean distance between this sequence of +1's and -1's and a given, identically filtered, discrete-time, unity-amplitude-limited sequence filtering is minimized. The research aims to show that Sigma Delta modulation constitutes a crude optimization algorithm and that practicable techniques solve this optimization problem well enough to improve dynamic range beyond the current state-of-the-art. The PI claims that the substantial improvement will almost certainly expose the inherent nonidealities of even single bit quantizers. Because of the bit-to-bit interactions produced by reflections from imperfect impedance matches at its output, even single bit D to A generates noise and spurious signals. The equipment requested, three pieces of high speed, mixed signal test: a data generator, a network analyzer, and a signal analyzer, will allow investigation of these effects and permit the design of better single- and multiple-bit quantizers. The data generator will be used as a stimulus source in a wavelength division multiplexing project; the superior range of the network analyzer will contribute to a microwave remote sensing project. Improvement in analog-to-digital and digital-to-analog bandwidth and dynamic range is expected. The devices are important whenever digital computation must be interfaced to physical world (e.g., getting the analog signal radiated by an antenna). Since the digital revolution depends on these conversions, the interface is critical to send and store information. Improved performance and reduced complexity in manufacturing systems that depend on these conversions, such as personal CD players, cellular telephones, high definition TV, computer modems, deep communication systems would benefit us all. Moreover, in addition to supporting research, the equipment will support enhanced projects in three undergraduate courses and contribute to make the students attractive to industry for both hiring and mentoring the required design projects.","title":"MRI: Acquisition of High Speed Mixed Signal Test Equipment","awardID":"0215753","effectiveDate":"2002-07-01","expirationDate":"2006-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1189","name":"MAJOR RESEARCH INSTRUMENTATION"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"4096","name":"COMMUNICATIONS RESEARCH"}}],"PIcoPI":["466234"],"PO":["557609"]},"72074":{"abstract":"The goal of this research is to elaborate an elegant and comprehensive <br\/>specification language and semantics for interactive computational <br\/>problems and explore the corresponding logic, --- the set of valid <br\/>principles of interactive computability expressible in that language. <br\/>Such a logic provides us with a powerful tool for systematically <br\/>studying computational tasks and automatically generating solutions to <br\/>new problems from known solutions to old problems. Other applications <br\/>include the possibility to base on this logic knowledge- and resource-<br\/>oriented automatic reasoning systems. <br\/><br\/>The intuitive notion of interactive computational problem is formalized <br\/>as a game between two players: the machine and the environment (user). <br\/>Moves of the game represent actions\/choices by these agents, and <br\/>positions represent states\/situations that emerge in the course of <br\/>interaction. A game is considered winnable (and hence the corresponding <br\/>problem solvable), if there is a computer program that wins it against <br\/>any possible environment. The language of the logic of interactive <br\/>computational problems suggested by the investigator is a non-disjoint <br\/>union of the languages of classical, intuitionistic and linear logics, <br\/>with logical operators interpreted as certain, --- most basic and <br\/>natural, --- operations on games. Validity of a formula is understood <br\/>as winnability for every game\/problem interpretation of its atoms. The <br\/>restriction of winnability to the classical fragment of the language <br\/>turns out to be equivalent to the classical concept of truth, which <br\/>makes classical logic a natural syntactic fragment of the logic of <br\/>interactive computational problems. The same is conjectured to be the <br\/>case for the intuitionistic logic and (a version of) linear logic. This <br\/>way, the logic of interactive computational problems can unify, within <br\/>the framework of one general semantics, the classical, intuitionistic <br\/>and linear logics, with their seemingly unrelated or even antagonistic <br\/>philosophies. Verifying this conjecture, along with finding an <br\/>axiomatization for the logic of interactive computational problems, is <br\/>among the main technical objectives of this research.","title":"A Logical Study of Interactive Computational Problems Understood as Games","awardID":"0208816","effectiveDate":"2002-07-01","expirationDate":"2006-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2860","name":"THEORY OF COMPUTING"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0507","name":"Division of SCIENCE EDUCATION RESOURCES IM","abbr":"SER"},"pgm":{"id":"1267","name":"TOPOLOGY"}}],"PIcoPI":[186637],"PO":["499399"]},"72096":{"abstract":"Frazzoli - Branicky Abstract<br\/><br\/>This project is aimed at the development of new tools and techniques for the design and analysis of high-confidence software for complex, distributed, reconfigurable aerospace embedded systems, and to transfer these methods to undergraduate and graduate students, other researchers, and industry. <br\/>Problems of direct interest include those arising in the control and coordination of multiple autonomous air and space vehicles, and in the detection and resolution of conflicts in Air Traffic Control. The techniques developed in this project are also applicable to other systems which require similar levels of reliability and performance, such as highway traffic automation systems, health care systems, power networks, and<br\/>financial services.<br\/><br\/>The primary goal of this project is a better understanding of the interactions between real-time software and dynamical systems. This will lead to new and powerful tools and techniques for the design and analysis of embedded systems, as well as an improved approach to the requirement specification for real-time systems.<br\/>The core of the research is aimed at dramatically reducing the complexity of embedded and hybrid systems design and verification by exploiting the geometric structure of the underlying physical system in the modelling effort, and by preserving this structure in the design of control laws and algorithms. This will make feasible the analysis of the complete system (including its physical and software components) by otherwise poorly scalable techniques such as abstract interpretation and model checking, and will provide<br\/>the means for the effective use of techniques based on compositional reasoning. For example, group symmetries in vehicle dynamics give rise to families of equivalent controlled trajectories: such sets are called motion primitives for single vehicles, and motion coordination primitives for groups of vehicles. A maneuver automaton is a collection of a finite number of motion primitives. It provides a discrete model of the vehicle dynamics, which leads to a dramatic reduction of the complexity of describing and controlling the vehicle behavior, by providing a high level of abstraction, and at the same time providing invariants which ensure that the physical state remains within some known bounds.<br\/><br\/>The educational part of the project is implemented through new course and curriculum development, and student mentoring. The main educational objective is to provide both undergraduate and graduate students with the knowledge and the skills to understand the key issues and to ensure technical leadership in the current and future aerospace information technology arenas. Finally, an interactive web site is being developed, where it is possible to access information and software developed in the research project and for the courses.","title":"Collaborative Research: Geometric and Algorithmic Techniques for Design and Verification of Hybrid Control Systems","awardID":"0208919","effectiveDate":"2002-07-15","expirationDate":"2006-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2801","name":"EMBEDDED & HYBRID SYSTEMS(EHS)"}}],"PIcoPI":["548925"],"PO":["561889"]},"67410":{"abstract":"This proposal aims to investigate the impact of the new I\/O<br\/>technologies on the operating system architecture of the network servers. <br\/>The key ingredient of the proposed approach is the memory-to-memory <br\/>intra-server interconnect which allows non-intrusive communication <br\/>between hosts and intelligent devices. Memory-to-memory communication <br\/>eliminates or significantly reduces the overhead typically associated with <br\/>conventional communication protocols. This benefit has been extensively <br\/>studied to improve the performance of distributed applications but has not <br\/>been yet explored in support of the operating system performance. <br\/><br\/>The research will focus on how to split the operating system functionality<br\/>across a cluster of computing nodes and intelligent devices. Two novel <br\/>operating mechanisms based on memory-to-memory communication will be <br\/>explored: (i) direct application-to-device communication to offload the <br\/>TCP\/IP protocol processing to TCP servers executed on intelligent network <br\/>interfaces or dedicated nodes, and (ii) direct communication between <br\/>memory-mapped file servers and TCP servers. The research will also <br\/>investigate how to use memory-to-memory communication to support cooperative <br\/>file and network servers for availability and load-balancing.<br\/><br\/>This research has been considerably motivated by the increasing interest<br\/>in VIA, InfiniBand, and programmable device controllers. Its ultimate goal is <br\/>to contribute to the understanding of how systems software should be designed<br\/>to exploit and combine these new technologies.","title":"CAREER: A Split Operating System Architecture for Servers with Memory-to-Memory Communication","awardID":"0133366","effectiveDate":"2002-07-01","expirationDate":"2007-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2876","name":"DISTRIBUTED SYSTEMS"}}],"PIcoPI":["486425"],"PO":["543507"]},"67553":{"abstract":"This is a Faculty Early Career Development (CAREER) award. The research will explore how an organism extracts information from its environment for learning and perception, both to understand human learning and to create better machine learning algorithms. The first objective is to develop and apply new algorithms to better understand the mapping in the sensory pathways. An important goal is to understand how the visual pathway computes the invariant responses observed in inferotemporal cortex. The second objective is to study the extraction of information from cross-sensory interaction and its role in the development of perceptual invariance. This work will involve integrated computer simulations, mathematical modeling, and psychological experiments. As part of this goal, the researcher will study input feature selection, output feature selection, and the general problem of how dimensions should best interact in machine learning algorithms. The final research goal is to bring together the new knowledge in constructing a better autonomous learning machine that can learn to recognize objects. The algorithm will be more modular than current algorithms and will collect its own training data autonomously through a camera, microphone, and other sensors.<br\/><br\/>The educational goal is to train students in the lab as well as in the classes to think about problems from a variety of approaches. They will be educated in the advantages and limitations of computational modeling, computational analysis, psychophysics and electrophysiology.<br\/><br\/>This CAREER award recognizes and supports the early career-development activities of a teacher-scholar who is likely to become an academic leader of the twenty-first century. The research will improve our understanding of optimal integration between sensory modalities. This will lead to improvement in computer sensing algorithms, including computer vision, speech recognition, and any other application where other sources of information may be available. The work is also expected to give insight to the general problem of how to optimally combine different sources of information for machine learning. The educational aspects of this project are designed to give students a multidisciplinary perspective along with specific skills allowing them to use and appreciate a variety of approaches and techniques.","title":"CAREER: Optimal Information Extraction in Intelligent Systems","awardID":"0133996","effectiveDate":"2002-07-01","expirationDate":"2009-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6856","name":"ARTIFICIAL INTELL & COGNIT SCI"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":["518651"],"PO":["387198"]},"76188":{"abstract":"ABSTRACT<br\/><br\/>UC Irvine requests funding to convene a workshop, in Irvine, on May 20-21, 2002, to produce a report that explores and recommends industry-academic-government infrastructure-building models for Experimental Infostructure Networks to help define new programs. This Workshop is being organized as a follow-on to a December 2001 workshop \"Grand Challenges in e-Science\" to add industry and private-sector input.<br\/><br\/>Infostructure encompasses the emerging computational, visualization, data storage, instrumentation and networking technologies that support our nation's major science and engineering research facilities. These facilities enable e-Science, large-scale networked science, that studies very complex micro to macro-scale problems over time and space. Infostructure includes computers and networks, and the middleware that enables coordinated resource sharing and problem solving among distributed facilities.<br\/><br\/>Networks are the key enabling technology for transforming infostructure from geographically separated computational facilities and instruments into a National Information Infrastructure. Three classes of Research & Education R&E networks beyond the commodity Internet are:<br\/>Production Networks<br\/>Experimental Networks<br\/>Research Networks<br\/><br\/>The purpose of this Workshop will be to answer the questions: Does the computer and telecommunications industry agree on a need for Experimental Infostructure Networks for e-Science? If yes, for what reasons, and what should they look like in the near and longer term? What roles should industry, government and academia play?<br\/><br\/>This Workshop will result in the publication of a report that contains a list of recommendations with justification. All participants' names will appear as contributors to the report. Cal (IT) will manage the logistics as the host site and will assist the program committee in planning. The agenda and the final report will be produced by a team at UC San Diego, headed by Dr. Larry Smarr, under subcontract from UC Irvine. The budget includes costs for the workshop expenses, for the subcontract, and for staff and supplies at UC Irvine.","title":"Workshop on Experimental Infostructure Networks; Irvine, California","awardID":"0227640","effectiveDate":"2002-07-01","expirationDate":"2003-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"4090","name":"ADVANCED NET INFRA & RSCH"}}],"PIcoPI":[198444],"PO":[198445]},"72394":{"abstract":"CCR-0210153<br\/>Kogge, Peter<br\/><br\/>This proposal was received in response to the Nanoscale Science and Engineering initiative, NSF 01-157, category NIRT. Quantum-dot cellular automata (QCA) is a revolutionary computing paradigm that is well suited to nanoelectronic implementation and scaling to molecular dimensions. The central feature of <br\/>QCA is that binary information is encoded in the position of single electrons among a group of dots forming a cell. This represents a significant break with the transistor-based paradigm in which information <br\/>is encoded by the state of the transistor current switch. In QCA, electrons switch between quantum dots within a cell, but no current flows between cells. This leads to extremely low power dissipation, avoiding the problem of heat generation that will ultimately limit the integration density of transistor circuits. <br\/>Clocking of QCA circuits has proven to be extremely important from the standpoint of both architectures and devices. It allows arrays of QCA cells to be broken into sub-arrays for pipelined processing, and it enables cells to produce signal power gain to replace signal energy lost to the environment. Functioning QCA devices have already been demonstrated in an aluminum\/oxide tunnel junction scheme, confirming the operation of QCA cells, shift registers, logic gates, and memory elements. Power gain in a QCA shift register has also been achieved. This project will advance the architectural development of QCA, investigate questions of switching speed in nanoelectronic devices, and develop advanced fabrication techniques to implement the architectural and circuit theory concepts. Since QCA represents a dramatic break from conventional devices, <br\/>significant changes in architecture are needed to fully exploit the capabilities of QCA. In QCA layout, timing, and architecture are intimately related, requiring a unified design approach. This is analogous to the <br\/>approach begun by Mead and Conway which revolutionized VLSI design by making a connection between architecture and layout and building on that connection to enable designers to quickly synthesize large and complex functional blocks. Likewise, QCA system designers will be able to exploit timing in addition <br\/>to layout to produce highdensity functional designs. In particular we will investigate the development of simple, yet complete, QCA based \"Field Programmable Gate Arrays\", where 2D arrays of identical cells are tiled together, with programmable interconnect and function. Timing plays a pivotal role in QCA designs, so it is vital to achieve a complete understanding of switching and switching dynamics in arrays of coupled electrons. Some recent theoretical results indicate that electron switching speeds would be orders of magnitude lower than that expected from the capacitances and resistances of the dots and tunnel junctions, contrary to theoretical work done at Notre Dame. To resolve this issue we will apply high frequency measurement techniques to the study of switching in QCA cells and in arrays of cells.<br\/>At present, experimental demonstrations of QCA devices are limited to a small number of cells by the large capacitances produced by the aluminum tunnel junctions. To support and experimentally confirm the advances made in architecture and circuit theory, we will employ advanced fabrication techniques based on AFM lithography to produce QCA with greatly enhanced operating characteristics. This will allow us to fabricate and measure arrays of cells with significant extent and complexity. QCA presents a unique opportunity for a broad impact on the educational experience of students, and on research in the field of electronic devices. <br\/>We will develop instructional modules based on QCA simulation tools to teach the concepts of QCA architecture to undergraduate and graduate students. These modules will benefit students by introducing them to <br\/>alternative architectural concepts. In addition, by broadening their horizons, it will strengthen their understanding of conventional architectures by emphasizing the foundational concepts of architectural <br\/>concepts.","title":"NIRT: Architectures and Devices for Quantum-dot Cellular Automata","awardID":"0210153","effectiveDate":"2002-07-15","expirationDate":"2007-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2878","name":"SPECIAL PROJECTS - CCF"}}],"PIcoPI":["489795","489796","336016","512755","512756"],"PO":["325495"]},"75320":{"abstract":"The long range goal of this project is to investigate a framework that can improve understanding of the topology\/connectivity of complex biological pathways. This research combines experimental molecular genetics with computational systems biology to develop new approaches for mapping complex signal transduction pathways in eukaryotic cells. The initial system for study is the Ras and Tor pathways in the budding yeast Saccharomyces cerevisiae. The research will employ data sets from whole genome expression analysis to develop and validate the pathway map. The research will focus on three avenues of analysis with the objectives: (1) to study a genetic epistasis analysis approach using extensive DNA microarray data to define a qualitative connectivity map of the pathways, (2) investigate a new computational systems approach based on a superstructure representation and a mixed integer linear optimization framework for the prediction of the topology of the complex pathways, and (3) study a quantitative analysis framework for the effect of model uncertainty on the network topology of the metabolic pathways.","title":"QSB: Computational and Experimental Studies of Pathways in Yeast","awardID":"0222471","effectiveDate":"2002-07-01","expirationDate":"2007-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0503","name":"Division of SHARED CYBERINFRASTRUCTURE","abbr":"SCI"},"pgm":{"id":"1271","name":"COMPUTATIONAL MATHEMATICS"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0702","name":"Division of CHEM, BIOENG, ENV, &  TRANSP S","abbr":"CBET"},"pgm":{"id":"1403","name":"PROCESS & REACTION ENGINEERING"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0702","name":"Division of CHEM, BIOENG, ENV, &  TRANSP S","abbr":"CBET"},"pgm":{"id":"1491","name":"BIOTECH, BIOCHEM & BIOMASS ENG"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0706","name":"Division of DESIGN & MANUFACTURING INNOV","abbr":"DMI"},"pgm":{"id":"5514","name":"OPERATIONS RESEARCH"}}],"PIcoPI":[195882,"539069"],"PO":["360556"]},"67543":{"abstract":"This research project will address the problem of information overload by creating new document organization and presentation techniques. The approach will generate intelligent interfaces to the scientific literature. Existing knowledge bases will be used for the automatic generation of these interfaces. Categorizations and analyses of the search results will be used as the basis of an interactive interface to manage and share documents. The career development plan will include the use of real-world problems in biomedicine to motivate learning about information technology. It will also develop courses that promote interdisciplinary learning.","title":"CAREER: Intelligent Interfaces for Searching, Managing, and Sharing the Scientific Literature","awardID":"0133973","effectiveDate":"2002-07-15","expirationDate":"2008-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6855","name":"INFORMATION & KNOWLEDGE MANAGE"}}],"PIcoPI":["486167"],"PO":["433760"]},"72010":{"abstract":"The increasing requirements on data rate and quality of<br\/>service for wireless communications systems call for new<br\/>techniques to improve radio link reliability and to increase<br\/>spectral efficiency. The three key technologies to achieve these<br\/>goals are equalization, diversity, and channel coding.<br\/>Mathematics is of fundamental importance to these technologies,<br\/>providing the theoretical basis as well as the means for<br\/>efficient numerical implementations. The investigator derives a<br\/>theoretical and numerical framework for designing equalization<br\/>techniques for time-varying channels. Using methods from<br\/>pseudo-differential operator theory and time-frequency analysis,<br\/>he develops a qualitative and quantitative theory for the<br\/>approximate diagonalization of operators associated with<br\/>time-varying systems. These theoretical results form a keystone<br\/>in the construction of fast and reliable numerical equalization<br\/>methods that are based on Krylov subspace techniques. The<br\/>investigator also studies the use of frame theory in wireless<br\/>communications. Using concepts from sphere packings and group<br\/>theory, he analyzes theoretical properties of special frames such<br\/>as Grassmannian frames. Furthermore, he develops theoretical and<br\/>numerical schemes in connection with multi-carrier communication<br\/>systems such as OFDM. This includes the design of transmission<br\/>signals with specific properties using a generalization of the<br\/>concept of prolate spheroidal wave functions. By taking recent<br\/>tools from harmonic analysis into the wireless communications<br\/>community, this project enables further advances and<br\/>breakthroughs in wireless communications. At the same time it<br\/>stimulates new research areas in applied mathematics and paves<br\/>the road for further interactions between applied mathematicians<br\/>and communication engineers.<br\/> The goal of this project is to develop mathematical concepts<br\/>and computational methods for wireless communications technology.<br\/>The investigator combines modern tools from mathematics with<br\/>methods from information theory and signal processing to develop<br\/>new concepts and algorithms for key technologies in wireless<br\/>communications, such as coding, transmission, and equalization.<br\/>Mathematics is of fundamental importance to these technologies,<br\/>because it provides the theoretical basis as well as the means<br\/>for efficient numerical implementations. By providing tools to<br\/>improve radio link reliability and increase data rates, this<br\/>project is instrumental in meeting the increasing requirements on<br\/>future wireless communications systems. The project produces<br\/>conceptual deliverables in the form of new mathematical methods<br\/>to analyze and construct wireless transmission systems. The<br\/>project also produces concrete deliverables in the form of<br\/>numerical algorithms for use in the scientific and industrial<br\/>sector.","title":"Applied Harmonic Analysis and Wireless Communications","awardID":"0208568","effectiveDate":"2002-07-15","expirationDate":"2006-06-30","fundingAgent":[{"dir":{"id":"03","name":"Directorate for DIRECT FOR MATHEMATICAL & PHYSICAL SCIEN","abbr":"MPS"},"div":{"id":"0304","name":"Division of MATHEMATICAL SCIENCES","abbr":"DMS"},"pgm":{"id":"1271","name":"COMPUTATIONAL MATHEMATICS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0504","name":"Division of MICROELECTRONIC INFOR PROCESS","abbr":"MIP"},"pgm":{"id":"4720","name":"SIGNAL PROCESSING SYS PROGRAM"}}],"PIcoPI":["551879"],"PO":["565027"]},"72494":{"abstract":"This proposal was received in response to Nanoscale Science and Engineering initiative, NSF 01-157, category NIRT. It focuses on innovative approaches to nanoscale subsurface spin imaging, including three MRFM (magnetic resonance force microscopy) schemes and one novel non-mechanical spin sensing scheme using giant magnetoresistance (GMR) detection. A research team composed of a condensed matter physicist, a physical chemist, a materials scientist and a theoretical physicist will design and develop nanoscale probes for MRFM as well as MFM (magnetic force microcopy). Carbon nanotube and multi-photon absorption (MPA) fabricated polymer cantilevers, in linear and various forked geometries, will be employed for piezoresistive, optical waveguide and RF impedance detection of specimen spins, with anticipated sensitivities to the single spin level. Novel attogram-sized ferromagnetic nanorods will be synthesized and attached to the cantilevers for use as gradient generators\/spin probes. In addition to individual magnetic spin sensors, arrays of MRFM sensors will be made, with each sensor having an integrated three-dimensional radio frequency microcoil fabricated via MPA, facilitating spatial and temporal spin correlation measurements toward nanoscale functional MRI. <br\/> There is much to be gained by advancing spin-detection technology toward the single-spin level, with potential applications in information technology, medicine and scientific exploration. MRFM, which is developing into a most highly sensitive measurement technique, stands to play a major role in this goal. Molecular-scale devices, such as carbon and other types of nanotubes, will play an increasingly important role as well. To reach this goal, several impediments must be obviated, such as thermal noise, the spectral function of which defines a set of parameters to be optimized in the quest for single spin detection, 3-D molecular imaging, dynamic visualization and beyond. Another impediment is the traditional optical detection using visible light, the wavelength of which is larger than the required physical dimensions of the resonating magnetic sensor. The approaches of this program are designed to overcome these obstacles.<br\/> In addition to the four senior personnel, this interdisciplinary research program will involve numerous graduate students, undergraduates, and select high school students during summer months, covering a broad range of topics such as nanoscale magnetometry, micro and nanofabrication, carbon nanotube synthesis, multi-photon absorption, nanomagnet synthesis, and theoretical aspects of magnetism, nanotubes and semiconductors.","title":"NIRT: Nanoscale Magnetic Microscopy with Multi-Photon Absorption Polymers and Y-Junction Nanotubes","awardID":"0210533","effectiveDate":"2002-07-01","expirationDate":"2007-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0503","name":"Division of SHARED CYBERINFRASTRUCTURE","abbr":"SCI"},"pgm":{"id":"1710","name":"CONDENSED MATTER PHYSICS"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0701","name":"Division of ELECTRICAL, COMMUN & CYBER SYS","abbr":"ECCS"},"pgm":{"id":"1517","name":"ELECT, PHOTONICS, & MAG DEVICE"}}],"PIcoPI":["556968","366512","549790"],"PO":["508629"]},"75882":{"abstract":"The proposal requests travel expenses for US researchers to participate in a DELOS workshop on methods and metrics for evaluating digital libraries from a number of perspectives. The workshop will be held at MTA SZTAKI in Budapest, Hungary in June 2002. The workshop is co-organized by US and EC funded researchers. The workshop is part of a larger, coordinated planning and research activity being carried out by NSF-EU working groups. The findings of the working groups is expected to inform funding programs in the US, EU and other nations.<br\/><br\/>DELOS is a major forum for and organizer of digital libraries research and planning activities in Europe. It is funded by Information Societies Technologies (IST) 5th Framework Programme of the European Commission. This proposal seeks travel support for six participants from the American research community.","title":"Travel Support for Fourth DELOS Workshop on Evaluation of Digital Libraries","awardID":"0225626","effectiveDate":"2002-07-15","expirationDate":"2004-02-29","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6857","name":"DIGITAL LIBRARIES AND ARCHIVES"}}],"PIcoPI":["517365"],"PO":["433760"]},"72021":{"abstract":"Abstract:<br\/> As the recording technology further matures, more complex coding<br\/>algorithms for recording channels are challenging integrated circuit<br\/>manufacturing technology limits. The implementation of recent major<br\/>conceptual advances in coding theory, including iterative decoding,<br\/>codes on graphs as well as constrained codes, has been limited mainly by<br\/>the speed and recording density requirements of modern recording<br\/>systems. This research is developing coding schemes for<br\/>ultra-fast high-density recording systems that can lend themselves to<br\/>very low complexity implementations.<br\/> The focus of the research is the idea that good codes can be<br\/>constructed without using random interleavers or random sparse parity<br\/>check matrices. The constructions are based on combinatorial<br\/>designs and finite geometries. Such codes have a simple and well-defined<br\/>structure, which means lower decoder complexity. This approach also<br\/>offers a large flexibility in choosing code parameters. The fundamental<br\/>code construction issues addressed in this research include<br\/>understanding a structure of good codes and tradeoffs among code length,<br\/>rate and structure as well as matching a code to a partial response<br\/>channel. The second class of codes studied in this research are<br\/>constrained codes and graph constrained codes.","title":"Coding for Ultra-Fast High-Density Recording Systems","awardID":"0208597","effectiveDate":"2002-07-01","expirationDate":"2007-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4096","name":"COMMUNICATIONS RESEARCH"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4097","name":"NETWORKING RESEARCH"}}],"PIcoPI":["548044"],"PO":["348215"]},"72164":{"abstract":"This research concerns the use of simultaneous multithreaded (SMT) processors for soft real-time applications such as multimedia applications. SMT processors have the potential to provide high throughput by running multiple threads at the same time, and soft real-time applications are an<br\/>increasingly important workload. The use of SMT processors for real-time applications, however, has largely been unexplored.<br\/><br\/>Most work on SMT has been driven by the goal of increasing throughput. Real-time applications additionally require high schedulability (i.e., the ability to meet deadlines) and predictability. Further, such applications often run in energy and thermal power constrained environments. This work<br\/>seeks to develop co-schedule selection and resource sharing algorithms (and consequent admission tests) for SMT processors that will (1) maximize instruction throughput, (2) maximize schedulability, (3)<br\/>maximize execution time predictability, (4) minimize energy, and (5) minimize thermal power, for soft real-time applications such as multimedia applications. This is the first work that considers the issues of temporal schedulability and predictability, and integrates them with energy and thermal considerations, for real-time applications and SMT. Without this research, an increasingly important class of workloads would be unable to exploit an architectural advance that has provided large benefits in other domains.","title":"Using Simultaneous Multithreaded Processors for Soft Real-Time Applications","awardID":"0209198","effectiveDate":"2002-07-01","expirationDate":"2006-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4715","name":"COMPUTER SYSTEMS ARCHITECTURE"}}],"PIcoPI":["551063"],"PO":["325495"]},"72065":{"abstract":"Cyberlogic is a semantic foundation for implementing evidential<br\/>transactions using the public key infrastructure (PKI). Evidential<br\/>transactions form the basis of frameworks for authorization and<br\/>authentication, electronic commerce, business workflow, and digital<br\/>government. Such transactions involve the exchange of physical evidence<br\/>in the form of identity cards, driver's licenses, money, checks, visas,<br\/>airline tickets, traffic tickets, birth certificates, and stock<br\/>certificates, as well as electronic evidence including PIN numbers,<br\/>passwords, keys, certificates, and nonces. Cyberlogic is an enabling<br\/>foundation for building and analyzing protocols that involve the<br\/>exchange of electronic forms of evidence.<br\/><br\/>Cyberlogic builds on evidence, public keys, and protocols. First, evidence<br\/>is encoded by means of numbers using digital certificates and nonces.<br\/>Second, public keys are predicates so that any information $i$ signed by a<br\/>private key corresponding to the public key $P$ entails that $P$ holds of<br\/>$i$. Indeed, the signed certificate is a proof for the assertion contained<br\/>in the certificate. Third, protocols are distributed logic programs that<br\/>gather evidence by using both ordinary predicates and digital<br\/>certificates. These simple building blocks can be used to<br\/>construct a rich variety of services in a variety of domains<br\/>ranging from digital government to access control in computer systems.<br\/><br\/>The public key infrastructure (PKI) provides basic services for<br\/>encryption, authentication, trust, authorization, and digital<br\/>certificates. Cyberlogic is a protocol layer over the PKI that serves as<br\/>a reliable foundation for evidential transactions. It provides a<br\/>standardized semantic and computational infrastructure for exchanging<br\/>evidence in electronic form. With such a foundation, it is possible to<br\/>design secure electronic versions of transactions that currently require<br\/>physical forms of evidence.","title":"Cyberlogic","awardID":"0208779","effectiveDate":"2002-07-15","expirationDate":"2005-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2802","name":"TRUSTED COMPUTING"}}],"PIcoPI":["555363","226666"],"PO":["521752"]},"71097":{"abstract":"This project focuses on the physical layer of digital communication<br\/>system design - in particular on the design of graph-based error<br\/>control coding techniques for noisy, fading channels, such as those<br\/>encountered in wireless communication systems. The research<br\/>addresses those issues that have made practical implementation of<br\/>graph-based coding techniques problematic. Those issues include:<br\/><br\/>The development of LDPC and turbo codes with algebraic structure,<br\/>suitable for high speed implementation.<br\/>The development of LDPC and turbo codes with moderate block length,<br\/>suitable for practical real-time applications.<br\/>The design of bandwidth efficient coded modulation schemes<br\/>incorporating these new code constructions in order to \"fatten the<br\/>bit pipe\" in high data rate applications.<br\/>The adaptation of these new coding schemes for use in the fading<br\/>environment that characterizes wireless channels.","title":"ITR Collaborative Research: Toward Practical Graph-Based Coding Schemes For Reliable Wireless Communications","awardID":"0205310","effectiveDate":"2002-07-15","expirationDate":"2008-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1687","name":"ITR MEDIUM (GROUP) GRANTS"}}],"PIcoPI":["508186","40607","261593",184035],"PO":["564898"]},"67500":{"abstract":"The gap between microprocessor and memory system cycle times has been increasing over the past 15 years. In practice, because of the many levels in the memory hierarchy and interconnection busses between the processor and DRAM, a primary memory access may take 200 processor clock cycles from request to response; more than 50% of this latency is due to the memory hierarchy and interconnect. This research will focus upon the reduction of this fraction by novel interconnect techniques and increased<br\/>focus on the DRAM controller management policies. As the amount of state present in DRAM devices increases, the available set of memory controller policy decisions also increases; this increased flexibility allows an intelligent memory controller to optimize controller policies to achieve<br\/>increased performance. This research will examine the potential for improved performance when the memory controller changes from a static control policy to a dynamic control scheme. This impact will be simulated over a variety of interconnection topologies from the current NorthBridge to a CMP architecture with multiple DRAM busses.","title":"CAREER: Memory Controller Interconnect and Policy Determination","awardID":"0133777","effectiveDate":"2002-07-01","expirationDate":"2010-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4715","name":"COMPUTER SYSTEMS ARCHITECTURE"}}],"PIcoPI":["361223"],"PO":["559883"]},"79677":{"abstract":"The efficient digital representation of voice, still images, high quality audio, and video, called lossy source compression, has a host of commercial applications today. These applications include digital cellular telephones, MP3 players, DVDs, HDTV, videoconferencing, Internet telephony, and the transmission\/storage of still images. The best approaches to source compression in these applications are adaptive in nature and are based upon a technique called nonlinear approximation. However, these compression methods have been designed primarily based on experiments without any guiding theory. This research investigates a new approach to adaptive lossy source compression based upon a mathematical quantity called the spectral entropy. This new approach to source compression, denoted as the SpEnt (spectral entropy) method, offers a fundamentally sound approach to adaptive source compression that has been missing heretofore. This work develops SpEnt-based lossy compression methods for speech, video, and still images that should find applications in many commercial products.<br\/><br\/>The most successful methods for lossy source compression today are sample-function adaptive coders (also called input-by-input adaptive or realization-adaptive). In sample function adaptive coders, not only might the number of parameters transmitted in each block or frame vary from block-to-block (frame-to-frame), but for a given number of transmitted parameters, which parameters are transmitted in each block may vary. For such coders with a fixed set of basis functions, it is usually said that the coefficients corresponding to the best n basis functions are sent, rather than the first n, and this is called nonlinear approximation in harmonic analysis. Campbell derived the quantity that he called the coefficient rate of a random process in 1960, and he showed that the coefficient rate depends on the spectral entropy (the entropy of the power spectral density of the original process). No coding theorems were proved and no possible implications of coefficient rate for source compression were stated. Recent work by the PI and his students produced two new derivations of Campbell's coefficient rate. One derivation allows coefficient rate to be interpreted with respect to a quantity called the effective bandwidth of the process. The other derivation reveals a new approach to source compression based upon coefficient rate that adapts to each realization of the source. More specifically, by studying the dominant terms in the series expansion of the product of terms, it was shown that in a sequence of N samples of a particular coefficient, the number of coefficient samples that should be coded is proportional to the coefficient variances. Thus, whether a particular coefficient is being coded or not is changing from block-to-block, and thus, lossy compression based upon the spectral entropy clearly falls in the class of nonlinear approximation methods. Motivated by these results, this research formulates a new approach to lossy source compression, called the spectral entropy (SpEnt) method, and develops SpEnt based coders for lossy compression of wideband speech (50 Hz to 7 kHz), video, telephone bandwidth speech, and still images. Further, this work examines the role of spectral entropy and Campbell's coefficient rate as fundamental quantities in adaptive coding of a sequence of source realizations.","title":"Spectral Entropy and Adaptive, Lossy Source Coding","awardID":"0243332","effectiveDate":"2002-07-01","expirationDate":"2004-02-29","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4096","name":"COMMUNICATIONS RESEARCH"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4720","name":"SIGNAL PROCESSING SYS PROGRAM"}}],"PIcoPI":["410030"],"PO":["223414"]},"70680":{"abstract":"As integrated circuit chips are becoming more complex to design, pre-fabricated platform chips, intended to meet the needs of a wide variety of embedded computing products, are becoming increasingly <br\/>common. The trend towards platforms creates the need for parameterizing computing architectures such that platforms can have their performance and power consumption adapted to the different needs of different products, and that can be tuned to the particular compute patterns of a particular product. This project will investigate several aspects of such parameterization. It will demonstrate the feasibility of extensive parameterization of an architecture's memory components, key contributors to power and performance. It will define the basic tasks that make up platform-oriented CAD, partition computer-aided design (CAD) tasks between desktop and platform resources to yield fast yet accurate and<br\/>cost-effective CAD solutions, and develop new CAD exploration algorithms for desktop\/platform co-exploration. The research will benefit platform designers, who need an understanding of parameters and tuning issues to effectively build heavily parameterized platforms and their associated CAD tools, and platform users, who can utilize such platforms and CAD tools to develop more efficient platform-based designs than currently possible.","title":"Collaborative Research: Platform-Based CAD for Power and Performance Optimization","awardID":"0203829","effectiveDate":"2002-07-01","expirationDate":"2006-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4710","name":"DES AUTO FOR MICRO & NANO SYS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7352","name":"COMPUTING PROCESSES & ARTIFACT"}}],"PIcoPI":["450944"],"PO":["562984"]},"71692":{"abstract":"The proposal is to establish a US-EU\/DELOS working group on \"Digital Archiving and Preservation\". The working group will meet over the next year to discuss and evaluate fruitful joint activities and research paths for collaborative activities in this general topical area. The EU component of the effort is funded and managed by the DELOS Forum, a major organizer of digital libraries research and planning activities in Europe. DELOS receives support from the Information Societies Technologies (IST) 5th Framework Programme of the European Commission. <br\/><br\/>This effort continues the planning and assessment activities begun by an earlier NSF-EU working groups' process. In their final report \"An International Research Agenda for Digital Libraries\", delivered in Brussels in October 1998, increased levels of collaboration and interaction was seen as critical to building multi-lingual, multi-national digital libraries. The objective of the new working groups, of which this is one, is to define a research agenda on a specific topic and identify areas and activities for cooperation between EU and US researchers. The efforts of this particular group take the next step in the planning process by assessing future directions for research and resource development related to archiving and preservation of digital content.","title":"North American participation in the NSF-DELOS Working Group on Digital Archiving and Preservation.","awardID":"0207482","effectiveDate":"2002-07-15","expirationDate":"2003-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6857","name":"DIGITAL LIBRARIES AND ARCHIVES"}}],"PIcoPI":["471467"],"PO":["433760"]},"71120":{"abstract":"ITR: Beyond Polygons and Pixels: New Paradigms for Real-Time, Physically-Based Rendering<br\/><br\/>The ultimate goal of this research proposal is to provide real-time, physically accurate synthetic images, delivering breakthrough realism at fully interactive rates. We will achieve this by combining new approaches for parallel graphics rendering with advanced, feature-level psychophysical models of human vision and new image representations. <br\/><br\/>Currently, the two extremes of image synthesis are physically-based rendering, where accurate simulation of light reflection gives faithful predictions of the appearance of scenes, and real-time rendering, where crude approximations to accurate simulation are tolerated to provide dynamic imagery at interactive rates. High-quality, physically accurate images incorporating indirect lighting, inter-reflections between surfaces, and color bleeding can take hours or even days to compute on today's workstations, and incremental improvements to the speed of rendering will not be enough to bridge the gap. We estimate that real-time simulations of global illumination for complex scenes might require 10 7 times more processing power than we have on multi-processor workstations today. This can only be achieved by taking a radically different approach to how we generate, encode, and display synthetic images, an approach that separates computation by light reflection components and is based on advanced psychophysical models of human vision and new image representations.<br\/><br\/>Low-cost, efficiently pipelined graphics accelerator boards have become extremely popular, but these architectures only process local illumination components, and thus cannot provide global illumination effects or guarantee physical accuracy. To address this shortcoming, we have developed new algorithms that exploit the speed of these accelerator boards for direct lighting while performing global illumination computations in parallel on clusters of off-the-shelf Intel microprocessors. We have reduced computation times from hours to minutes for complex environments, but for real-time image synthesis we need another four orders of magnitude speed-up.<br\/><br\/>To reach this goal, we must develop more advanced models of human visual perception.<br\/>Current perceptually-driven rendering methods are based on threshold models of human vision that predict the limits of our abilities to discriminate luminance contrasts, spatial patterns, motions, and colors, but provide no guidance for optimizing the order or precision of rendering operations. For our new perception oracles, we are developing higher-level visual models to monitor the importance of scene features such as shadows and reflections to perceived image quality. These new models will then drive the allocation of parallel computing resources as well as select appropriate algorithms to provide the \"steepest ascent\" solutions. New data structures for pictorial representation will incorporate illumination and contrast gradients as well as pixel-by-pixel intensities to ensure optimal display of physically accurate and perceptually indistinguishable solutions under all viewing conditions. These capabilities will extend the scientific, educational, and commercial application of graphical simulations into visually critical tasks where predictive reliability and speed are paramount.","title":"ITR\/AP: Beyond Polygons and Pixels: New Paradigms for Real-Time, Physically-Based Rendering","awardID":"0205438","effectiveDate":"2002-07-01","expirationDate":"2009-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1687","name":"ITR MEDIUM (GROUP) GRANTS"}}],"PIcoPI":["429027",184119,"474957"],"PO":["565272"]},"72000":{"abstract":"Security protocols are notoriously difficult to design and prove correct. The goal of this project is to design a logic that deals with a number of deficiencies in current logics. The focus will be on two issues: <br\/><br\/>(1) Getting more realistic notions of knowledge: Informal arguments regarding the correctness of security protocols often involve statements about knowledge and belief. Assumptions such as \"The adversary does not know the key\" and \"The participants believe that k is a good session key\" are standard. The standard semantics for these operators has the problem that agents are able to deduce all logical tautologies and the logical consequences of their knowledge. Because agents \"know\" how to factor, for example, they can break RSA.<br\/><br\/>(2) Modeling more general intruders: Current logics almost invariably use the Dolev-Yao intruder model, which assume that an intruder can compose messages, replay them, or decipher them if she knows the right keys, but cannot otherwise \"crack\" encrypted messages. While useful, this model is restrictive, in that it does not consider the knowledge that agents have of the protocol being run and cannot deal with probabilistic arguments, such as an adversary randomly guessing the right key to use. <br\/><br\/>The research will take as its point of departure the standard models of knowledge and belief based on possible worlds, augmented with probability, so as to be able to reason about knowledge and probability. The notion of algorithmic knowledge, where an agent uses an algorithm to compute what it knows, will be used to deal with resource-bounded reasoning.","title":"Towards Improved Logics For Reasoning About Security","awardID":"0208535","effectiveDate":"2002-07-01","expirationDate":"2006-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2802","name":"TRUSTED COMPUTING"}}],"PIcoPI":["516488"],"PO":["521752"]},"71164":{"abstract":"This project brings together two disciplines, computer science and artificial intelligence on the one hand, and economics and game theory on the other, and by doing so addresses some fundamental problems of computing in the Internet era. Some of the problems addressed are rooted directly in today's Internet applications: How do you charge for network usage so as to smooth out peaks in the demand? How do you incent people to contribute personal information and recommendations in recommender systems and discretionary databases? While this project is motivated by its potential application to electronic commerce, the focus is on foundational matters. Computing in the Internet era means computing in the context of multiple self-interested entities, which in turn means that reasoning about computing must take the incentives of these entities into account. This, in turn, calls for a fundamental integration of ideas from computer science (such as fault tolerance, fairness, verification, algorithms, complexity, graphical models of uncertainty, machine learning) with elements of game theory (such as mechanism design, equilibrium analysis, game representations, learning, and agency theory). The outcome is expected to benefit electronic commerce, but also more fundamentally to help lay the foundations for a new area of research called \"non-cooperative computing.\"","title":"ITR: Non-Cooperative Computing: Foundational Problems at the Interface of Computer Science and Game Theory","awardID":"0205633","effectiveDate":"2002-07-15","expirationDate":"2010-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1687","name":"ITR MEDIUM (GROUP) GRANTS"}}],"PIcoPI":["409972","561961",184296,"437972"],"PO":["564456"]},"72385":{"abstract":"CCR-0210094<br\/>MacLennan, Bruce<br\/>NER: \"NER: Universally Programmable Intelligent Matter\"<br\/>Intelligent matter is any material in which individual molecules or supra-molecular clusters function as agents to accomplish some purpose. Intelligent matter may be solid, liquid or gaseous, although liquids and membranes are perhaps most typical. Universally programmable intelligent matter is made from a small set of molecular building blocks that are universal in the sense that they can be rearranged to accomplish any purpose that can be described by a computer program. In effect, a computer program controls the behavior of the material at the molecular level. In some applications the molecules self-assemble a desired nanostructure by \"computing\" the structure and then becoming inactive. In other applications the material remains active so that it can respond, at<br\/>the molecular level, to its environment or to other external conditions. An extreme case is when programmable supra-molecular clusters act as autonomous agents to achieve some end. Accomplishing the goals of universally programmable intelligent matter will require the identification of a small set of molecular building blocks that is computationally universal. The SK calculus (a kind of combinatory logic) is a formal system that demonstrates that such sets exist.<br\/>It is capable of universal computation, but makes use of only two simple operations on graphs, which are suggestive of molecular processes. Computer scientists have investigated the SK calculus extensively for several decades as a basis for massively parallel computer architectures, and the translation of high-level functional computer programs into SK structures is well understood. However, the SK calculus may not be the best choice for programmable intelligent matter. This exploratory research project has four principal objectives: (1) to develop a model of computation compatible with the constraints of molecular processes; (2) to identify at least two universal sets of building blocks for programmable intelligent matter; (3) to develop methods for interfacing<br\/>with additional molecular building blocks for sensing conditions and causing effects in the external environment; (4) to develop prototype simulation software to investigate characteristics peculiar to molecular computation.<br\/>Some of the methods are theoretical: (1) the construction of a mathematical model of computation compatible with the constraints of molecular processes, and (2) a mathematical investigation of the properties (such as computational universality) of some simple graph operations resulting in at least two universal sets of building blocks. The theoretical investigation will be supplemented by (3) the development of simulation software to investigate stochastic and other novel factors affecting computation in a molecular context, and (4) the use of the simulator to demonstrate the use of programmable intelligent matter to implement several useful nanostructures, such as nanotubes and membranes with active channels and cilia.<br\/>Since the resulting building blocks for universal programmable matter are expected to be individually simple and few in number, this project will provide the information needed by chemists to identify or synthesize the substances sufficient to implement universally programmable intelligent matter. This will open the way toward the ability to produce materials with a desired nanostructure and behavior as easily as we program computers today. This project will take a first step toward a systematic approach to nanotechnology that will failitate its rapid development.","title":"NER: Universally Programmable Intelligent Matter","awardID":"0210094","effectiveDate":"2002-07-01","expirationDate":"2004-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2878","name":"SPECIAL PROJECTS - CCF"}}],"PIcoPI":["521958"],"PO":["200829"]},"67512":{"abstract":"For the majority of its users, the Internet remains a best-effort network and provides no direct means for<br\/>meeting specific network Quality of Service (QoS) requirements of applications, such as fixed bandwidth<br\/>rates or bounds on propagation delay and loss rates. Most previous work that addressed improving QoS<br\/>capabilities of networks focused on mechanisms and techniques that require a combination of resource<br\/>reservation, admission control, and wide-scale modifications to the network and transport layers of the<br\/>protocol stack. These mechanisms and techniques are difficult to deploy in practice because a) they require<br\/>changes and new standards within already operational lower layers of the protocol stack and b) they restrict<br\/>competing sessions' access to basic network resources.<br\/> Recently, as an alternative, researchers and network practitioners have utilized distributed mechanisms<br\/>implemented within the network's application layer to compensate for the QoS limitations of the underly-ing<br\/>best-effort network infrastructure. These mechanisms provide services such as alternate path routing,<br\/>network-internal transcoding of data, content replication and caching that improve session quality. Communication of both data and state information between the network points that implement these distributed mechanisms is performed upon network overlays: virtual networks that directly connect these points to one another by tunneling transmissions across the underlying network.<br\/> The research described in this proposal develops and analyzes a Best-Effort QoS service for the wide-area<br\/>Internet. This service automates the procedure used by applications to draw upon these distributed<br\/>application layer mechanisms to improve the perceived quality and capabilities of the network. An application initiates the service by placing a specific QoS request at a network endpoint. A best effort is then made by the service to locate and instantiate the necessary distributed mechanisms to meet the QoS requirement. The service is best effort in that there is no reservation or admission control phase that restricts or denies other sessions' access to network resources. Hence, there is no guarantee that the QoS requirement will be met, nor is there a guarantee that once met, the requirement will be satisfied for the remainder of the session. The only guarantee is that as long as application layer resources can be located and effectively applied to meet the requirement, then the service will do so.<br\/> The work in this proposal will evaluate this service in three broad areas: (i) techniques for locating<br\/>available application layer resources, (ii) coordinated selection of these resources, and (iii) controlling how<br\/>competing applications share these resources. Our evaluation is performed mainly via mathematical analysis<br\/>and simulation upon a generic service. However, we also demonstrate the practicality of the service by<br\/>extending the analysis to two specific applications as well as developing and using a testbed for experimental<br\/>purposes.<br\/> The researcher's teaching efforts focus on the intertwining of analytical and experimental aspects of networking research. To this end, he proposes to develop courses in networking that (i) teach fundamental approaches to modeling and performance evaluation of networking systems, (ii) develop a wide-area classroom laboratory atop the Internet2 that can be used by students across the world to implement wide-area experiments, and (iii) teach students how to integrate experimental and theoretical approaches to networking issues.","title":"CAREER: Flexible, Large-Scale Best-Effort Quality of Service in the Internet","awardID":"0133829","effectiveDate":"2002-07-01","expirationDate":"2007-12-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"4095","name":"SPECIAL PROJECTS IN NET RESEAR"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"4097","name":"NETWORKING RESEARCH"}}],"PIcoPI":["522280"],"PO":["565090"]},"71781":{"abstract":"Microprocessor performance enhancements tend to be inefficient in terms of power, especially as new sources of performance become scarce. Yet, performance remains a key competitive factor in the microprocessor market and inefficiency is somewhat inevitable.<br\/><br\/> Microprocessors that support multiple frequencies are strategic because they can manage inefficiency. Performance requirements of systems change over time. Microprocessors with variable frequency can be used to balance performance, power, and energy by adapting frequency to changing performance requirements.<br\/><br\/> This project predicts that the need for variable frequency will have a profound impact on the way microprocessors are designed in the future. Current hardware support for variable frequency is predominantly circuit and technology oriented: dynamic voltage scaling accommodates higher or lower frequency by raising or lowering supply voltage, respectively. In the future, support for variable frequency should also be an integral part of microarchitecture design.<br\/><br\/> To demonstrate this overall vision, this project puts forth a novel microarchitecture called dynamic superpipelining (DSP). DSP switches from low to high frequencies by dynamically doubling the number of pipeline stages. DSP combines the advantages of two very different pipeline design styles (shallow and deep pipelines) that are optimized for different frequency targets. A flexible pipeline delivers better performance across a wider range of frequencies, ultimately improving the energy efficiency of the microprocessor. To evaluate DSP, it will be used as a variable-frequency substrate for a speculative frequency reduction technique recently proposed by the PI.","title":"Dynamic Superpipelining: Shaping Microarchitecture for Variable Frequency","awardID":"0207785","effectiveDate":"2002-07-01","expirationDate":"2006-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4715","name":"COMPUTER SYSTEMS ARCHITECTURE"}}],"PIcoPI":["518384"],"PO":["325495"]},"72001":{"abstract":"Innovative Programming Technology for Embedded Systems<br\/><br\/><br\/>This is a proposal to provide innovative programming technology for<br\/>designing and implementing reliable distributed embedded systems. The proposal<br\/>addresses a critical generic problem and a major opportunity. The generic<br\/>problem is that the research community does not know how to scale logical<br\/>methods that are known to improve programs and small systems to the task of<br\/>improving larger systems. The opportunity is that new methods of factoring are<br\/>possible for embedded systems, and new kinds of specifications are important.<br\/>This project approaches the problem\/opportunity by creating advanced logical<br\/>methods and tools to structure embedded systems in a new way and to draw on<br\/>relevant formal knowledge about them to accelerate both the design and coding<br\/>process and to improve the quality of the system code and its documentation.<br\/><br\/><br\/>The project will add extensive formal knowledge to a logical programming<br\/>environment (LPE) and use it to generate system components that are correct by<br\/>construction and to combine components based on semantic methods. The<br\/>semantics supports formal classes and aspect-oriented programming. One test<br\/>case for the new methods is a particular distributed embedded system called<br\/>MediaNet -- a system for processing various media (audio, video, text) over a<br\/>distributed computing network to adaptively respond to quality of service<br\/>constraints.<br\/><br\/>The project will use mathematical knowledge about media streams and transition<br\/>systems to precisely formulate design requirements and component functionality.<br\/>Quality of service constraints will be incrementally added to the functional<br\/>specifications and used to automatically modify the proof and the extracted<br\/>code so that these requirements are met. This is a very high level example of<br\/>formal aspect-oriented programming and proof reuse.<br\/><br\/>The library of formal knowledge about the system will be organized as a<br\/>mathematical theory. That organization draws on concepts about stream<br\/>transformers, the distributed network of machines, quality of service<br\/>properties and communication services. An expressive logic will be used to<br\/>state properties of the system and keep track of logical dependencies among<br\/>system components.<br\/><br\/>The project team has considerable experience working together building and<br\/>supporting distributed communications systems by specifying and verifying<br\/>communication protocols and optimizing them using formal methods.","title":"Innovative Programming Technology for Embedded Systems","awardID":"0208536","effectiveDate":"2002-07-01","expirationDate":"2005-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2801","name":"EMBEDDED & HYBRID SYSTEMS(EHS)"}}],"PIcoPI":["531903",186454],"PO":["561889"]},"75631":{"abstract":"EIA 02-24439<br\/>Grunwald, Dirk C.<br\/>University of Colorado<br\/><br\/>Title:CISE RR: Instrumentation Support for Very Large Data Stores <br\/><br\/>This proposal, designing a system using Massive Arrays of Idle Disks (MAID) as a replacement for data centers that would normally use tape archives, will utilize infrastructure in the design and fabrication of an alternative design to conventional mass storage systems that attempt to address critical data center issues such as data density (i.e., reduced floor space), reliability, power efficiency, and manageability. Using a combination of commodity disk drives, power management, distributed control, and caching hierarchy, the researcher claims that the MAID storage organization provides storage densities matching or exceeding those of tape libraries with performances similar to disk arrays. Studies have shown that through a combination of effective power management of individual drives and caching, this performance can be achieved using a very small power envelope. The large backing store will be composed of inexpensive IDE disks that, rather than spinning, are allowed to go idle when not in use. The main goal consists of replacing conventional tape archival storage with an alternative technology at significantly reduced power cost. The experimental testbed consists of 120 IDE drives, each of which holds 160GB of data for a total of 19.2TB of online storage, of which approximately 160TB would be available once redundancy is addressed. The infrastructure also includes 120 drive enclosures that connect commodity IDE drives to 1394 (firewire) I\/O networks.","title":"CISE Research Resources: Instrumentation Support for Very Large Data Stores","awardID":"0224439","effectiveDate":"2002-07-15","expirationDate":"2004-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2890","name":"CISE RESEARCH RESOURCES"}}],"PIcoPI":["543625"],"PO":["309350"]},"72034":{"abstract":"Providing assurance of security and privacy is becoming more difficult with current trends towards building computing infrastructure out of distributed components connected by networks, including untrusted client machines. Important to this assurance are the confidentiality and integrity properties of distributed systems that serve principals whose trust in each other is incomplete. This description encompasses, among others, clinical information systems, joint military information<br\/>systems, and financial information systems.<br\/><br\/>A new security mechanism, secure program partitioning, can provide stronger, end-to-end assurance that data remains confidential. In this approach, programs are transformed according to strong security<br\/>policies, resulting in secure distributed systems. This is an attractive way to specify and enforce confidentiality and integrity in environments that include untrusted, possibly malicious host machines.<br\/><br\/>Because the integrity of distributed computations and data is difficult to maintain in the presence of untrusted hosts, this research investigates an extension of secure program partitioning to use<br\/>redundant computation to preserve integrity. In addition, new models of information flow in concurrent systems are being explored because the current theory and practice of security for concurrent systems is<br\/>restrictive, yet also unsound. This is especially important because distributed systems are naturally concurrent. Solutions to these problems are being implemented as part of the Jif language system.","title":"End-to-end Integrity and Confidentiality for Distributed Systems","awardID":"0208642","effectiveDate":"2002-07-15","expirationDate":"2005-12-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2802","name":"TRUSTED COMPUTING"}}],"PIcoPI":["555502"],"PO":["521752"]},"72045":{"abstract":"ABSTRACT<br\/>0208678<br\/>Xiaolin Wu and Nasir Memon<br\/>Polytechnic Univ of NY<br\/><br\/>An Algorithmic Study of Optimal Multiresolution Quantization and Joint Source-Channel Coding<br\/><br\/>In this research project the investigators will develop algorithms to improve service quality of video and audio streaming over switched networks, wired or wireless, in adverse network conditions such as congestion, delay, and packet loss. The idea is to have graceful degradation in quality of service rather than outright stoppage of audio and video playback, when the effective transmission rate drops. This will significantly enrich users' experience with IP-based multimedia services.<br\/><br\/>The research consists of two inter-connected studies: optimal multiresolution (progressively refinable) quantization (MRQ), and uneven error-protected packetization (UEPP) of scalable source code streams generated by MRQ. The investigators' main objective is to develop efficient algorithms for optimal MRQ design, and for optimal bit allocation between scalable source codes of MRQ and forward error correction codes. Their approach differs from the existing rich body of literature on joint source-channel coding and on MRQ in that the problem is treated as one of combinatorial optimization, rather than resorting to continuous Lagrangian optimization. The investigators will classify various optimization problems related to MRQ design and joint source-channel coding by their innate computational tractability, and develop either globally optimal algorithms for those that are solvable in polynomial time, or heuristic algorithms for those that are NP-hard. In order to obtain efficient algorithms for MRQ and UEPP, discrete structures of the underlying objective functions of optimization will be explored, which in turn may offer new insights into these problems of increasing interest and immediate relevance to internet and wireless communications.","title":"An Algorithmic Study of Optimal Multiresolution Quantization and Joint Source-Channel Coding","awardID":"0208678","effectiveDate":"2002-07-15","expirationDate":"2005-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4720","name":"SIGNAL PROCESSING SYS PROGRAM"}}],"PIcoPI":["559652",186568],"PO":["564898"]},"75389":{"abstract":"The project plans to solve two important network problems facing distributed computation and Grids. The first problem is to provide a sufficiently flexible and robust framework for authentication and authorization, and the second problem is to provide secure mechanisms to allow researchers to upload new or enhanced measurement tools in a secure and trustworthy fashion. Building on the National Internet Measurement Infrastructure (NIMI), the project plans to evolve NIMI to a truly large scale implementation. Work involves migrating messaging, authentication and authorization to commonly used components, and mitigating some of the security problems associated with uploading measurement tools by building fine-grained delegation support and different levels of security. These structures can be used for various forms of distributed passive monitoring and security monitoring such as intrusion detection systems.<br\/><br\/>The NIMI architecture will be extended to support open large-scale grid technologies. The overall vision is to encourage researchers, especially grid-proejcts, to build clients which will interact with the NIMI infrastructure. The infrastructure can then be used for secure, flexible command and control mechanisms, and also be sued for distributed passive monitoring.","title":"An Open Infrastructure for Network Performance and Security Monitoring","awardID":"0222846","effectiveDate":"2002-07-01","expirationDate":"2005-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"4089","name":"NETWORK CENTRIC MIDDLEWARE SVC"}}],"PIcoPI":["562327",196080],"PO":["250082"]},"67326":{"abstract":"This is a Faculty Early Career Development (CAREER) award. The research will develop speech recognition and auditory scene analysis models that are probability distributions whose parameters can be trained from data and whose internal structures are capable of abstracting the perceptual response patterns of human listeners. Two broad research questions will be explored: (1) Can probability models representing the pitch, envelope, and timing of an acoustic source be computed and integrated in a tractable manner? (2) What are the theoretical and empirical requirements for the partitioning, training, and recognition scoring of probability models for landmark-based acoustic features? Landmarks in speech are identifiable points in the flow of sound over time, such as consonant releases and closures, vowel centers, and glide extrema. The educational component of this project includes significant curriculum development at both the undergraduate and graduate levels, and a strong investment in the mentoring of undergraduate and graduate research trainees.<br\/><br\/>This CAREER award recognizes and supports the early career-development activities of a teacher-scholar who is likely to become an academic leader of the twenty-first century. This is fundamental scientific research in acoustics and computer science, but it addresses the very practical problem that computers are still far worse at recognizing speech than human beings are. Speech recognition technology has already become an important industry, but it will become far more important in the future as mobile computing and computer-mediated communications make it necessary for millions of people to control machines verbally rather than by means of keyboards. The educational component of this work will train graduate students to be teachers and communicators, as well as researchers, thus preparing them to help build the base of personnel needed in this exciting, growing area.","title":"CAREER: Landmark-Based Speech Recognition in Music and Speech Backgrounds","awardID":"0132900","effectiveDate":"2002-07-01","expirationDate":"2008-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6845","name":"HUMAN COMPUTER INTER PROGRAM"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7274","name":"HUMAN LANGUAGE & COMMUNICATION"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7484","name":"IIS SPECIAL PROJECTS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":["426305"],"PO":["565227"]},"67447":{"abstract":"DSP-Enhanced Low-Voltage Signal Processing in Submicron CMOS<br\/><br\/>Today's electronic systems are strongly influenced by the dramatic advancement of submicron complementary metal-oxide-silicon (CMOS) integrated circuits (IC) technology as the size of transistors shrink to extreme dimensions. Because of the shrinking size of transistors, the digital signal processing (DSP) power and efficiency of digital computation grow exponentially; however, the equally decreasing operating voltage of the transistors leads to design problems for mixed analog-digital circuits which are part of all digital processors. By taking advantage of the CMOS down-scaling trend that increases DSP capability, this research combines the developmental efforts in both low-voltage analog circuit techniques and optimum architectures for DSP enhancements. This research systematically explores various architectures, develops and compares<br\/>adaptive algorithms and digital correction techniques, studies the effects of analog imperfections in deep submicron CMOS, and obtains the fundamental limits of digital compensation and calibration.<br\/><br\/>In this research, two IC design methods are created and expanded to overcome the analog\/mixed-signal design challenges of very deep submicron CMOS technologies. The first explores new architectures and techniques capable of maximizing the power of DSP for enhancing analog and mixed-signal circuit performance, including DSP-enabling architectures, use of multi-signal paths and taking advantage of inherent structures for error estimation, and merged system calibration of multi-stage architectures. The second explores new analog circuit design techniques for ultra low-voltage operation that is fully compatible with submicron CMOS, focusing on fast low-voltage switching schemes, analog-error insensitive and DSP-corrected low-voltage structures, and linear low-voltage input sampling circuits.","title":"CAREER: DSP-Enhanced Low-Voltage Signal Processing in Submicron CMOS","awardID":"0133530","effectiveDate":"2002-07-01","expirationDate":"2007-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4720","name":"SIGNAL PROCESSING SYS PROGRAM"}}],"PIcoPI":["492228"],"PO":["564898"]},"71881":{"abstract":"This project aims at developing a suite of multiuser diversity driven algorithms for packet scheduling and localized routing, and to obtain some overriding principles in multimedia wireless systems. In particular, the issues of hierarchical multiuser diversity (HMD) driven downlink and uplink access schemes for multimedia traffic will be studied. The objective related to HMD driven downlink access schemes is to devise efficient packet transmission schemes for the downlink, exploiting multiuser diversity gain in a multiuser wireless system. Specifically, the proposal addresses such an HMD scheme in which each user can choose either a direct transmission mode or a relay transmission mode. Treating delay tolerance as a network resource, the HMD-driven scheduling for both direct trans-mission and relay transmission is then explored for both single-cell setting and cellular networks. Also the localized routing algorithms will be developed for both slowly fading channels and fast fading channels, due to mobility. In the part of the project related to based on code division multiple access (CDMA\/HMD) uplink access schemes, the pro-ject will include studies of access schemes taking into account explicitly the delay con-straints of different multimedia traffic, with particular focus on the uplink. Since the up-link is a multi-access channel, the multiuser diversity will be explored in the context of CDMA. In particular, the number of simultaneous transmissions will be optimized, based on the channel conditions across the users. The project will also address the critical issues related to the buffering, jitter, fairness and possible loss due to switching to a new relay. Finally, the trade-off between HMD and CDMA will be studied, with the aim at develop-ing a hybrid scheme that achieves multiuser diversity gain and guarantee the user's minimal throughput requirement as the same time.","title":"CDMA\/HMD (Hierarchical Multiuser Diversity) Access Schemes for Multimedia Wireless Networks","awardID":"0208135","effectiveDate":"2002-07-01","expirationDate":"2006-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"4097","name":"NETWORKING RESEARCH"}}],"PIcoPI":["518327"],"PO":["565090"]},"70671":{"abstract":"The goal of this project is to develop parallel algorithms and a parallel software system for clustering Expressed Sequence Tags (ESTs). ESTs are derived from fragments of reverse transcribed mRNA isolated experimentally and thus directly correspond to protein coding genes. The proposed project is aimed at overcoming the computational limitations of current software systems such as inability to handle large data sets within reasonable time and memory resources. This project will provide a strong context for fundamental research in practical parallel string algorithms, including the development of parallel algorithms for constructing suffix trees and suffix arrays, applications involving suffix trees and arrays such as containment and overlap detection. Particular emphasis will be placed on the design of space-efficient algorithms because space-complexity often determines whether the use of an algorithm is feasible for large data sets. The software will be validated using large EST data sets from organisms with small and known genomes, which will be exploited to derive correct clustering though alternate methods. The algorithms developed will provide the basis for other similar projects including protein repertoire comparisons and testing of biological hypotheses such as exon shuffling and gene duplication. The human EST collection at the National Institute of Health currently has over 3.8 million ESTs and parallel processing is essential for discovering biologically useful information from such large EST collections.<br\/><br\/>Throughout the project, emphasis will be placed on design of parallel algorithms using realistic models of parallel computation, rigorous proofs of optimality with respect to best known sequential algorithms, careful evaluation of the communication complexity and the constants involved in asymptotic run-time estimates, and development of user-friendly software. Experimental evaluation of the algorithms will be carried out both on conventional tightly-coupled parallel computers and clusters. The project will be carried out by an interdisciplinary team of researchers having the required expertise in parallel algorithm design, building large parallel software systems, bioinformatics and life sciences. To further ensure the success of this project, collaborations have been established with researchers from the University of Bielefeld and the National Institute of Health.","title":"ALGORITHMS: Parallel Algorithms and Software for EST Clustering","awardID":"0203782","effectiveDate":"2002-07-01","expirationDate":"2004-12-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4080","name":"ADVANCED COMP RESEARCH PROGRAM"}}],"PIcoPI":[182948,"565135","526244"],"PO":["551992"]},"72112":{"abstract":"The GRIDLOCK hypothesis is that use of a globally specified and locally interpreted policy language for specification of access-control policy can provide a new, unified approach to securing network applications. In particular, this approach can be used to specify network access-control policies and host access-control policies in combination to provide \"virtual private services.\" GRIDLOCK simultaneously provides more security to applications, greater scalability, and unification of network access control and host access control. Policies are specified in a new policy-expression language, modeled on the KeyNote trust-management language. This design supports compliance checking, with which credentials provided by a client can be validated to provide access to a resource. The applicability of this layer-crossing approach to multiple virtual private services is investigated.<br\/><br\/>The research focuses on the development of formal semantics for the unified access-control policy, as well as a rigorous experimental investigation, using multiple example applications. The expected results include both the new policy-expression language and the demonstration that a scalable access-control model for networked applications is practical.","title":"GRIDLOCK: A New Scalable Approach to Unifying Computer and Communications Security","awardID":"0208972","effectiveDate":"2002-07-15","expirationDate":"2006-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2802","name":"TRUSTED COMPUTING"}}],"PIcoPI":["450982","564223","527253"],"PO":["521752"]},"72013":{"abstract":"Computational information theory is concerned with techniques (such as<br\/>channel coding) for achieving channel capacities. The field has<br\/>achieved dramatic scientific breakthroughs in recent years, and codes<br\/>that come close to theoretical limits have been discovered. Today,<br\/>the development of coding and information theory is closely related to<br\/>the explosion of information technology, with applications to the<br\/>Internet and the next generation of networks technologies. The rapid<br\/>development of a myriad of networked devices for computing and<br\/>telecommunications presents new and exciting challenges for coding and<br\/>information theory. <br\/><br\/>This project will explore interconnections among coding theory,<br\/>theoretical computer science, information theory, and related areas of<br\/>computer science and mathematics in order to deal with research<br\/>challenges arising from optical\/magnetic recording and optical<br\/>transmission, the interface between information theory and symbolic<br\/>dynamics, the development of network information theory, advances in<br\/>high speed data transmission in wired channels, the connection between<br\/>coding theory and related mathematical approaches (especially using<br\/>discrete mathematics), the role of compression in all layers of data<br\/>networks, and exploiting the connections between algorithmic<br\/>complexity and notions of entropy and randomness.<br\/><br\/>Research efforts will be carried out by ``working groups'' that will<br\/>come together at DIMACS for several meetings aimed at catalyzing<br\/>communications and collaborations. Subgroups will investigate problems<br\/>of interest. The working groups will be concerned with Data<br\/>Compression in Networks and Applications and with Optical\/Magnetic<br\/>Recording and Optical Transmission.<br\/><br\/>The project will integrate research and education through a series of<br\/>workshops aimed at identifying areas for research, involving large<br\/>groups of researchers in the field of computational information theory<br\/>and coding, and introducing many people (including outstanding junior<br\/>people and students) to the field. Workshops are<br\/>planned on the topics of High Speed Data Transmission in Wired<br\/>Channels, Network Information Theory, Complexity and Inference,<br\/>Information Theory and Symbolic Dynamics, and Coding Theory and<br\/>Discrete Mathematics.","title":"Computational Information Theory and Coding","awardID":"0208577","effectiveDate":"2002-07-01","expirationDate":"2005-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4096","name":"COMMUNICATIONS RESEARCH"}}],"PIcoPI":["264120"],"PO":["348215"]},"72024":{"abstract":"The proposed research contributes to the development of autonomous agents capable of operating in real world situations. Agents in multi-agent environments must often choose between maximizing their expected utility according to their current knowledge, and trying to learn more about the world and thereby increase their gains. A negotiator may try to obtain information about its options by asking outside sources, taking actions, or by making offers and counter offers. In order to find the best negotiation strategy, agents' decision-making processes will be modeled. This research will lead the automated agent to reach more beneficial agreements when negotiating with bounded rational agents (human or automated). Strategies and decision-making procedures will be tested in the domains of e-commerce and international crises. The significance of the research lies first in the evaluation of alternate strategies for the acquisition of information by self-interested agents, from the perspective of a fully automated environment, and also by evaluating the behavior of automated agents interacting with human actors in simulated decision making environments. The dynamics of information acquisition in complex decision making structures will be better understood. The research will also contribute to the better understanding of decision making when automated negotiators interact with bounded rational agents.","title":"Information acquisition as a factor in improving agent performance in negotiation and decision making","awardID":"0208608","effectiveDate":"2002-07-01","expirationDate":"2006-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6850","name":"DIGITAL SOCIETY&TECHNOLOGIES"}}],"PIcoPI":["379377","333993"],"PO":["564456"]},"66711":{"abstract":"EIA-0129978<br\/>Catherine Plaisant<br\/>Ben Shneiderman<br\/>University of Maryland Baltimore County<br\/><br\/>Digital Government: Collaborative Research: Integration of Data and Interfaces to Enhance Human Understanding of Government Statistics - Toward the National Statistical Knowledge Network<br\/><br\/>This award will support collaborative research with several Federal statistical agencies to develop better statistical data models, to explore the use of SML, to develop better map-querying tools and to integrate other available tools for manipulating, browsing and visualizing tabular data. The goal is to develop better human\/computer interfaces for expert users to novices, to increase general statistical literacy, and to provide seamless access to data held by multiple Federal agencies and agencies at other levels of government, in particular state and local data.","title":"Digital Govt. Collaborative Research: Integration of Data and Interfaces to Enhance Human Understanding of Government Statistics: Toward the National Statistical Knowledge Network","awardID":"0129978","effectiveDate":"2002-07-01","expirationDate":"2006-12-31","fundingAgent":[{"dir":{"id":"04","name":"Directorate for DIRECT FOR SOCIAL, BEHAV & ECONOMIC SCIE","abbr":"SBE"},"div":{"id":"0403","name":"Division of SCIENCE RESOURCES","abbr":"NCSE"},"pgm":{"id":"8806","name":"INFO & TECHNOLOGY SVCES PRGM"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1706","name":"DIGITAL GOVERNMENT"}}],"PIcoPI":["527292","440679"],"PO":["371077"]},"72068":{"abstract":"Mixing in turbulent flows play an essential role in diverse engineering<br\/>applications. Beneficial non-equilibrium dynamics impact on engine<br\/>efficiency, durability, stability, and emissions, on reduced drag in<br\/>aircrafts and in naval vessels. The unique focus of this research is on<br\/>feedback regulation of active mixing control. Technical challenges are<br\/>an outgrowth of the complexity and sensitivity of fluid dynamic systems,<br\/>and require an integrated approach to modeling, information technology,<br\/>control theory, algorithm development, and software and hardware<br\/>implementation. Modeling will focus on dominant coherent structures,<br\/>periodicity, and concepts of Hamiltonian energy. Those provide also<br\/>possibilities for efficient parallel implementation on an embedded<br\/>system. Intended models will range from lumped point vortex models, to<br\/>purely phenomenologically derived I\/O correlations of main structures.<br\/>Hybrid models arise naturally as a design framework, subject to (nearly)<br\/>periodic vortex generation and elimination. On a finer time scale,<br\/>hybrid models will be used as a means to parallelize spatially<br\/>distributed control and observer implementation. This project includes<br\/>collaborations with industry, government and academe. If successful,<br\/>this high risk-high yield undertaking will include both technology<br\/>transition in critical applications and developments of integrated<br\/>embedded systems and control design methods for interesting classes of<br\/>complex, nonlinear systems.","title":"Embedded Systems for Feedback Mixing Control in Fluid Flow","awardID":"0208791","effectiveDate":"2002-07-01","expirationDate":"2005-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2801","name":"EMBEDDED & HYBRID SYSTEMS(EHS)"}}],"PIcoPI":["557274","284682"],"PO":["561889"]},"71640":{"abstract":"Current intrusion detection systems (IDSs) usually generate many false alerts and often do not detect novel attacks or variations of known attacks. Moreover, most existing IDSs focus on low-level attacks or<br\/>anomalies; none capture the logical steps or strategies behind these attacks. In situations where there are intensive intrusions, not only will actual alerts be mixed with false alerts, but the number of<br\/>alerts will also become unmanageable. As a result, it is difficult for human users or intrusion response systems to understand the nature of the attack and to take appropriate actions.<br\/><br\/>To address these issues, this project will investigate techniques to correlate intrusion alerts on the basis of the prerequisites and consequences of attacks. The research uses a formal and rigorous<br\/>approach to study the fundamental issues involved in alert correlation, including representation of prerequisites and consequences of attacks, efficient algorithms to process alerts, expressiveness of the high-level representation mechanisms, effectiveness of the technique in reducing false alerts, impact of<br\/>false alerts and undetected attacks on the technique, and methods to predict attacks in progress. Expected impacts of the proposed research include (1) a reduction in the number of false alerts, (2) <br\/>identification of attackers' high-level strategies, and (3) early configuration of effective defenses against attacks in progress. If successful, the research will lead to better tools for intrusion<br\/>detection and thus to improved computer and network security.","title":"Reduce False Alerts, Uncover High-Level Attack Strategies and Predict Attacks in Progress Using Prerequisites of Intrusions","awardID":"0207297","effectiveDate":"2002-07-01","expirationDate":"2006-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2802","name":"TRUSTED COMPUTING"}}],"PIcoPI":["548079","553866"],"PO":["521752"]},"71651":{"abstract":"EIA 0207338 <br\/>Roberts, Fred<br\/>Rutgers University<br\/><br\/>TITLE: Satellite Reconnect Project<br\/><br\/>This Satellite Reconnect Project is designed to \"reconnect\" to the computer science and mathematics research enterprise, two-year and four-year college faculty who have not had opportunities to keep up with new research developments. It aims to reinvigorate their careers and enhance their teaching by exposing them to current research topics in computer science and related mathematics that are relevant to the undergraduate classroom. This is being accomplished initially through a series of summer conferences at DIMACS, the Center for Discrete Mathematics and Theoretical Computer Science, at Rutgers University. As part of the conferences, participants prepare written classroom materials based on current research topics and have the opportunity to publish them in the DIMACS Educational Modules Series. Concurrently, the basic program conference structure is being replicated at six selected satellite locations around the country, generally with different research topics, but under DIMACS guidance and leadership. Through this mechanism, the project aims to establish a community of individuals and institutions with expertise in and commitment to this type of \"Reconnect\" project and concept. The satellite activities are supplemented with an effort to disseminate the model to the wider community so that this type of program can be copied at numerous other locations around the country.","title":"Special Project: Satellite Reconnect Project","awardID":"0207338","effectiveDate":"2002-07-15","expirationDate":"2007-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1713","name":"WORKFORCE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}},{"dir":{"id":"11","name":"Directorate for DIRECT FOR EDUCATION AND HUMAN RESOURCES","abbr":"EHR"},"div":{"id":"1106","name":"Division of HUMAN RESOURCE DEVELOPMENT","abbr":"HRD"},"pgm":{"id":"1260","name":"INFRASTRUCTURE PROGRAM"}}],"PIcoPI":["264120"],"PO":["564181"]},"72410":{"abstract":"David Lilja<br\/>U Minnesota<br\/>0210197<br\/><br\/>Recent work in physics, chemistry, and materials science has<br\/>produced nanometer-scale structures out of exotic materials using<br\/>sophisticated fabrication techniques. However, very little work has<br\/>been conducted in computer engineering to investigate how to build<br\/>full-scale computer systems out of these new devices.<br\/><br\/>The goal of this exploratory project is to begin to develop new<br\/>techniques for constructing finite state machines (FSMs) out of<br\/>molecular nanodevices. FSMs are one of the fundamental building<br\/>blocks of any digital computing system. In this project, we<br\/>introduce NanoBoxes as a possible abstraction for constructing<br\/>reliable finite state machines for use in molecular computer<br\/>systems.<br\/><br\/>The reliability and error characteristics of molecular nanodevices<br\/>are substantially different from the corresponding characteristics<br\/>of traditional silicon-based CMOS transistors. These nanodevice<br\/>characteristics present new challenges to computer designers which<br\/>will require an entirely new approach for designing finite state<br\/>machines. The techniques we develop eventually could be used to<br\/>build entire computer systems out of molecular nanodevices.<br\/><br\/>This is a high-risk\/high-reward project. The risk is that we need<br\/>to develop new approaches for designing computers out of a large<br\/>collection of devices which are still under development themselves.<br\/>By observing common trends in newly developed molecular devices, we<br\/>make assumptions about their weak drive capabilities and their<br\/>unstable nature. While we expect that we can adapt and extend<br\/>traditional space, time, and information redundancy techniques for<br\/>fault-tolerance into this new domain of molecular computers, new<br\/>ideas will be necessary to develop appropriate solutions.<br\/><br\/>This project is high-reward, however, since by conducting computer<br\/>architecture research in tandem with research on the nanodevices<br\/>themselves, we will be streamlining the development process to be<br\/>able to have fully-functional molecular computers more quickly than<br\/>if we wait for the nanodevice research to solidify. Furthermore,<br\/>while we are tailoring our techniques for molecular nanodevices, our<br\/>techniques also will be applicable to error detection and correction<br\/>in quantum nanodevices and in nanometer-scale conventional CMOS<br\/>devices, which are becoming more fault-prone as transistor sizes<br\/>shrink.<br\/><br\/>This project will make substantial contributions to educational and<br\/>human resource development. It will initiate the dissertation<br\/>research of a Ph.D. student in electrical and computer engineering<br\/>to focus their research in this new area. We also expect to involve<br\/>a few M.S. students in this work and possibly provide research<br\/>opportunities for undergraduate students through existing internship<br\/>programs at the University of Minnesota.","title":"NER: Designing Reliable Computers Using Molecular Nanotechnology","awardID":"0210197","effectiveDate":"2002-07-01","expirationDate":"2004-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2878","name":"SPECIAL PROJECTS - CCF"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0702","name":"Division of CHEM, BIOENG, ENV, &  TRANSP S","abbr":"CBET"},"pgm":{"id":"1517","name":"ELECT, PHOTONICS, & MAG DEVICE"}}],"PIcoPI":["528635","244108"],"PO":["562984"]},"70474":{"abstract":"This project aims at studying problems fundamental in cellular networks and specifically related to the call admission control schemes. Efficient call admission control schemes provide the users with access to wireless networks and at the same time are crucial for network operators in guaranteeing services and operating efficiently. In this three-year project, the following research activities will be particularly pursued. First, a novel call admission control algorithms for signal-to-interference ratio (SIR) based power-controlled direct sequence code division multiple access (DS-CDMA) cellular networks that provide multiple classes of services will be developed. When a new call (or a handoff call) arriving at a base station requesting for admission, the new, desired, power level for that new call as well as the power levels for all existing calls will be calculated. These calculations are based on the interference received at the base station and the desired quality of service target (i.e., the desired SIR) for each call. In the case of a higher priority calls, e.g. handoff calls, different thresholds for new calls and handoff calls can be allowed. The research within this project will particularly focus on the admission control decision based on a computationally tractable calculation of the target power level, which would avoid the iterative process of power control for determination of the required power levels for all users. Finally, power control algorithms with vigorous theoretical results regarding stability, convergence, and feasibility of solutions will also be studied for the best applicability in future cellular networks. This project will include graduate and undergraduate students in research and will be conducted as means of creating awareness and interest among students on the issues surrounding wireless networks.","title":"Power Control and Call Admission Policies for Multiclass Traffic in SIR-Based Power-Controlled DS-CDMA Cellular Networks","awardID":"0203063","effectiveDate":"2002-07-01","expirationDate":"2005-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"4097","name":"NETWORKING RESEARCH"}}],"PIcoPI":["456536"],"PO":["565090"]},"72432":{"abstract":"Engineering of InAs Quantum Dot Ensembles Using Interference of Optical<br\/>Surface Waves<br\/><br\/>This project addresses the problem of inhomogeneous broadening of the size<br\/>distribution of quantum dot (QD) epitaxial semiconductor ensembles formed<br\/>via a stress-driven Volmer-Weber or Stranski-Krastanov growth mechanism. The<br\/>uniformity and narrow size distribution of the QDs are the major challenges<br\/>for the utilization of QD structures in optoelectronic devices. The primary<br\/>goal of this proposal is to evaluate the feasibility of nanoscale control of<br\/>the nucleation process of InAs QDs on a GaAs surface using the interference<br\/>of the optical surface waves. The interference pattern will be generated on<br\/>the surface of the substrate using a pulsed UV laser during the growth of<br\/>QDs by molecular beam epitaxy (MBE). The pattern, with a typical period of<br\/>few hundred nm, will be created using two different optical schemes based<br\/>on: (i) the interference of the incident wave with the scattered coherent<br\/>surface wave; and (ii) the interference of the incident waves with two<br\/>surface waves coupled to the split laser beams. The optical interference<br\/>pattern will modulate periodically the surface properties of the substrate<br\/>at 100-200 nm level. The nucleation of QDs will be controlled through either<br\/>substrate temperature modulation, thereby destroying the nucleation clusters<br\/>in the antinode of the standing wave pattern, or through undulation of the<br\/>surface by laser ablation to control the surface energy. The 100-nm<br\/>modulation scale is expected to form a template for initial QD nucleation,<br\/>and the subsequent evolution of the QD ensemble will be driven<br\/>thermodynamically towards higher density of dots, (3-10)e10 cm-2. The<br\/>important features of the in-situ optical impact are that it does not leave<br\/>any residues on the surface, can be conducted during the growth process, and<br\/>can be adjusted to introduce the minimum defect density.<br\/>We will systematically investigate the factors (growth temperature, As flux,<br\/>growth rate, laser power, etc.) that provide uniform and narrow QD<br\/>distribution and efficient luminescence. The samples grown using optically<br\/>controlled nucleation will be studied by the in-situ RHEED, as well as STM,<br\/>TEM and photoluminescence methods to reveal the correlations between growth<br\/>parameters, and the structure and properties of the QD systems. The<br\/>laboratories at the Institute have all the necessary equipment for the QD<br\/>characterization. This includes state-of-the-art field-emission ultra-high<br\/>resolution TEM, focused ion beam station, surface analysis tools, five STM<br\/>tools configured for different imaging modes and environment including<br\/>ultra-high vacuum, and unique ultrasonic force microscope.<br\/>The successful completion of the proposed work would have a significant<br\/>impact on the performance of various optoelectronic components. The method<br\/>will allow the growth of QD structures with sharp size distribution and high<br\/>radiative recombination efficiency. For example, the QD structures will be<br\/>used as active media for laser diodes with superior performance<br\/>characteristics, such as higher efficiency, higher thermal stability, higher<br\/>modulation frequency and increased reliability.","title":"NER: Engineering of InAs Quantum Dot Ensembles Using Interference of Optical Surface Waves","awardID":"0210279","effectiveDate":"2002-07-01","expirationDate":"2003-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2878","name":"SPECIAL PROJECTS - CCF"}}],"PIcoPI":["525366"],"PO":[187585]},"71013":{"abstract":"ITR: Enhancing Crystal Structure Determination through Data Mining, Collaborative Environments, and Grid Computing<br\/><br\/>X-ray crystallography, with its unique ability to reveal the atomic or near-atomic structures of a wide range of biomedically important molecules, is the cornerstone of modern structural biology. This project will support critical advances in the enabling technologies of automated tuning of software, learning via data mining, geographically distributed collaborative environments, and grid computing for the enhancement and determination of crystal structure.<br\/><br\/>Computer programs based on \"direct methods\" are used to determine the majority of small-molecule organic crystal structures. These methods begin to fail in the 100-200-atom range because the accuracy of the underlying probabilistic relationships is inversely proportional to the square root of the size of the structure. The Shake-and-Bake algorithm and SnB program have extended the size of crystal structures amenable to direct-methods phasing from 100 to 2500 atoms. SnB has also been used to increase the size of heavy-atom substructures in large proteins that can be determined from 10 to 180 Se atoms. This provides a bootstrap by which complete structures, containing hundreds of thousands of atoms, can be elucidated. Such accomplishments would have been regarded as impossible only a few years ago, and the ultimate potential of the Shake-and-Bake approach to ab initio structure determination of macromolecules is unknown.<br\/><br\/>The integrated SnB collaborative environment will allow multiple simultaneous users at distinct locations to work together in a virtual environment via a variety of platforms (from 3D fully immersive to desktop PC). Users will be able to navigate through a structure, search and import structures available from public crystallographic data banks, edit structures, and interface directly with SnB while running either in solution mode or in refinement mode. The users will have the ability to work in a collaborative fashion as they would if they were all situated in close physical proximity. Finally, platforms consisting of computational grids are available in many academic and commercial institutions that use crystallographic software. A grid-enabled version of SnB will be created so that it can take advantage of computational grids and networks of workstations that have available computing cycles. The introduction of SnB has had an enormous impact on the crystallographic community. The integration of the Shake-and-Bake methodology with automated data warehousing and data mining should provide equally spectacular advances in the near future. The introduction of collaborative environments and the ability to exploit computational grids is expected to have a significant impact as well. Advances in enabling technologies coupled to a widely-distributed package, provides a unique opportunity to evaluate the viability of these enabling technologies, which have far-reaching applications to a wealth of diverse areas, including computational chemistry, advanced design, optimization, and edutainment.","title":"ITR: Enhancing Crystal Structure Determination through Data Mining, Collaborative Environments, and Grid Computing","awardID":"0204918","effectiveDate":"2002-07-01","expirationDate":"2009-12-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1687","name":"ITR MEDIUM (GROUP) GRANTS"}}],"PIcoPI":["442408",183781,"518277","269283",183784,183785],"PO":["565272"]},"72168":{"abstract":"An ad hoc network is a group of mobile computers (or nodes) using wireless network interfaces, in which individual nodes cooperate by forwarding packets for each other to allow nodes to communicate beyond their direct wireless transmission ranges. This project is attempting to create a routing protocol for ad hoc networks that is highly robust against attacks, yet is able to perform close to the best existing non-secure ad hoc network routing protocols.<br\/><br\/>The research focuses primarily on on-demand (or reactive) routing protocols, in which a node attempts to discover a route to some destination only when it has a packet to send to that destination, but also considers how the routing security techniques developed apply to other styles of ad hoc network routing protocols such as periodic (or proactive) and hybrid protocols. The research addresses passive and active attackers, including cooperating attacking nodes and compromised nodes. The types of attacks considered range from routing disruption attacks, in which an attacker attempts to cause legitimate data packets to be routed in dysfunctional ways, to resource consumption attacks, in which an attacker injects packets into the network in an attempt to consume valuable network resources such as bandwidth, or to consume node resources such as memory (storage) or computation power.","title":"Security in Multihop Wireless Ad Hoc Network Routing","awardID":"0209204","effectiveDate":"2002-07-15","expirationDate":"2006-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2802","name":"TRUSTED COMPUTING"}}],"PIcoPI":["233000"],"PO":["521752"]},"71079":{"abstract":"CareMedia provides automated video and sensor analysis for geriatric care. Through activity and environmental monitoring in a skilled nursing facility, a continuous, voluminous audio and video record is captured. Through work in information extraction, behavior analysis and synthesis, this record is transformed into an information asset whose efficient, secure presentation empowers geriatric care specialists with greater insights into problems, effectiveness of treatments, and determination of <br\/>environmental and social influences. CareMedia allows the behavior of senile dementia patients to be more accurately interpreted through intelligent browsing tools and filtered audiovisual evidence, leading to <br\/>treatment that reduces agitation while allowing awareness and responsiveness. The research begins with disruptive vocalization, a particular behavior noted across senile dementia assessment scales. The <br\/>coverage is then broadened ambitiously to integrate sensor and visual data for behavioral analysis and summarization in support of OBRA regulations requiring behavior management strategies that are not just chemical restraints. This effort includes automatic techniques to recognize disruptive vocalizations, more complex behavioral occurrences such as falls or physical aggression, and circadian patterns of activity. This research builds on key Carnegie Mellon research efforts in digital video analysis, wearable mobile computers, computer-based vision systems, and information retrieval systems for multimedia metadata.","title":"ITR: CareMedia: Automated Video and Sensor Analysis for Geriatric Care","awardID":"0205219","effectiveDate":"2002-07-01","expirationDate":"2007-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1687","name":"ITR MEDIUM (GROUP) GRANTS"}}],"PIcoPI":[183958,"457516","333951","371226","533348"],"PO":["564456"]},"77635":{"abstract":"Future networked multimedia information systems will carry a wide variety of applications including digital libraries, video, audio and image services, distance learning and collaboration, networked virtual environments, and entertainment. The main characteristics of multimedia applications that lead to difficulties in end-to-end systems design are that they have very large bandwidth and storage requirements, with vastly different performance and reliability requirements, often coupled with real-time constraints. Along with these characteristics, the highly interreliability requirements, often coupled with real-time constraints. Along with these characteristics, the highly interactive nature of a variety of multimedia applications, resulting in fairly unpredictable workloads, makes the design and evaluation of networked multimedia information systems an exceptionally challenging problem. In this proposal, we outline research on three aspects of this problem: (1) the design and evaluation of server resource allocation algorithms for CM servers in order to retrieve information efficiently and according to the QoS demanded by the application; (2) the development of performance evaluation techniques for evaluating new server designs. (3) the participants of this project bring expertise from a wide variety of areas: databases, distance learning, multi-media, networking, and performance evaluation to bear on problems in these areas. Another important feature of this proposal is that the participants have available four prototypes of state of the art multimedia systems: the Virtual World Data Server (VWDS) developed at UCLA: the prototype of a Video-on-Demand server developed in Brazil as part cooperative research project among Brazilian institutions; and the Multimedia Asynchronous Networked Individualized Courseware (MANIC) and the Internet Multimedia Proxy (IMP) both developed at UMass. These applications will be used to motivate the development of new algorithms for retrieving information and for maintaining the desired quality of service after sending the data over a wide area network. They will also form the basis of the many experimental and analytical studies that will be performed to evaluate these new algorithms. To aid in this evaluation, our group also developed three performance evaluation and modeling tools: a state-of-the-art tool for constructing performance and reliability models (Tangram-II) developed in Brazil jointly with UCLA; a symbolic model checking tool (VERUS): and a tool which facilitates design, development, and subsequent performance evaluation of designs of multimedia storage hierarchies (ViPEr-HiSS) under development at UMD. Thus, the environment of our labs as well the long distance among them will provide a unique testbed for this type of an evaluation due to the drastically different connectivities available to our applications, from gigabit low utilized links to intercontinental congested links. <br\/>The proposed research represents a fundamentally important step in the design and performance evaluation of next generation information servers and the networked applications that will operate on top of them. As a result of our research we expect to have a better understanding of how storage server resource management policies, channel allocation policies, and network adaptation policies interact to satisfy the required QoS of CM applications, despite the fairly unpredictable network delays.","title":"Collaborative Research (NSF-CNPq): Application Level Adaptation and Control for Retrieval and Delivery of Continuous Media over the Internet","awardID":"0233979","effectiveDate":"2002-07-01","expirationDate":"2004-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6855","name":"INFORMATION & KNOWLEDGE MANAGE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2885","name":"CISE RESEARCH INFRASTRUCTURE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"4097","name":"NETWORKING RESEARCH"}}],"PIcoPI":["410098"],"PO":["565090"]},"69968":{"abstract":"ABSTRACT<br\/>0201253<br\/>Shang-Ching Cou<br\/>Wichita State U<br\/><br\/><br\/>Automated geometry reasoning has been a very successful area in the past twenty years. Highly<br\/>successful methods for automated geometry theorem proving and discovering have been introduced<br\/>since the late 70s. With these methods, one can not only prove most of the geometry theorems<br\/>within seconds, but also discover many new theorems. One may also prove and discover theorems<br\/>in differential geometries and mechanics. In the early 90s, methods were developed to generate<br\/>human-readable proofs, multiple proofs, and the shortest proofs in geometry.<br\/>Methods for automated geometry diagram generation (AGDG) have been developed recently.<br\/>The purpose of AGDG is to draw a declaratively described diagram automatically. Compared to<br\/>automated theorem proving, AGDG has a wider range of applications, including intelligent CAD,<br\/>robotics, linkage design, computer vision, nanotechnology and chemical molecular modeling,<br\/>interactive constraint-based graphic systems, numerically controlled machines, and computer aided<br\/>instruction.","title":"Automated Geometry Reasoning and Methods for Diagram Generation","awardID":"0201253","effectiveDate":"2002-07-15","expirationDate":"2006-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2865","name":"NUMERIC, SYMBOLIC & GEO COMPUT"}}],"PIcoPI":[181052,181053,181054],"PO":["321058"]},"67449":{"abstract":"Home Area Networks (HANs) are an emerging technology that is very likely to play a major role in future homes. Broad deployment of this technology, however, depends strongly on the achieved security and the policies used to allow unsophistcated users to express and communicate their security requirements. The key objective of this research is to investigate technologies and methodologies which can be deployed and used to protect home networks. The research contributions include (a) user-accessible security policies, (b) a framework for the safe and secure communication between devices in a Home Automation Network (HAN), and (c) the collection and analysis of empirical findings by deploying such devices in a home environment. Without the security components that this research will produce, wide deployment of HANs may have devastating consequences. The results of low security awareness coupled with \"always-on\" connectivity have been demonstrated by the problems caused by computer viruses. In addition, the proxy-based communication framework that will be implemented as part of this research, will also be applicable to self-reconfigurable networks that may be found in health monitoring systems, battlefield sensor networks, etc.","title":"CAREER: The Home Area Networking Gateway Architecture (HANGAR)","awardID":"0133537","effectiveDate":"2002-07-01","expirationDate":"2008-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"4095","name":"SPECIAL PROJECTS IN NET RESEAR"}}],"PIcoPI":[174826],"PO":["565090"]},"70771":{"abstract":"The goal of this research is to develop system-on-a-chip (SOC) test resource partitioning techniques based on test data compression. Topics being investigated under this grant include: (i) data compression codes; (ii) efficient on-chip decompression architectures; (iii) low-power scan testing. This project is expected to lead to a unified framework to reduce SOC test data volume, testing time, and test power.","title":"Test Resource Partitioning and Optimization for System-on-a-Chip","awardID":"0204077","effectiveDate":"2002-07-01","expirationDate":"2007-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4710","name":"DES AUTO FOR MICRO & NANO SYS"}}],"PIcoPI":["506171"],"PO":["562984"]},"70782":{"abstract":"ABSTRACT<br\/>0204112<br\/>Hanson, Andrew<br\/>Indiana U Bloomington<br\/><br\/>Complex variables form the basis for virtually every aspect of modern science, and complex<br\/>projective spaces are the home to the rich world of objects and structures that arise from com-plex<br\/>variables. Yet attempts to depict geometric aspects of these spaces have been scarce due the<br\/>prodigious difficulty of higher dimensional visualization and poor understanding of the wealth of<br\/>relevant problems that touch on complex projective spaces. Modern computer technology provides<br\/>a number of very significant new tools symbolic manipulation programs, numerical optimiza-tion<br\/>programs, and interactive computer graphics visualizations that can provide powerful as-sistance<br\/>for the human mathematical intellect. The benefits of exploiting these tools fall into two<br\/>major categories: (i) lowering the bar, so to speak, so that a larger number of people, possibly<br\/>even interested lay persons, can understand the significance and excitement of previously inacces-sible<br\/>mathematical concepts; and (ii) raising the potential level of research attainment to allow the<br\/>solution of problems that would be nearly impossible using conventional mathematical research<br\/>methods.","title":"Visualizing Complex Projective Spaces and their Applications","awardID":"0204112","effectiveDate":"2002-07-01","expirationDate":"2007-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2865","name":"NUMERIC, SYMBOLIC & GEO COMPUT"}}],"PIcoPI":["503797"],"PO":["532791"]},"72015":{"abstract":"Mueller, Frank<br\/>CCR-0208581<br\/>\" Reducing Frequency via Speculation and Fall-Back Recovery\"<br\/><br\/>Conserving power is a key issue in embedded computing. At present, significant power is wasted because embedded system designers lack detailed knowledge of the processing speed needed by applications. Naive worst-case timing analysis exaggerates the required processor frequency, especially as software and hardware complexity increases.<br\/><br\/>This work puts forth a two-tier approach to reduce the processor frequency of complex embedded systems. First, tight worst-case timing analysis reduces the perceived upper bound on the number of cycles consumed by tasks. This reduces the maximum frequency, saving power. Second, architecture simulation and processors with dual frequency\/voltage modes enable significant additional power savings. Architecture simulation produces an approximate worst-case timing estimate, which does not have to be safe and, consequently, is the basis for a very low speculative frequency. A higher recovery frequency is utilized as a fall-back mode to ensure safe operation bounded by tight worst-case timing analysis, as delivered in the first approach. These two approaches complement each other. They initially reduce the power requirements by a significant amount when compared with the naive approach. Additionally, they reduce power<br\/>requirements further by exploiting simulation to accurately","title":"Reducing Frequency via Speculation and Fall-Back Recovery","awardID":"0208581","effectiveDate":"2002-07-01","expirationDate":"2006-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2801","name":"EMBEDDED & HYBRID SYSTEMS(EHS)"}}],"PIcoPI":["518384","553590"],"PO":["561889"]},"70893":{"abstract":"EIA-0204464<br\/>Rosenbloom, Joshua L., Ash, Ronald A.<br\/>University of Kansas <br\/><br\/>Title: Characteristics and Career Paths of Current IT Workers<br\/><br\/><br\/>This award provides support for a study that will identify important decision points in the educational and work experiences of Information Technology (IT) workers that have led them to enter and remain in the IT workforce. The results of this study will document the normal patterns of entry and retention in the IT workforce to provide a baseline to examine the special problems of women and minorities who are greatly underrepresented in this expanding and lucrative sector of the economy.<br\/><br\/>Through a survey of both current IT and non-IT workers in the greater Kansas City area, the project will gather data on individual personality traits in conjunction with detailed family background, and educational and work histories. These data will in turn be used to identify aspects of attitudes, family background, and educational and work experiences that have influenced individual decisions to enter IT jobs, as well as to remain in (or exit from) them. Among IT workers the same data will be used to explore differences by sex, and race and ethnicity. The results will illuminate both the similarities between IT and science and engineering career choices, and the differences.","title":"ITWF: Characteristics and Career Paths of Current IT Workers","awardID":"0204464","effectiveDate":"2002-07-15","expirationDate":"2005-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1713","name":"WORKFORCE"}}],"PIcoPI":[183502,"565013"],"PO":["289456"]},"70541":{"abstract":"Davis, Timothy<br\/>University of Florida<br\/>0203270<br\/><br\/>The focus of this project is the development of innovative library-quality software and under-<br\/>lying mathematics for dual active set techniques in optimization.The dual active set algorithm<br\/>(DASA)was .rst introduced in the context of state constrained control problems,and later in the<br\/>context of constrained mathematical programs.For linear or quadratic programming,each step of<br\/>the algorithm is equivalent to solving a linear system of equations,and in successive steps,there<br\/>is a small rank change in the matrix corresponding to the change in the active set.Numerical<br\/>experience has shown that the dual active set framework is an extremely e .cient approach for<br\/>solving some broad classes of optimization problems,including problems in optimal control and<br\/>quadratic network optimization.A version of the algorithm targeted to linear programming has<br\/>already solved some LPs that other state-of-the-art packages are unable to solve.We will develop<br\/>a variety of sparse matrix techniques,which have broad applicability,and which provide,in par-<br\/>ticular,the numerical foundation for DASA.Each technique will be developed into library-quality<br\/>software and made widely available.These include:","title":"Sparse Matrix Algorithms and their Application to Dual Active Set Techniques in Optimization","awardID":"0203270","effectiveDate":"2002-07-01","expirationDate":"2007-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2865","name":"NUMERIC, SYMBOLIC & GEO COMPUT"}}],"PIcoPI":["485318","485200"],"PO":["381214"]},"70783":{"abstract":"ABSTRACT<br\/>0204113<br\/>Gene Cooperman<br\/>Notrheastern U<br\/><br\/>The proposed research is part of an ongoing project to provide the software infrastructure for large symbolic computations. It is proposed to employ the rich set of computational group theory algorithms, with which the P.I. is intimately familiar, as a testbed for analyzing the barriers to wider use of parallelism. In addition<br\/>to the algorithmic difficulties of irregular computations that characterize much of symbolic computation, there are barriers based on limitations of RAM in today's hardware. These hardware barriers are<br\/>demonstrably real. A random access to RAM can cost more than 1,000 CPU cycles on the most recent architectures. This affects symbolic algebra computations to a much greater extent than traditional<br\/>numerical or commercial applications, which emphasize sequential access to RAM. Even some non-parallel applications in symbolic algebra are shown to be primarily memory-bound (bound by slowness of RAM),<br\/>rather than CPU-bound, on current architectures. This requires a revised, non-uniform complexity model of RAM.","title":"Scalable Parallel Symbolic Computation for Irregular Problems","awardID":"0204113","effectiveDate":"2002-07-15","expirationDate":"2006-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2865","name":"NUMERIC, SYMBOLIC & GEO COMPUT"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0507","name":"Division of SCIENCE EDUCATION RESOURCES IM","abbr":"SER"},"pgm":{"id":"1264","name":"ALGEBRA,NUMBER THEORY,AND COM"}}],"PIcoPI":["521812"],"PO":["321058"]},"70795":{"abstract":"The goal of this work is to develop a new canonical representation and an efficient verification infrastructure to support the RTL verification of large designs. The proposed graph-based representation, called Taylor Expansion Diagram, is based on a different decomposition principle than used by decision<br\/>diagrams such as BDDs and BMDs. It is obtained by treating the symbolic expression of the design as a continuous, differentiable function and applying Taylor series expansion with respect to its word-level variables. <br\/><br\/>The resulting Taylor Expansion Diagram (TED) is canonical for a fixed ordering of variables. TEDs can be used to represent functions containing both algebraic and Boolean expressions, facilitating the representation of complex designs with arithmetic operators and Boolean logic, typically encountered in <br\/>RTL specifications. <br\/><br\/>We are building an RTL verification infrastructure centered around TED that can be used to verify functional equivalence of RTL designs. We are developing systematic, algorithmic techniques for constructing and manipulating TED representations of HDL designs, based on the new theory.<br\/>We are also investigating how to exploit TEDs for implementation verification, that is checking functional equivalence between an RTL specification and its logic, gate-level implementation. By carrying out extensive experiments, the applicability of TEDs to realistic designs with arithmetic circuits and Boolean logic must be evaluated, and the performance of TEDs compared against that of BDDs and *BMDs.<br\/><br\/>This project has also an important educational role of teaching students about modern design representations from decision diagrams to more abstract, word-level data structures in the context of design synthesis and verification.","title":"Taylor Expansion Diagrams: A Compact Canonical Representation for RTL Verification","awardID":"0204146","effectiveDate":"2002-07-01","expirationDate":"2006-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4710","name":"DES AUTO FOR MICRO & NANO SYS"}}],"PIcoPI":["550433"],"PO":["562984"]},"72159":{"abstract":"Lepreau, Jay<br\/>CCR-0209185 <br\/>\"Composable Execution Environments: A Foundation for Building Robust Embedded Systems\"<br\/> <br\/>Real-time and embedded systems are built using a wide variety of \"execution models\"---collections of rules for sequencing actions and mediating access to shared resources. In general, systems developed using restricted execution models are easier to understand, debug, and test than are systems developed using powerful models. They are also more efficient and permit stronger properties to be proven about them<br\/>with less effort, such as non-violation of timing constraints and freedom from deadlock, livelock, or race conditions.<br\/><br\/>The instantiation of an execution model with a specific set of tasks and their associated timing and resource sharing requirements is called an \"execution environment.\" The central premise of this project is that it is feasible and useful to structure embedded systems as hierarchical compositions of execution environments. If successful, this research will result in a new way to develop embedded systems software that permits developers to make use of powerful compositions of execution environments without sacrificing the software engineering benefits of individual, more restricted environments.<br\/><br\/>To accomplish this, the researchers must solve a number of research problems. First, compositions of execution environments must be analyzed and mapped to threads and schedulers in such a way that no<br\/>real-time deadlines or other constraints of the individual environments are violated. This will be accomplished by leveraging the researchers' experience with hierarchical real-time scheduling, with<br\/>constraint checking for component systems, and with flexible execution models in operating systems. Second, compositions of execution environments must not suffer from undue or unexpected degrees of inefficiency and unpredictability. The researchers will accomplish this by leveraging their experience in developing and optimizing component-based operating systems.","title":"EHS: Composable Execution Environments: A Foundation for Building Robust Embedded Systems","awardID":"0209185","effectiveDate":"2002-07-01","expirationDate":"2005-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2801","name":"EMBEDDED & HYBRID SYSTEMS(EHS)"}}],"PIcoPI":["344532","550238"],"PO":["561889"]},"65746":{"abstract":"Wireless communication technology has gained widespread acceptance in recent years. Wireless local area networks have come into greater use, with the advent of the IEEE 802.11 standard and availability of several commercial products based on this standard.<br\/><br\/>An ad hoc network can be formed by wireless, potentially mobile hosts, without requiring the use of any fixed infrastructure, such as base stations. Such networks have many applications, including home networking, personal area networking, sensor networking, search-and-rescue missions in remote areas, and other civilian as well as military operations.<br\/><br\/>Modern wireless devices are often designed with the capability to transmit at different bit rates using different modulation schemes and to operate in a power-save mode to conserve energy. While such wireless devices can be built, there is not adequate research on performance of ad hoc networks utilizing such devices. This project will, therefore, attempt to answer two broad questions:<br\/><br\/>(1)How to design wireless medium access control (MAC) protocols that exploit multi-rate and power-save capabilities in ad hoc networks? While there has been some work on such protocols, this project is expected to develop new techniques to utilize multi-rate and power-save capabilities.<br\/><br\/>(2) What is the impact of multi-rate and power-save capabilities on performance on network layer and transport layer? The project will study the interaction between wireless device capabilities and upper layer performance, and develop mechanisms to improve performance of the various layers.","title":"Ad Hoc Wireless Networks Utilizing Multi-Rate and Power-Save Capabilities","awardID":"0125859","effectiveDate":"2002-07-15","expirationDate":"2006-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"4097","name":"NETWORKING RESEARCH"}}],"PIcoPI":["553537"],"PO":["565090"]},"72049":{"abstract":"This research is focused on developing circuits and architectures for asynchronous high-performance computers. Asynchronous organization has a number of significant advantages over the traditional globally synchronous approach that we plan to exploit. These advantages can be broken down into two general categories: those that relate to the circuit-level properties of asynchronous circuits, and those that relate to the higher-level sequential properties of this form of implementation. Circuit advantages, which are mostly directly related to the absence of the global clock signal, include lower electro-magnetic interference (EMI), lower power, and easier system integration due to the local and modular interconnection of asynchronous system pieces. Higher-level organizational advantages<br\/>include the ability of an asynchronous system to adapt to data-dependent delays in system components, take advantage of early completion of system activities, and more naturally mediate sub-task<br\/>concurrency during system operation.","title":"High-Performance Asynchronous Computer and SoC Architecture","awardID":"0208692","effectiveDate":"2002-07-01","expirationDate":"2006-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4715","name":"COMPUTER SYSTEMS ARCHITECTURE"}}],"PIcoPI":["451272"],"PO":["325495"]},"76416":{"abstract":"EIA-0228847<br\/>William Aspray<br\/>Computing Research Association<br\/><br\/>RI: Infrastructure 2002: NSF CISE\/EIA RI and MII PI Workshop<br\/><br\/>The National Science Foundation has requested assistance to coordinate the Principle Investigator's meeting for the Research Infrastructure and Minority Institutions Infrastructure programs. The PI meeting is a chance to bring researchers together to learn about the work of other research projects, and to provide a forum to discuss new ideas and future directions of the programs. CRA proposes to act as the organizer of the annual RI\/MII PI Workshop. CRA is in a unique position to carry out the workshop support. Their organizational mission is to support research and advanced education in computing, and it brings them in contact with many of the departments represented in the RI and MII programs. This workshop will be held at the Cliff Lodge at Snowbird Ski and Summer Resort in Snowbird, Utah on July 12 - 14, 2002.","title":"RI: Infrastructure 2002: NSF CISE\/EIA RI and MII PI's Workshop","awardID":"0228847","effectiveDate":"2002-07-01","expirationDate":"2005-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2885","name":"CISE RESEARCH INFRASTRUCTURE"}}],"PIcoPI":["208531","209556"],"PO":["297837"]},"67517":{"abstract":"EIA-0133840 Srinidhi Varadarajan Virginia Polytechnic Institute & State University CAREER: Weaving a Code Tapestry: A Compiler Directed Framework for Scalable Network Emulation <br\/><br\/>In this research, we propose a new scalable network emulation test-bed that supports both the simulation as well as direct code execution paradigms within a single framework. In order to represent the scale and heterogeneity of the Internet, the test-bed scales to tens to hundreds of thousands of network nodes. The first major challenge lies in developing programming models that can represent the digraph relationship of network protocol stacks within a single process, without manually modifying either the protocol stack or network applications. Secondly, the enormous scope of the test bed requires us to address problems in inter application context switch time, memory usage and parallel discrete event simulation, all of which present bottlenecks to scalability.","title":"CAREER: Weaving a Code Tapestry: A Compiler Directed Framework for Scalable Network Emulation","awardID":"0133840","effectiveDate":"2002-07-15","expirationDate":"2008-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2884","name":"NEXT GENERATION SOFTWARE PROGR"}}],"PIcoPI":["309299"],"PO":["551712"]},"70872":{"abstract":"High-speed circuits are highly pipelined, use latches as opposed to flip-flops, and practice extensive time borrowing to reduce overheads of pipelining. Since speed is a critical objective, high quality delay testing, such as path delay testing, is imperative for such circuits. Use of latches and extensive time borrowing have two important consequences that give rise to new problems in delay testing. First, since the paths in one block interact with the paths in the blocks in its fan in and fan out, it becomes necessary to test for delay faults multi-block paths, i.e., paths that traverse multiple blocks of a circuit. The number of such paths is often astronomical. Second, due to time borrowing, values at a latch output are not applied at any fixed time, but at some time within a range. Since the exact time when values are applied at the outputs of a latch vary from vector to vector and from one fabricated copy of a chip to another, it is impossible to design design-for-testability (DFT) circuitry that mimics the timing of events during the normal mode of operation. <br\/><br\/>Two types of test application schemes are proposed that can be implemented using scan designs that do not try to mimic the timing of events during the circuit's normal operation but apply values and capture responses at specific clock edges. It is then proven that it is indeed possible to use such scan to precisely test, for path delay faults, latch based circuits that use time borrowing. Techniques to use above DFT technique to efficiently test such high-speed circuits will be developed. This will include development of a technique to generate optimal test plans as well as tools that can generate the types of tests and perform detailed design of DFT circuitry required by the proposed approach. The proposed research will provide the first systematic approach for achieving, at reasonable costs, efficient testing for path delay faults in high speed circuits while providing provably high test quality. The tools developed will be leveraged and extended for instructional purposes.","title":"Efficient Techniques for High Quality Delay Testing of High-Speed Circuits","awardID":"0204414","effectiveDate":"2002-07-01","expirationDate":"2007-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4710","name":"DES AUTO FOR MICRO & NANO SYS"}}],"PIcoPI":["535238"],"PO":["562984"]},"70894":{"abstract":"The goal of this research is to develop a comprehensive co-design methodology, including algorithms and tools to facilitate the simultaneous power, noise margin, signal integrity, and power economy design with few, if any, design iterations. <br\/><br\/>The key objectives are:<br\/><br\/>1. Develop novel hierarchical, efficient, distributed and accurate system-level power delivery RLS models and analysis tools to evaluate power reduction and noise-immune design techniques for power delivery.<br\/><br\/>2. Develop efficient power and area estimation algorithms at the architecture level and at the physical design level.","title":"Robust Architecture-Physical Power Delivery Co-Design Methodology and Algorithm","awardID":"0204468","effectiveDate":"2002-07-01","expirationDate":"2006-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4710","name":"DES AUTO FOR MICRO & NANO SYS"}}],"PIcoPI":[183505],"PO":["562984"]},"71544":{"abstract":"The goal of this project is to automatically classify emotion in speech. In addition to using standard acoustic parameters, this work use will also use syllabic patterns and speech formant contours within syllables. These features, along with pattern recognition techniques, will first be used to produce an optimal separation of presence or absence of selected emotions in single words and short phrases. The software will then be adapted to recognizing and classifying these emotions where they occur in longer speech samples. Experiments will also be conducted in applying the software to \"impoverished speech\" where the linguistic content has been obscured. If successful, this will be a major contribution to automatic recognition and classification of emotion in speech.","title":"Automatic Recognition of Emotion in Speech","awardID":"0206940","effectiveDate":"2002-07-15","expirationDate":"2003-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6845","name":"HUMAN COMPUTER INTER PROGRAM"}}],"PIcoPI":[185299],"PO":["193961"]},"72468":{"abstract":"NER Proposal #0210428<br\/>PI: Faquir Jain<br\/>Nanochannel FETs and Quantum Dot based Nonvolatile Memory Cells using <br\/>Site-Specific and Layer-by-Layer Self-Assembly Techniques<br\/><br\/>Summary<br\/><br\/>This proposal aims at forming nanochannels (10-30 nm length with ~100nm <br\/>width), using SiOx-Si nanomasks deposited via site-specific self-assembly, <br\/>to fabricate FETs with enhanced performance. In addition, it seeks to <br\/>develop quantum dot based nonvolatile memory cell structures in floating <br\/>gate and floating trap configurations. These nonvolatile memory cells are <br\/>proposed to be grown using layer-by-layer self-assembly of ZnS-cladded CdSe <br\/>or ZnCdSe quantum dots (with core diameter ~3-5nm). The final goal is the <br\/>integration of FETs with nonvolatile memory cells to design programmable <br\/>circuits.","title":"NER: Nanochannel Field-Effect Transistors (FETs) and Quantum Dot Based Nonvolatile Memory Cells using Site-Specific and Layer-by-Layer Self-Assembly Techniques","awardID":"0210428","effectiveDate":"2002-07-01","expirationDate":"2004-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2878","name":"SPECIAL PROJECTS - CCF"}}],"PIcoPI":["313731","407303","380243","477490"],"PO":["562984"]},"72127":{"abstract":"Intrusion detection (ID) is an imperfect science. With state-of-the-art techniques, simple attacks with unambiguous signatures can be detected fairly easily, but trying to diagnose more complex attacks often results in a flurry of false positives and undetected attacks.<br\/><br\/>This situation would be improved if ID systems could work together, so that the weaknesses of one would be covered by the strengths of another. However, most of the recent work in combining ID results has focused on the protocol and architecture of the systems. Even a process as simple as corroboration--attempting to agree on a single attack diagnosis--is not assured with only protocol and architecture. Without an underlying body of theory, efforts to combine the results of multiple ID systems<br\/>will still fail.<br\/><br\/>The LATTICE plan is to define a consistent and comprehensive way to combine the results of multiple ID systems. The research will employ a graph theory approach to representing the conclusions of individual ID systems. Operators can be defined to combine the graph representations of ID diagnoses in rigorous ways that can be comprehended and analyzed. The results generated by these methods can be understood as the conclusions of the multiple systems, taken as a whole. The outcome of this approach is a rigorous unifying of the abilities and strengths of all the involved ID systems.","title":"LATTICED: An Algebra for Intrusion Correlation","awardID":"0209046","effectiveDate":"2002-07-15","expirationDate":"2004-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2802","name":"TRUSTED COMPUTING"}}],"PIcoPI":["427568","226310",186776],"PO":["529429"]},"72149":{"abstract":"Composing Data-Rich Embedded Systems the Easy Way<br\/>-------------------------------------------------<br\/><br\/>Arvind Krishnamurthy and Henrik Nilsson<br\/>Department of Computer Science, Yale University<br\/><br\/><br\/>Embedded computing increasingly takes place in a sensor rich environment where<br\/>the acquisition of raw information is much easier than its interpretation. In<br\/>addition to building components to process this data, embedded systems<br\/>programmers must also arrange the communication among potentially hundreds of<br\/>components, distributing computation to the processing elements so as to<br\/>minimize communication costs and maximize responsiveness, and scheduling of<br\/>the processing elements to adapt to changing priorities and communication<br\/>patterns. These challenges must be addressed at the system level rather than<br\/>the processor level.<br\/><br\/>This project develops a framework for composing distributed, data-rich<br\/>embedded systems that automates many of the low-level process allocation and<br\/>scheduling tasks. It takes place against a backdrop of a \"next generation\"<br\/>humanoid robot currently being developed at Yale. The robot contains a<br\/>significant number of processors connected in a heterogeneous fashion. The<br\/>project addresses two fundamental research issues. The first is the use of<br\/>modern programming language techniques to address critical embedded system<br\/>concerns such as composability and dynamic configuration change. The second is<br\/>improving overall system performance by exploiting high level system knowledge<br\/>in the run-time system. The end result will be a design methodology that will<br\/>enable rapid and reliable construction of complex data-rich interactive<br\/>systems.","title":"Composing Data-Rich Embedded Systems the Easy Way","awardID":"0209122","effectiveDate":"2002-07-01","expirationDate":"2004-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2801","name":"EMBEDDED & HYBRID SYSTEMS(EHS)"}}],"PIcoPI":["226134","497125","549890"],"PO":["561889"]},"70862":{"abstract":"ABSTRACT<br\/>0204372<br\/>Michael Gleicher<br\/>U of Wisconsin-Madison<br\/><br\/>As the dangers of our world become more apparent, and our desire to prepare for them increases, there is a<br\/>growing need for virtual experiences: simulated environments that convey to a participant the sense that they<br\/>are in a situation, not just a place. A virtual experience can provide an opportunity to explore a situation that<br\/>is too dangerous to rehearse, too impractical to create, or too inconvenient to attend. They may be used for<br\/>training, for example to give first hand experience to emergency response personnel in directing panicked<br\/>crowds; for design, for example to determine how people interact with a space before it is constructed; or<br\/>for entertainment. The key to a virtual experience is that they combine environment and situation. Simply<br\/>creating a visually compelling virtual environment is insufficient.<br\/>Our vision is to use compelling virtual experiences in training, research and entertainment. To be effec-<br\/>tive in these applications, virtual environments must be authored to meet specific pedagogical and commu-<br\/>nicative goals. Realizing this vision, therefore, requires technologies for both simulating and rendering the<br\/>worlds and enabling an author to specify behavior effectively.","title":"Mix-N-Match Motion: Animating Virtual Experiences","awardID":"0204372","effectiveDate":"2002-07-01","expirationDate":"2006-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2865","name":"NUMERIC, SYMBOLIC & GEO COMPUT"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7453","name":"GRAPHICS & VISUALIZATION"}}],"PIcoPI":["531411",183424],"PO":["532791"]},"70895":{"abstract":"EIA-0204469<br\/>Joshi, Kshiti, Kuhn, Kristine M.<br\/>Washington State U.<br\/><br\/>Title: What Does it Take to Succeed in Information Technology? A Multi-Level Analysis of Stakeholders' Perceptions of Critical Attributes and the Effects of Stereotype Fit.<br\/><br\/>Washington State University has been awarded an ITWF grant to examine beliefs about the attributes of successful IT professional, applying social psychological research on gender stereotypes and cognitive processes in performance evaluation to the case of IT professionals. The study will examine associated effects on employee satisfaction, commitment, and performance. Key research questions include: What are the desired characteristics of IT workers that are necessary to be successful in IT occupations? Do the desired characteristics fit men more so than women? How do evaluation and reward systems impact the retention of workers in the IT workforce?","title":"ITWF: What Does It Take to Succeed in Information Technology? A Multi-Level Analysis of Stakeholders' Perceptions of Critical Attributes and the Effects of Stereotype Fit","awardID":"0204469","effectiveDate":"2002-07-01","expirationDate":"2007-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1713","name":"WORKFORCE"}}],"PIcoPI":[183507,"530243"],"PO":["564181"]},"70797":{"abstract":"This research focuses on the development of symbolic formulations for timing and reliability analysis that can handle a wide range of custom-designed, complex circuits in an efficient, cost-effective manner. This symbolic approach enables handling of any arbitrary circuit structure and allows for an efficient means of incorporating information on the functional operation of the circuit into the analysis.<br\/><br\/>Two areas are being explored: (1) Symbolic algorithms are being developed to analyze electrical noise problems due to such things as leakage currents and charge sharing. To improve accuracy, the analysis is constrained by timing and input conditions. Based on the results of this analysis, circuits may be flagged for design violations or automatically re-designed to improve electrical reliability. (2) Symbolic formulations to calculate the delay through a channel-connected region (CCR) of CMOS devices are be developed. These formulations will handle nearly all commonly-used digital circuit families, as well as handle multiple inputs transitioning and accept arbitrary input-exclusivity constraints. The goal of this work is to develop an efficient means to identify problem circuits for further analysis while avoiding the need to verify many non-realizable worst-case conditions with other more costly simulation techniques.","title":"Symbolic Techniques for Evaluating Complex Custom Circuits","awardID":"0204151","effectiveDate":"2002-07-01","expirationDate":"2007-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4710","name":"DES AUTO FOR MICRO & NANO SYS"}}],"PIcoPI":["550256"],"PO":["562984"]},"80125":{"abstract":"The project focuses on integration of two learning paradigms for modeling stochastic visual patterns, and on developing a computational paradigm for effective stochastic inference. The work will strengthen the move from descriptive to generative models. Algorithms for learning and inference stronger than those existing today will be developed. A few order of magnitude improvement is expected for the mew methods. There is a good education program that includes improvement in the curriculum and design of new courses. Strong collaboration with industry and governmental labs will provide students with interesting experience.","title":"CAREER: Stochastic Modeling and Computing of Visual Patterns: From Descriptive to Generative Methods","awardID":"0244763","effectiveDate":"2002-07-01","expirationDate":"2007-05-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6840","name":"ROBOTICS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7339","name":"COMPUTER VISION"}}],"PIcoPI":["456867"],"PO":["317663"]},"73987":{"abstract":"EIA-0216592<br\/>James L .Caldwell<br\/>Jeffrey Van Baalen<br\/>Gamboa Ruben<br\/><br\/>MRI: Acquisition of a Network of Workstations Serving as a Platform for Distributed Automated Reasoning<br\/><br\/>This proposal from an EPCoR state, adapting current parallel and distributed theorem <br\/>proving technology to a setting in which different computation servers become available in an unpredictable fashion, aims at building a network of workstations that can be used as a computational server for research. A cluster of high-performance workstations running Linux and the required networking infrastructure will be acquired. The effort will make available a large proportion of the computational facilities of the department for theorem proving efforts. In this setting, the search for the proof of a single theorem will be spread between all the idle workstations participating in the distributed proof effort.<br\/>In extending model checking to infinite state spaces, the research involves exploring two approaches for protocol verification: Development of,<br\/>1. On-the-fly model checker based on a 3-values logic and,<br\/>2. Theorem proving methods that can reduce a protocol's state space to a finite size.","title":"MRI: Acquisition of a Network of Workstations Serving as a Platform for Distributed Automated Reasoning","awardID":"0216592","effectiveDate":"2002-07-01","expirationDate":"2005-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1189","name":"MAJOR RESEARCH INSTRUMENTATION"}},{"dir":{"id":"11","name":"Directorate for DIRECT FOR EDUCATION AND HUMAN RESOURCES","abbr":"EHR"},"div":{"id":"1108","name":"Division of EXPER PROG TO STIM COMP RSCH","abbr":"EPS"},"pgm":{"id":"9150","name":"EXP PROG TO STIM COMP RES"}}],"PIcoPI":["194771","308683","546962"],"PO":["557609"]},"71127":{"abstract":"EIA-0205470<br\/>Inderjeet Mani<br\/>Georgetown University<br\/><br\/>ITR: Constructing Protein Ontologies Using Text Mining<br\/><br\/>Given the vast amounts of genomic and molecular data being generated by scientific research, there is a pressing need to develop advanced bioinformatics infrastructures for biological knowledge management. An ontology is a semantic model that contains a shared vocabulary and classification of concepts in a domain. Ontologies for biology are crucial in data integration from multiple databases and in literature mining for knowledge extraction and evidence attribution. This project focuses on the development of an ontology of protein names, consisting of a data dictionary and links to more specific, more general and synonymous protein names. Ontology development, however, currently requires substantial human effort. This project will exploit statistical and computational linguistics methods to induce an ontology of protein names using text corpora from MEDLINE and a knowledge base developed at the Protein Information Resource (PIR); terms in the induced ontology will also be linked to the functional hierarchy of the Gene Ontology. The induced ontology can then be further edited by a human. This project aims at demonstrating that this domain-independent method of ontology induction is more cost-effective than having humans develop an ontology from scratch. The approach could therefore be of practical value in other domains where there is a need to develop ontologies linking text corpora and nomenclature in databases. Both the ontology and software system developed in this project will be freely distributed to the scientific community via the PIR web site in standard XML-based ontology interchange formats and for intelligent literature mining and PubMed searching.","title":"Constructing Protein Ontologies Using Text Mining","awardID":"0205470","effectiveDate":"2002-07-01","expirationDate":"2005-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1687","name":"ITR MEDIUM (GROUP) GRANTS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1994","name":"BIOINFORMATICS PROGRAM"}}],"PIcoPI":["529169",184155],"PO":["355797"]},"72128":{"abstract":"Ad hoc wireless networks have the potential of supporting seamless anytime-anywhere access to communications and computing resources on a very large scale. Such networks, while extremely compelling for applications, pose profound problems of security and quality-of-service provisioning. Ad hoc networks rely on cooperative mechanisms that adapt to the dynamic changes in network topology due to the mobility of the nodes, which are often constrained by energy limitations. Consequently, these networks are difficult to secure and extremely vulnerable to attacks.<br\/><br\/>The overall objective of the research is to develop a scalable and adaptive framework for integrating security and quality-of-service (QoS) into the critical components of routing and mobility management in ad hoc wireless networks for both commercial and military applications. A scalable computer simulation environment is developed to analyze the security strength of an ad hoc network with respect to its ability to maintain quality-of-service under a variety of attack scenarios, mobility patterns, and network traffic loadings. The research investigates the security limitations of existing routing and mobility management schemes and extends these schemes to incorporate security-inclusive QoS attributes. The focus of the research is on the critical tradeoffs among security and traditional QoS parameters such as performance, energy management, and availability. The research investigates security mechanisms that can prevent or mitigate the effects of hostile attacks without incurring excessive overhead.","title":"Integrating Security into Quality-of-Service Based Routing and Mobility Management in Ad Hoc Wireless Networks","awardID":"0209049","effectiveDate":"2002-07-01","expirationDate":"2006-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2802","name":"TRUSTED COMPUTING"}}],"PIcoPI":["548184","511513"],"PO":["521752"]},"80785":{"abstract":"This is a Collaborative Proposal between Northwestern University and University of Florida which addresses the key research challenges associated with management of dynamic Virtual Machines (VM) and interfacing these mechanisms with existing grid middleware techniques. The project will develop novel solutions that will address<br\/>- resource management for distributed virtualized end-resources that can be created dynamically,<br\/>- image management for the on-demand transfer of data representing the entire state to create a dynamic VM instance, and<br\/>- data management for the on-demand transfer of user and application data between decoupled compute and data servers on the grid.<br\/>The proposed approach will lead to middleware solutions that will form an information processing foundation for grid computing. The software generated in this project will be sued to implement the next generation of network computing hubs currently being used to support simulation needs in nanotechnology, electronics CAD, computer architecture and parallel programming.<br\/><br\/>The project addresses key research challenges to allow the management of dynamic instances of virtual machine middleware and will lead to solutions that will form an information processing foundation for grid computing on virtualized end-resources. In particular, the software generated in this project will be used to implement the next generation of network computing hubs currently being used to support simulation needs in nanotechnology, electronics CAD, computer architecture and parallel programming.","title":"Collaborative Research: Resource and Data Management for Virtualized End-resources in Computational Grids","awardID":"0301108","effectiveDate":"2002-07-01","expirationDate":"2007-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"4089","name":"NETWORK CENTRIC MIDDLEWARE SVC"}}],"PIcoPI":["558495"],"PO":["7594"]},"70556":{"abstract":"0203323<br\/>Nancy Kaplan<br\/>University of Baltimore<br\/>Baltimore, MD<br\/> \"An HCI Partnership Serving Underrepresented Groups\"<br\/><br\/>This is a multinstitutional project that leverages prior and ongoing research in the area of Human Computer Interfaces (HCI) into new curricula. In particular, the project's focus is: (a) to create a Human-Computer Interaction curriculum at the University of Baltimore's School of Information Arts and Technologies (SIAT) that will actively involve early-stage graduate students in ongoing research; (b) to construct and deliver this curriculum so that it is maximally effective in attracting and graduating students from groups underrepresented in the sciences, especially women, African-Americans, and students from non-traditional age groups; (c) to structure this curriculum around the results, and ongoing inquiry, of research at the University of Maryland's Human-Computer Interaction Lab (HCIL) in the design of children's technologies; (d) to embed this curriculum and research in a partnership spanning SIAT, HCIL, and local private and public sector institutions, and (e) widely disseminate this partnership model, and the results of its evaluation, with the goal of creating further partnerships between research and comprehensive institutions that will result in the involvement of students from underrepresented groups in ongoing research. Students who participate in this project's curriculum will also engage in field research that prepare them to join the workforce as professionals who have experience with research-grounded methods of developing HCI technologies, particularly those that are components of the HCIL's work on children's educational information technologies (including contextual inquiry, task analysis, participatory design, low-fidelity prototyping, querying interfaces, and spatial interfaces).","title":"CRCD: An Human-Computer Interfaces (HCI) Partnership Serving Underrepresented Groups","awardID":"0203323","effectiveDate":"2002-07-01","expirationDate":"2006-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1709","name":"CISE EDUCAT RES & CURRIC DEVEL"}}],"PIcoPI":["426438","518152",182630,182631],"PO":["551712"]},"70677":{"abstract":"As integrated circuit chips are becoming more complex to design, pre-fabricated platform chips, intended to meet the needs of a wide variety of embedded computing products, are becoming increasingly <br\/>common. The trend towards platforms creates the need for parameterizing computing architectures such that platforms can have their performance and power consumption adapted to the different needs of different products, and that can be tuned to the particular compute patterns of a particular product. This project will investigate several aspects of such parameterization. It will demonstrate the feasibility of extensive parameterization of an architecture's memory components, key contributors to power and performance. It will define the basic tasks that make up platform-oriented CAD, partition computer-aided design (CAD) tasks between desktop and platform resources to yield fast yet accurate and<br\/>cost-effective CAD solutions, and develop new CAD exploration algorithms for desktop\/platform co-exploration. The research will benefit platform designers, who need an understanding of parameters and tuning issues to effectively build heavily parameterized platforms and their associated CAD tools, and platform users, who can utilize such platforms and CAD tools to develop more efficient platform-based designs than currently possible.","title":"Collaborative Research: Platform-Based CAD for Power and Performance Optimization","awardID":"0203813","effectiveDate":"2002-07-01","expirationDate":"2006-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4710","name":"DES AUTO FOR MICRO & NANO SYS"}}],"PIcoPI":["541836"],"PO":["562984"]},"75924":{"abstract":"This award supports the travel and subsistence expenses of student participants in the First International Conference on Autonomous Agents and Multi-Agents Systems (AAMAS), being held July 15 - 19, 2002 in Bologna, Italy. This conference is entirely devoted to all aspects of research and application of agents technology, an important area of research in the success of the World Wide Web, electronic commerce, digital libraries, search agents, personal agents and synthetic agents. Participation in this conference will allow a diverse group of students, representing a wide range of research areas and methodologies, to present their research to the agents' community. In addition, special mentoring activities are planned for them.","title":"Support for International Travel of Graduate Students to AAMAS 2002 Conference","awardID":"0225813","effectiveDate":"2002-07-01","expirationDate":"2003-12-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6850","name":"DIGITAL SOCIETY&TECHNOLOGIES"}}],"PIcoPI":["561562"],"PO":["565227"]},"73625":{"abstract":"EIA-0215583<br\/>Patrick O'Leary<br\/>Kenrick Mock<br\/>University of Alaska Anchorage<br\/><br\/>MRI: Acquisition of Research Computational Equipment<br\/><br\/>This proposal from an EPCoR state, aiming at performing collaborative research on computational and visualization aspects of various application areas, targets interactive computational environments and intelligent systems; more specifically, parallel processing, scientific visualization, and intelligent systems. The work, requiring a high performance infrastructure, supports complex computing and the ability to visualize, store, and easily retrieve large data sets. The advancement of research techniques again requires significantly improved distributed computing and visualization capabilities. The computational steering tools require analysis involving consistency, latency, scalability, and perturbation costs. Research activities in an Interactive Computational Environment (ICE) involve:<br\/> 1. Seamless Monitoring and Steering of High-Performance Distributed Computations,<br\/> 2. Realistic Simulators, and<br\/> 3. Computational models.<br\/>The intelligent systems component explores information systems (new techniques and applications for machine learning, e.g., user profiles), information relevance and retrieval, efficient methods for human-computer interaction, and multi-agent research.","title":"MRI: Aquisition of Research Computational Equipment","awardID":"0215583","effectiveDate":"2002-07-01","expirationDate":"2003-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1189","name":"MAJOR RESEARCH INSTRUMENTATION"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2885","name":"CISE RESEARCH INFRASTRUCTURE"}},{"dir":{"id":"11","name":"Directorate for DIRECT FOR EDUCATION AND HUMAN RESOURCES","abbr":"EHR"},"div":{"id":"1108","name":"Division of EXPER PROG TO STIM COMP RSCH","abbr":"EPS"},"pgm":{"id":"9150","name":"EXP PROG TO STIM COMP RES"}}],"PIcoPI":[190709,"491237"],"PO":["557609"]},"72107":{"abstract":"Proposal Number: 0208956<br\/>Title: Formal Verification of Hybrid Systems Using Global Optimization<br\/><br\/><br\/>The embedding of logic-based controllers in modern technological systems such as automobiles, air and spacecraft, oil refineries and chemical processes, power generation plants and distribution networks, etc., is ubiquitous. Such systems are characterized by a coupling between continuous state dynamics and the discrete state dynamics of the logic based controllers, which are simultaneously responsible for interlock, sequencing and safety functionality. As performance and safety demands on technological systems increase, the design of logic based controllers encompassing all these functionalities simultaneously is increasingly complex. Once a design has been proposed, it is highly desirable to verify formally that the design does indeed implement all the desired functionalities. Ideally this verification step should take into account the continuous dynamics of the underlying technological system. This project is developing formal verification technologies that can accommodate such hybrid systems.<br\/><br\/>Formal verification problems for hybrid systems can in principle be formulated and solved as mixed-integer optimization problems. However, for formal verification purposes, it is essential to guarantee that the global solution of the optimization problem is found in a finite number of iterations. This project is developing novel deterministic global optimization algorithms for hybrid systems in the continuous time domain that can provide such guarantees.","title":"Formal Verification of Hybrid Systems Using Global Optimization","awardID":"0208956","effectiveDate":"2002-07-01","expirationDate":"2005-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2801","name":"EMBEDDED & HYBRID SYSTEMS(EHS)"}}],"PIcoPI":["459301"],"PO":["561889"]},"72118":{"abstract":"There are a rapidly-growing number and diversity of embedded processors in general use today. In a growing number of cases the device is programmable by its user. Programmablility varies in complexity from<br\/>simple memory functions, like a cell phone that remembers a list of numbers, to full third-party programmability (TPP), where, for example, a cell phone can download new software from the Internet<br\/>and offer significantly new functionality. This feature allows the device to exploit some of the advantages of general-purpuse computers like personal desktop computers or Internet servers. The device serves as a platform for a diversity of applications, even applications that were not yet conceived at the time the device was built.<br\/><br\/>In order to exploit these advantages, embedded processor software platforms must offer a range of features well-known from general purpose computers: flexibility, portability, extensibility, predictability, and deliverability. Of these, a particularly unique challenge arises in the delivery of new programs to the device.<br\/>Installing new code on general-purpose computers attached to the Internet is already a significant challenge, but the support of TPP embedded processors is an even more diverse and unsettled issue. It is often the case that smart devices are not networked, have only intermittent Internet connectivity, or operate primarily in networks consisting of other smart devices through local peer-to-peer links. This makes code delivery a particular challenge and impels the need for new architectures.<br\/><br\/>In this project we will derive a range of code delivery architectures for TPP smart devices based on the assumption of complex connectivity requirements. In the general case issues include small code size (for<br\/>instance programs may be limited to one or two kilobyte sizes), interaction with operational requirements (like naivety of a human operator in the field or kitchen), safety requirements for TPP devices with high-energy actuators, security issues for network communication or when mischief is particularly threatening (like programming for automobiles), interplay with network connectivity (like ability to<br\/>function both with and without access to the Internet). We will analyze architecture, language, and analysis techniques available to deal with the issues.<br\/><br\/>An early basis for our study of requirements will be the area of smart appliances for homes. A diversity of delivery options are the subject of current research in this area. We will begin by developing a system for programming microwave ovens using bar codes on food packages and generalize our experience with this system to others. Existing systems in this area assume too little (like recipes that can be expressed with 3-10 numbers) or too much (like an attached PC that must access recipes from the Internet). An ideal system will allow small programs to be delivered on packages that can function as scripts or invoke network connectivity if it exists to download code for more substantial functionality.<br\/><br\/>Our research also focuses on predictability using advanced analysis techniques such as formal verification. Our research will identify the appropriate subsets of general-purpose programming languages for embedded<br\/>applications and develop tools for applying verification techniques directly to the source code using domain-specific and automated abstractions.","title":"Third Party Programmability for Embedded Systems","awardID":"0208990","effectiveDate":"2002-07-01","expirationDate":"2004-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2801","name":"EMBEDDED & HYBRID SYSTEMS(EHS)"}}],"PIcoPI":["553855","497082"],"PO":["561889"]},"73449":{"abstract":"EIA-0214927<br\/>Ariola, Zena<br\/>University of Oregon<br\/><br\/>Special Projects: Proofs as Programs<br\/><br\/>The University of Oregon at Eugene has been provided with support to organize a summer school on the increasingly important paradigm of proofs-as-programs. According to this paradigm a typing assertion M: A has several \"isomorphic\" interpretations. In the computational interpretation, M is a (functional) program and the type A is its specification. In the logical interpretation M is a proof of the proposition A. The discovery of the connection between the two interpretations is due to Curry, Howard, and DeBruijn. Fifty years later, this connection between proofs and programs is now established as the foundation of many formal systems and automated techniques for reasoning about programs.<br\/><br\/><br\/>The aim of the school is to prepare interested graduate students, academics, and software engineers for conducting research in the area. The curriculum will include basic foundational material for all attendees; advanced material for those interested in new research directions; and a review of various tools together with experience in using them for various tasks for those interested in practical applications. In more detail, the curriculum will include the following three major categories of lectures:<br\/><br\/>1. Background: This material consists of well-established results developed in the late 80's and early 90's. This background information will provide an introduction to the essential concepts and methodologies of the paradigm.<br\/><br\/>2. Advanced Topics: This material consists of more recent results that extend and generalize the earlier work. This will provide students with insights into research and open questions.<br\/><br\/>3. Applications: This material will demonstrate how theoretical results can be used by practitioners in various fields of computer science. This will provide students with skills in the use of formal methods to reason about and generate solutions to practical problems, such as verification of hardware protocols and Java specifications.","title":"Special Projects: Proofs as Programs","awardID":"0214927","effectiveDate":"2002-07-01","expirationDate":"2003-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2880","name":"SOFTWARE ENGINEERING AND LANGU"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0506","name":"Division of EXPERIMENTAL & INTEG ACTIVIT","abbr":"EIA"},"pgm":{"id":"1714","name":"SPECIAL PROJECTS - CISE"}}],"PIcoPI":["489107"],"PO":["289456"]},"65705":{"abstract":"Over the past several years two technologies, ad hoc networking and smart antenna systems, have developed independently of one another. Smart antenna systems have been developed primarily for cellular communication systems while ad hoc network technology has been developed for military and disaster relief network models. In this research, the researchers plan on utilizing smart antenna systems in the context of ad hoc networking. The researchers believe that smart antennas with their ability to dynamically form directed beams will allow the capacity of ad hoc networks to dramatically increase.<br\/><br\/>The approach in this research is to exploit direction of arrival information obtained at<br\/>the antenna level for MAC and routing protocol design and, conversely, use routing and MAC layer information to form appropriate beams. This integrated approach appears to be ideal in terms of improving the overall system performance. The planned approach will rely on simulations as well as modeling. For the simulation, the researchers propose adding smart antenna models into NS-2. In addition, since one of the performance metrics is energy, the researchers plan on incorporating accurate energy models for beamforming and direction of arrival algorithms into NS-2. One of the two approaches that will be explored for this is a mixed NS-2\/DSP (Digital Signal Processor) environment in which NS-2 uses external DSPs to run the antenna algorithms and the exact measured energy cost is returned to the simulator.<br\/><br\/>This research will have a significant impact on the existing state of the art in ad hoc<br\/>network design. The researchers believe that as smart antenna systems mature, these systems are the right choice for infrastructureless networks. This research will develop protocols and answer questions related to performance improvements and the energy cost of using smart antennas. The researchers hope that the work will enable other researchers to explore this merging of technologies as well.","title":"Using Smart Antennas for Ad Hoc Networking","awardID":"0125728","effectiveDate":"2002-07-15","expirationDate":"2006-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"4097","name":"NETWORKING RESEARCH"}}],"PIcoPI":["518079",170087],"PO":["565090"]},"72129":{"abstract":"Janusz Konrad<br\/>Boston University<br\/><br\/>This research is concerned with the processing of visual information captured by a video camera. To date, image sequences have been typically analyzed and processed in groups of two frames; by differentiating one <br\/>frame from another, short-term image dynamics can be measured, such as changed areas (e.g., occlusions) or pixel displacements. Although the approach has been very successful to date (e.g., MPEG compression <br\/>standards), further gains are difficult to attain based on two image frames only. This research project offers a different approach to the analysis of image sequences - one based on a joint processing of multiple <br\/>image frames at a time. This joint treatment of, for example, 10 or 20 frames is expected to result in new gains in video compression, more reliable video database querying, and more accurate detection of <br\/>innovations (occlusion and exposure areas) that are of interest in surveillance applications.<br\/><br\/>The primary problem attacked in the project is the joint space-time segmentation of an image sequence into \"object tunnels\", i.e., 3-D volumes carved out in the space of horizontal, vertical and temporal coordinates <br\/>by a moving object. The estimation of object tunnels is approached as a volume competition problem, and solved using active-surface evolution equations embedded into the level-set solution framework. In order to <br\/>model motion of points within each object tunnel, a new spatially-parametric, temporally-quadratic motion model is studied. Various cost functionals relating object-tunnel intensities to the underlying motion are investigated. Since the standard volume competition can only extract a single moving object from background, an extension to more objects by means of multiple \"repelling\" surfaces evolving simultaneously is studied as well.","title":"Joint Space-Time Analysis and Characterization of Image Sequences","awardID":"0209055","effectiveDate":"2002-07-01","expirationDate":"2005-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4720","name":"SIGNAL PROCESSING SYS PROGRAM"}}],"PIcoPI":["521649"],"PO":["564898"]},"72019":{"abstract":"Kolmogorov complexity is a modern theory of randomness<br\/>and has many applications in computer science and<br\/>other fields. The investigator is enriching this theory<br\/>and its applications by doing research in two directions.<br\/><br\/>Analyzing the average-case complexity of an algorithm<br\/>is at the heart of practical algorithm analysis. <br\/>It has been demonstrated over the past decade that <br\/>Kolmogorov complexity is a powerful tool to help analyzing the <br\/>average-case complexity and the lower bounds of algorithms.<br\/>Examples are the average case analysis of Shellsort and Heapsort.<br\/>The PI plans to continue this work to systematically develop <br\/>the tool, the Incompressibility Method. This involves comparative <br\/>studies to understand why, how, and when <br\/>the incompressibility method<br\/>works. In order to demonstrate, and to uncover,<br\/>the power of this method, this method will be used to solve <br\/>other open questions. Samples of some open questions include: <br\/>improving Shellsort average-case lower bound analysis, <br\/>average height of balanced trees, and Stack sorting lower bound.<br\/><br\/>The modern information age and the post-genomic era raises a <br\/>fundamental question: Given two sequences (genomes or English<br\/>documents), how much information do they share? For example,<br\/>given two genomes, can we measure their evolutionary distance? <br\/>The goal of this second part of the proposal is to understand <br\/>this fundamental question and develop tools.<br\/>In the past, the PI and his coauthors have partially answered this<br\/>question by defining the concept of Information Distance. <br\/>Information Distance measures the absolute<br\/>thermodynamic energy required to convert one sequence to another.<br\/>However, it does not measure evolutionary distance because<br\/>genomic evolution allows long segment deletion\/insertion, cheaply.<br\/>A new theory suitable for such evolutionary distance will be<br\/>developed. To demonstrate the feasibility of this research,<br\/>some preliminary theory has been proposed and successfully applied to <br\/>construct whole genome and chain letter phylogenies when no other<br\/>method applies. More recently, this theory has also been<br\/>applied to program plagiarism detection and language classification.","title":"Kolmogorov Complexity and Its Applications","awardID":"0208595","effectiveDate":"2002-07-01","expirationDate":"2006-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2860","name":"THEORY OF COMPUTING"}}],"PIcoPI":["196924"],"PO":["565157"]},"76617":{"abstract":"This is the first year of funding of a 4-year continuing award. The PI will focus on the development of a biologically plausible framework for sensor-based machine olfaction (SBMO), with an emphasis on computation, analysis and instrumentation. The specific objectives are: (1) To develop a computational architecture based on neuro-morphic models of the biological olfactory system in order to improve the signal-processing and cognitive capabilities of SBMO; (2) To validate the perceptual plausibility ofthe computational architecture through comparative studies with the \"gold standard\" for olfactory perception - human-panel sensory analysis; (3) To develop advanced sensor interrogation techniques in order to improve selectivity, sensitivity and robustness of commercial conductivity-based gas sensor arrays. The results will lay the foundations fora new generation of SBMO systems by helping bridge the gap between multivariate chemical sensing and human olfactory perception. Improved analytical capabilities, as a result of advances in both signal processing and sensor instrumentation, will broaden the range of applications for SBM0.","title":"CAREER: Computational Models for Sensor-Based Machine Olfaction","awardID":"0229598","effectiveDate":"2002-07-01","expirationDate":"2008-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6845","name":"HUMAN COMPUTER INTER PROGRAM"}}],"PIcoPI":["467563"],"PO":["565227"]},"78927":{"abstract":"While some researchers have aimed at efficiency, they have often developed algorithms without proving them secure. Conversely, researchers focussed on provable security have often produced impractical algorithms. Providing both performance and provable security entails great effort in each domain, often entailing a strange marriage of mathematics with implementation considerations.<br\/>It is not unusual for researchers to be seeking a generator of a random cyclic group while at the same time worrying about whether finding one will cost too many machine cycles. This research effort aims to address these problems by developing cryptographic algorithms that are vigorously optimized, yet retain proven security. Moreover, for each algorithm a carefully-tested implementation will be provided, along with a specification for porting to other platforms. Finally, the most promising algorithms will be forwarded to standards activities in order to make them widely available. The planned results are to provide the user community with fast, secure algorithms with freely-available reference code; to encourage other researchers to expend efforts in these directions when publishing new protocols, and to introduce students to the cross-disciplinary nature of this research, which blends pure mathematics with architectural considerations.","title":"CAREER: Highly-Optimized Provably-Secure Cryptography","awardID":"0240000","effectiveDate":"2002-07-01","expirationDate":"2008-05-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2802","name":"TRUSTED COMPUTING"}},{"dir":{"id":"11","name":"Directorate for DIRECT FOR EDUCATION AND HUMAN RESOURCES","abbr":"EHR"},"div":{"id":"1108","name":"Division of EXPER PROG TO STIM COMP RSCH","abbr":"EPS"},"pgm":{"id":"9150","name":"EXP PROG TO STIM COMP RES"}}],"PIcoPI":["517575"],"PO":["565264"]},"70776":{"abstract":"ABSTRACT<br\/>0204084<br\/>Gilbert Stewart<br\/>University of Maryland College Park<br\/><br\/>Krylov sequence methods are widely used in the solution of large eigenproblems (e.g., the Lanczos and Arnoldi methods) and the solution of large linear systems (e.g., the conjugate gradient method and GMRES). In their ordinary applications these methods are well understood and have a firm theoretical basis. In more exotic applications, however, the theory and practice are not as advanced. This proposal in concerned with<br\/>three of these applications. Residual Krylov methods. The property of being a Krylov sequence is very sensitive to error. A single error toward the beginning of the sequence causes permanent loss of<br\/>accuracy in the approximations to eigenvectors in the Krylov subspace. This has the consequence that when shift-and-invert techniques are used to enhance the spectrum of a matrix, the resulting linear systems must be solved to full accuracy at each step of the process. It turns out, however, that if the sequence is extended using the residual for a targeted eigenvector, the sequence converges to that vector even when the shift-and-<br\/>invert equations are solved inaccurately. The practical consequences of this observation, which needs new theory to support it, promises to be great.","title":"New Krylov Methods: Theory and Applications","awardID":"0204084","effectiveDate":"2002-07-01","expirationDate":"2006-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2865","name":"NUMERIC, SYMBOLIC & GEO COMPUT"}}],"PIcoPI":["450658","279149"],"PO":["381214"]},"72515":{"abstract":"NER: Massively Parallel Electron Photoemitter Micro-arrays for Nanoscale<br\/>Lithography, Imaging and Inspection Applications<br\/><br\/> Present electron-beam lithography, imaging and inspection systems<br\/>are limited to serial scanning of patterns with only one beam. As a<br\/>result the ability of such systems to scan substantial areas at<br\/>nanoscale resolution with practical throughput is not possible. However<br\/>if such machines were to scan using a massively parallel array of<br\/>independently modulated beams, the resultant parallelism would make<br\/>possible not only significantly improved throughput for conventional<br\/>applications in the nanoscale environment but also enable faster device<br\/>development by software changeable patterns. However at this time there<br\/>is no practical multiple-beam electron emitter source available that<br\/>will meet system-level performance and reliability requirements. The<br\/>goal of the proposed research is to prove feasibility of photocathode<br\/>microarrays for massively parallel and independently modulated electron<br\/>sources. A key deliverable of the research will be a fabricated<br\/>individually gated array of sources with sufficient emission current<br\/>density to expose a line of electron sensitive resist 5 to 100nm in<br\/>width.<br\/> The successful demonstration of feasibility for photocathode<br\/>massively parallel microarrays will require a stable, low noise and<br\/>reproducible photocathode and a viable scheme for fabrication and<br\/>independently modulating the current in each beam. As a result the work<br\/>will focus on two key aspects. First the extension of our previous work<br\/>to develop a thin film stack photocathode and pretreatments that will<br\/>provide the emission stability and intensity necessary and second to<br\/>examine schemes for producing microarrays using such photoemitters.<br\/> Photoelectron source arrays will make nanoscale lithography and<br\/>rapid e-beam review testing possible. Lithography and testing on the<br\/>nanoscale are necessary if the manufacturing at this scale for<br\/>microelectronic devices, sensors and electrical- mechanical systems is<br\/>to become as high in yield and rapid as sub-micron fabrication is<br\/>today.","title":"NER: Massively Parallel Electron Photoemitter Micro-arrays for Nanoscale Lithography, Imaging, and Inspection Applications","awardID":"0210626","effectiveDate":"2002-07-01","expirationDate":"2004-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2878","name":"SPECIAL PROJECTS - CCF"}}],"PIcoPI":["276196",187889,"193135",187891],"PO":["562984"]},"72009":{"abstract":"Current high-end microprocessors incorporate a variety of predictors to improve performance. Future CPUs will likely include even more predictors, in particular load-value predictors. Load-value predictors provide predicted values to instructions that need the result of a load, thereby allowing these instructions to proceed without waiting for the load's slow memory access to complete. Thus, the program execution time is reduced.<br\/><br\/>Recent work on load-value prediction proposes sophisticated hybrid predictors with confidence estimators. While these predictors are quite effective, their complexity and size negatively affect performance parameters such as critical-path length, cycle time, chip area, power consumption, and heat dissipation.<br\/><br\/>The goal of this research is to reduce the size of value predictors without decreasing performance, to improve the prediction accuracy and coverage, and to develop new predictors and confidence estimators. A systematic search will find novel predictors that exploit additional value locality and will identify better confidence estimators that reduce costly mispredictions. Moreover, techniques that repair malformed predictions and inhibit wrong predictions will be investigated. Finally, schemes to enhance the predictor utilization and approaches to speed up predictor accesses will be researched. While the proposed ideas are already beneficial in today's systems, they will become even more important as increasing numbers of CPU cycles are wasted due to growing load latencies.","title":"Next-Generation Load-Value Predictors","awardID":"0208567","effectiveDate":"2002-07-01","expirationDate":"2004-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4715","name":"COMPUTER SYSTEMS ARCHITECTURE"}}],"PIcoPI":["517663"],"PO":["200829"]},"70711":{"abstract":"ABSTRACT<br\/>0203932<br\/>Gortler, Steven<br\/>Harvard University<br\/><br\/>Image based rendering is a promising area of innovation in computer graphics. In image based rendering,<br\/>one starts with an input set of images or a video sequence. One then applies some degree of processing<br\/>to this data to obtain an intermediate representation. This intermediate representation is then used in an<br\/>interactive computer graphics setting. These interactive uses include but are not limited to: viewing the<br\/>scene from novel points of view that were not available in the input sequence, relighting the scene using<br\/>virtual lights that were not available in the input sequence, and geometrically manipulating the objects that<br\/>make up the scene. This functionality greatly enlarges the uses of digital photographs, and introduces a rich<br\/>source of content for use in interactive computer graphics.<br\/>For image based rendering, we plan to focus on lumigraph representations, which are a sampled repre-sentation of the light that travels along the rays in the scene. In particular, the visual information of a static scene is represented by the five dimensional radiance function. This function describes the intensity and color of light for every 2D direction at every 3D spatial position (x; y; z). If we consider only the<br\/>subset of light leaving the convex hull bounded object (or equivalently entering a bounded empty region of<br\/>space), the fact that radiance along any ray remains constant 1 allows us to reduce the domain of interest of<br\/>the radiance function from five to four dimensions.","title":"Irregular and optimized representations for image based rendering","awardID":"0203932","effectiveDate":"2002-07-01","expirationDate":"2005-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2865","name":"NUMERIC, SYMBOLIC & GEO COMPUT"}}],"PIcoPI":[183052],"PO":["532791"]},"70832":{"abstract":"EIA-0204267<br\/>Good, Mary L., Mitchell, William M.<br\/>U. Arkansas, Little Rock<br\/><br\/>Title: The Research Component of a Model IT College<br\/><br\/><br\/>This ITWF award provides support to the University of Arkansas, Little Rock to use the tools of IT to serve the educational enterprise in the same way that these tools support business enterprises. In 1999 the state of Arkansas recognized the shortage of IT workers and created the College of Information Science and Systems Engineering, called the Cyber-college of Arkansas, at the University of Arkansas at Little Rock. The Cyber-college will design a database that will house data on every facet of the college's recruitment and first-year student experience across four computer-based four-year degree programs. The database will:<br\/><br\/>provide a test-bed for conclusions derived from demographic and pedagogic research from other studies.<br\/><br\/>be mined for new associations and clusters of experience and behavior patterns that will suggest research in new directions.<br\/><br\/>provide data on the IT students of Arkansas and on the efficacy of the various strategies that the Cyber-college has implement to achieve its mission.<br\/><br\/>prototype recruitment and retention databases that could be installed in other IT college and thereby contribute an important tool to further the understanding of the efforts of IT colleges to serve underrepresented population groups.<br\/><br\/>Once built, this dynamic data model will be sustained within the Cyber-college and the data that it collects and the analysis that it engenders will provide insight to the longitudinal problem of maintaining the supply of college-trained professionals in the IT workforce nationally.","title":"ITWF: The Research Component of a Model Information Technology (IT) College","awardID":"0204267","effectiveDate":"2002-07-01","expirationDate":"2005-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1713","name":"WORKFORCE"}},{"dir":{"id":"11","name":"Directorate for DIRECT FOR EDUCATION AND HUMAN RESOURCES","abbr":"EHR"},"div":{"id":"1104","name":"Division of UNDERGRADUATE EDUCATION","abbr":"DUE"},"pgm":{"id":"7427","name":"CCLI-EDUCATIONAL MATERIALS DEV"}}],"PIcoPI":[183345,"309750",183347],"PO":["289456"]},"70876":{"abstract":"Cluster computing systems are becoming increasingly popular for<br\/>providing cost-effective and affordable computing environments for a<br\/>range of applications (such as databases, data mining, visualization,<br\/>collaborative computing, and high performance computing). These<br\/>applications require four fundamental communication services from the<br\/>underlying communication subsystem: point-to-point communication,<br\/>collective communication, synchronization, and Quality of Service<br\/>(QoS). Modern Network Interface Cards (NICs) for clusters incorporate<br\/>one or more programmable processors, DMA channels, and large amount of<br\/>memory. The NICs are becoming faster, smarter, and intelligent and are<br\/>being designated as Active Network Interfaces. Research is proposed<br\/>along the following directions to take advantage of such active<br\/>network interfaces for implementing and delivering scalable<br\/>communication services for next generation clusters: 1) Using<br\/>multi-CPU NICs and their architectural features to provide fast<br\/>point-to-point communication, 2) Designing NIC-level support for<br\/>high-performance and scalable collective communication and<br\/>synchronization, 3) Taking advantage of programmable NIC-level<br\/>features to provide QoS support, and 4) Experimentally evaluating the<br\/>benefits of the new\/enhanced communication services for a wide range<br\/>of applications using message passing programming model. Through<br\/>extensive theoretical, experimental, and simulation studies, NIC-based<br\/>solutions are planned to be designed, developed, implemented, and<br\/>evaluated for clusters with Myrinet and Gigabit Ethernet<br\/>interconnects.","title":"Network Interface Support for High-Performance and Scalable Communication Services in Clusters","awardID":"0204429","effectiveDate":"2002-07-01","expirationDate":"2005-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"2876","name":"DISTRIBUTED SYSTEMS"}}],"PIcoPI":["561947"],"PO":["309350"]},"70569":{"abstract":"The research component of the proposal is to explore a new methodology for clock networks that explicitly accounts for the interplay between the various design factors. The educational component will provide graduate student researchers with an interdisciplinary training in VLSI, optimization, and numerical computing. Furthermore, the research results will be integrated in graduate courses at Purdue University.<br\/>The design of clock networks is a fundamental problem in synchronous circuit synthesis, and requires trading off between design effort, physical resource costs and performance. Most existing clock design methodologies do not explicitly perform this trade-off. Instead, a design is first proposed, and then evaluated in terms of physical resource costs and performance, and the design repeated if necessary. As a large number of such iterations may be required, the design effort is minimized with some simplifying assumptions. One of these artificially imposed constraints is that of ``zero-skew'', where it is required that all elements are clocked (i.e., switch) at the same time-instant. This requirement constrains the physical layout of clock distribution networks, as the variation in the arrival of the clock signal at the various switching elements must be held small. Perhaps more important, as all circuit elements switch together, the demand from the power supply is not uniform over time but peaks sharply once every clock cycle. This uneven demand on the power supply leads to what is commonly referred to as power-supply noise: As the demands on the power supply peak sharply, its ability to deliver power degrades, leading to possibly degraded performance of the circuits.<br\/>With these observations serving as the backdrop, we propose to develop a design methodology for clock networks that employs nonzero clock skews, and directly addresses the interplay between various factors that determine the trade-off between the design effort, physical resource costs and performance. We present preliminary results that show that our approach holds much promise. Specifically, we propose to perform together scheduling and synthesis of clock networks such that both power supply noise and physical resource costs are reduced. Essential to our objectives is the efficient analysis of power supply noise. We propose a framework and techniques for power-supply noise analysis that draw upon our past successes with model reduction techniques for interconnect modeling both in the time and frequency domain.","title":"Reliability Analysis and Robust Synthesis of HIgh-Performance Clock Networks.","awardID":"0203362","effectiveDate":"2002-07-01","expirationDate":"2006-12-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4710","name":"DES AUTO FOR MICRO & NANO SYS"}}],"PIcoPI":["332293","475378"],"PO":["562984"]},"72406":{"abstract":"CCR-0210176<br\/>Crommie, Michael<br\/><br\/>This proposal was received in response to the Nanoscale Science and <br\/>Engineering initiative, NSF 01-157, category NIRT. The main objective of this project is to develop and characterize mechanical devices at the nanoscale. This will be performed through the creation of new, synthetic molecular machines purposefully designed in a molecule-by-molecule fashion. In order to achieve this goal an interdisciplinary team of researchers has been gathered that will engage in the following <br\/>activities:<br\/>1) chemically synthesize new molecules having tailored properties to be used as nano-machine components, 2) adhere newly synthesized molecules to prepared surfaces and demonstrate mechanical functionality, 3) combine photolithographic MEMS technology with carbon growth techniques to create electro-mechanically actuated molecular motors from carbon nanotubes. Two new categories of functional molecular assemblies are expected to result from this research. The first involves chemically engineered molecules designed with specific mechanical functions in mind. This research thrust will be supported by a strong chemical synthesis effort aimed at the development of new classes of molecules able to undergo conformational changes when triggered by an outside stimulus. The second category involves the engineering of multi-wall carbon nanotubes to form the basis of a new mechano-molecular technology. This effort is expected to culminate in the demonstration of the first functional nanotube motor.","title":"NIRT: Synthesis and Control of Molecular Machines","awardID":"0210176","effectiveDate":"2002-07-15","expirationDate":"2008-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1674","name":"NANOSCALE: INTRDISCPL RESRCH T"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2878","name":"SPECIAL PROJECTS - CCF"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0503","name":"Division of SHARED CYBERINFRASTRUCTURE","abbr":"SCI"},"pgm":{"id":"1710","name":"CONDENSED MATTER PHYSICS"}}],"PIcoPI":["512340","403380","557556"],"PO":["550859"]},"72549":{"abstract":"Timp, Gregory<br\/>CCR-0210843<br\/><br\/><br\/>This proposal was received in response to the Nanoscale Science and Engineering initiative, NSF 01-157, category NIRT. As research in nanotechnology extends its tools for miniaturization and integration to nanometer dimensions (the scale of the secondary structure in a protein or a DNA molecule), new vistas in biology and information science are revealed, which require new multi-disciplinary approaches to <br\/>both research and education. One new question that emerges is: Can biology be directly integrated with electronics to provide information on physiology? Nature has provided an electrical interface between biology and the environment through ion channels that can now be mimicked using nanotechnology.<br\/>The main objective of this project is to develop a revolutionary type of silicon integrated circuit that incorporates Metal-Oxide-Semiconductor technology with an on-chip nanopore mechanism for probing the electrical activity of DNA molecules. Ultimately, this biosensor might enable fast, inexpensive <br\/>characterization of the minimum volume of genetic material, a single strand of DNA. A key constraint is to achieve the required sensitivity. To accomplish these goals, an artificial ion channel (AIC) or nanopore, will <br\/>be used in conjunction with an amplifier built within one micron from the nanopore, in order to process high-frequency electrical signals occurring when single molecules diffuse through the channel. A membrane having an AIC will be immersed into a buffer solution, and DNA molecules will be pushed through the nanopore by the applied voltage bias a principle that has been tested in a number of recent experiments. Preliminary tests have already successfully demonstrated that ~2-nm diameter nanopores can be reproducibly etched through a ~2-5-nm-thick SiO2 membrane, using a high energy focused electron beam. High-quality, <br\/>pinhole-free membranes are being used in these experiments. The project will develop artificial ion channels for ultrafast sequencing of single DNA strands. The AIC devices will also be applied for direct measurements of electronic transport properties of DNA molecules. This subject is important <br\/>since the charge migration in DNA has been linked to the DNA ability to develop and repair defects while being exposed to ionizing radiation. Also, the desire of using single DNA molecules as building blocks for electronic <br\/>circuits motivates the quest for understanding its transport properties. So far transport properties of DNA have been tested either indirectly or when the molecule is removed from the buffer solution and dried. The AIC device proposed here will be applied to measure directly the long-range charge transfer along DNA, while the molecule is kept in its natural environment in solution. The measurements will be compared with <br\/>first-principle atomistic simulations. The objective is to understand basic mechanisms that control the charge transport in DNA this controversial topic continues to be strongly debated in the community.","title":"NIRT: A Nanometer-Scale Gene Chip","awardID":"0210843","effectiveDate":"2002-07-15","expirationDate":"2006-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2878","name":"SPECIAL PROJECTS - CCF"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0506","name":"Division of EXPERIMENTAL & INTEG ACTIVIT","abbr":"EIA"},"pgm":{"id":"2884","name":"NEXT GENERATION SOFTWARE PROGR"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0702","name":"Division of CHEM, BIOENG, ENV, &  TRANSP S","abbr":"CBET"},"pgm":{"id":"1517","name":"ELECT, PHOTONICS, & MAG DEVICE"}}],"PIcoPI":[188017,"506211","445336","535303"],"PO":["325495"]},"71108":{"abstract":"Securing our nation's computing and networking infrastructure against damage due to malicious attacks or spontaneous faults is a problem of paramount importance. This project aims to contribute to this mission<br\/>by developing novel techniques and tools based on model checking and program analysis for vulnerability analysis: the problem of identifying and monitoring weaknesses in computer systems that can be exploited to compromise system security. A major expected outcome of the project is a set of tools for determining the consistency and safety of computer system configurationss, such as those specified by firewall rules<br\/>and domain type rules.","title":"ITR: Model Checking for Detecting Computer System Vulnerabilities","awardID":"0205376","effectiveDate":"2002-07-15","expirationDate":"2007-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1687","name":"ITR MEDIUM (GROUP) GRANTS"}}],"PIcoPI":["451745","518366","550275","477226","531979"],"PO":["521752"]},"70800":{"abstract":"ABSTRACT <br\/>0204157<br\/>Funderlic, Robert E.<br\/>North Carolina State U<br\/><br\/>This section summarizes the progress the co-PI has made under the support of NSF grants DMS-9804759<br\/>(07\/01\/98 06\/30\/00)for the project Adaptive Control Algorithm for Adaptive Optics Applications and<br\/>DMS-0073056 (08\/01\/00 7\/31\/03)for the project Algorithms for the Inverse Problem of Matrix Con-<br\/>struction of the former,the objectives are to design,analyze,and evaluate adaptive control algorithms for<br\/>adaptive optics applications.The co-PI has established a mathematical framework for the linear econstructor<br\/>problem in adaptive optics,and has made progress in the understanding of a latency-delay control algorithm.<br\/>Fo the latter,the proposed objectives were to investigate both the theory and the practice of constructing a<br\/>physical model,described mathematically in the form of a matrix,from prescribed spectral data.The co-PI<br\/>has collected,classi .ed,and de .ned the egimen of inverse eigenvalue problems as a whole,and has developed<br\/>new numerical methods for tackling some inverse eigenvalue problems.Thus far,a signi .cant portion of these<br\/>objectives has been accomplished under the NSF support as is evidenced below.","title":"The Centroid Decomposition and Other Approximations to the SVD","awardID":"0204157","effectiveDate":"2002-07-01","expirationDate":"2007-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2865","name":"NUMERIC, SYMBOLIC & GEO COMPUT"}}],"PIcoPI":["549174","549174",183271],"PO":["381214"]},"70624":{"abstract":"ABSTRACT<br\/>0203586<br\/>Johnstone, John<br\/>U of Alabama @ Birmingham<br\/><br\/>The work of this proposal can be divided into three categories: (1) the study of dual representations of<br\/>the tangent space of a curve and surface, (2) the application of these dual representations to the computation<br\/>of bitangency, and (3) the application of bitangency to several problems in geometric modeling, computer<br\/>graphics and robotics such as visibility, lighting and motion.<br\/>The problem that binds together these areas of study is bitangency. There are basically three bitangent<br\/>structures: the bitangent line (a line that is tangent to two curves), the bitangent plane (a plane that<br\/>is tangent totwo surfaces), and the bitangent developable (the envelope of a familyof bitangent planes).<br\/>While the tangent is important in the analysis of individual curves and surfaces in isolation, the bitangent<br\/>is important in the analysis of collections of curves and surfaces, since it relates two curves or two surfaces.<br\/>As the analysis of large scenes becomes increasingly important, the bitangent becomes an important tool.","title":"The Geometric Modeling of Bitangency","awardID":"0203586","effectiveDate":"2002-07-15","expirationDate":"2006-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2865","name":"NUMERIC, SYMBOLIC & GEO COMPUT"}}],"PIcoPI":["393645"],"PO":["321058"]}}