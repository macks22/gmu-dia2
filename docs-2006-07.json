{"120131":{"abstract":"The Directorate for Computer and Information Science and Engineering (CISE) and the CISE research community are planning an initiative called Global Environment for Networking Innovations or GENI to explore new networking capabilities that will advance science and stimulate innovation and economic growth. The GENI Initiative responds to an urgent and important challenge of the 21st Century to advance significantly the capabilities provided by networking and distributed system architectures.<br\/>To have significant impact, innovative research and design ideas must be implemented, deployed, and tested in realistic environments involving significant numbers of users and hosts. The initiative includes the deployment of a state-of-the-art, global experimental GENI Facility that will permit exploration and evaluation under realistic conditions. The GENI Facility will permit a range of researchers, including network engineers, policy analysts, protocol designers, system architects, and economic modelers to contribute to and study innovative new capabilities for the global network of the future. Assuming the concept proves to be as promising as currently anticipated, GENI construction will be considered for funding from NSF's MREFC account.<br\/><br\/>In support of making the case for GENI as a MREFC project, the PIs propose to undertake a set of tasks to advance the GENI project definition from the Conceptual Design, through the MREFC Readiness Stage, to Preliminary Design. This will involve addressing a set of design issues; taking the definition of various components of the facility to the next level of specificity; creating a detailed work breakdown structure (WBS), bottom up budget, schedule, contingency, and critical path analysis for each component and the facility as a whole; and taking the project management definition for construction and operation to the next level of specificity with due considerations to special requirements of GENI.","title":"Collaborative Research: Facility for Experimental Network Architecture Research","awardID":"0631422","effectiveDate":"2006-07-01","expirationDate":"2008-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"024F","name":"GENI CONCEPT\/DEVELOPMENT"}}],"PIcoPI":["560046","531675"],"PO":["495796"]},"115753":{"abstract":"Scintillators are usually consist of a transparent insulator and an impurity that functions as a luminescence center. They are often slow or how low efficiency. Colloidal nano-crystals in liquids, sol-gel and organic polymers will be developed. The nano-crystal surface will be modified to make them soluble. The optical response will be investigated and results compared across systems. The work will provide the first studies of the optical response of colloidal nano-crystals to irradiation. It is anticipated that this effort will lead to identification of high-efficiency, fast scintillators utilizing 3D confinement of electrons and holes in nano-crystals. It will provide a systematic database of gamma ray and neutron response and characterization of nano-crystals. The work will contribute to the investigation of basic radiation effects on nano-crystals and their utilization in handheld, efficient detectors of nuclear radiation. The work should have a major impact on the development of scintillating materials and expand the range to nano-crystals. The groups actively engages undergraduate students in the research through a specialized program focused on recruitment, mentoring, retention and graduation of members of underrepresented groups.","title":"Exploratory Studies of Optical Response to Gamma and Neutron Radiation of Doped and Undoped II-VI, III-V, and Novel Scintillating Core\/Shell Nanocrystals [UNM_FY06_025]","awardID":"0610201","effectiveDate":"2006-07-01","expirationDate":"2011-12-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"H186","name":"Defense Intelligence Agency"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"I331","name":"Defense Intelligence Agency"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"T377","name":"DIA-MASINT CONSORTIUM PROJECT"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"T489","name":"DIA-MASINT CONSORTIUM PROJECT"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"T768","name":"DIA -MASINT RESEARCH PROJECT"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"J265","name":"Defense Intelligence Agency"}}],"PIcoPI":["474428"],"PO":["565136"]},"116633":{"abstract":"Open software systems made up of independently developed components interacting using agreed-upon protocols represent one of the most promising approaches for supporting applications where organizations of all kinds, which often have not previously worked together, must be assembled and reconfigured within small time frames on the infrastructures at hand (e.g., coalition military forces, disaster recovery operations, supply chains, collaborative engineering projects, and electronic marketplaces). Ensuring that such systems are reliable is a challenge; the very openness that makes open systems attractive places them in a realm where the potential failure modes ('exceptions') and associated exception handling techniques are numerous and often far from obvious. Components may not operate correctly; they may lie to get an advantage, even act maliciously. We cannot view or manipulate their code or internal state. And since there is no one component 'in charge', we must be prepared to deal with emergent problems with non-local causes and effects. The problems are exacerbated by the wide range of possible open system interaction protocols, ranging from constraint satisfaction to markets to swarms, each with their own unique set of potential exceptions and relevant handlers. Unfortunately, existing techniques do little to help us design more reliable open systems; designers must rely on their experience and intuition to determine what exceptions apply to their particular system, and how those exceptions can best be addressed. In this project, the PI will tackle this gap by helping groups of collaborating software designers rapidly search through the vast space of possible open system designs for ones that they agree will be reliable and effective for their particular application. To do this, he will integrate and extend two powerful innovations that have not been applied in software engineering contexts heretofore. The first is a taxonomically organized knowledge base of open system coordination mechanisms, with each mechanism linked to its characteristic exceptions and each exception linked to its possible handlers. This knowledge base defines, by delineating a set of orthogonal design dimensions, a very large space of possible open system designs. The second innovation is a family of negotiation algorithms that help designers with diverse interests rapidly converge on pareto-optimal (win-win) design agreements in such large nonlinear design spaces. Very little work has been done to date on nonlinear negotiation (i.e., negotiation with interdependent issues), and this work has focused exclusively on \"flat\" design spaces (with a static set of predefined design dimensions). This project will push forward our understanding of how to find pareto-optimal solutions with taxonomically structured design spaces, a formalization that is potentially applicable to a wide range of important real-life product and process design challenges.<br\/><br\/>Broader Impacts: This work will help us design robust open systems more quickly and effectively, and will in particular help students and educators by providing a comprehensive and well-organized knowledge base of open system coordination and exception handling expertise. It will develop negotiation algorithms for complex contracts, a challenge relevant to domains ranging from defining electronic commerce to airplane design. The results will be broadly disseminated, via web-accessible software as well as traditional media.","title":"SoD-HCER: Using Non-Linear Negotiation to Enable the Design of Robust Open Software Systems","awardID":"0613819","effectiveDate":"2006-07-15","expirationDate":"2008-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7372","name":"ITR-SCIENCE OF DESIGN"}}],"PIcoPI":["427334"],"PO":["565227"]},"116249":{"abstract":"New technologies for collecting genotypic data from natural populations open the possibilities of investigating many fundamental biological phenomena, including behavior, mating systems, heritabilities of adaptive traits, kin selection, and dispersal patterns. Mining the emerging genotype data for ecological and evolutionary information is one of the most challenging problems in modern biology. Yet full utilization of the genotypic data is only possible if statistical and computational approaches keep pace with our ability to sample organisms and obtain their genotypes. The power and potential of genotypic information often rests in our ability to reconstruct genealogical relationships among individuals. Current computational methods for kinship (lower order pedigree) reconstruction have been developed mainly in the context of human populations. Natural populations pose unique computational and scientific challenges for genetic research: data collection is often limited to a demographic subgroup, such as juveniles; test data for the population under study is rarely available; the number of used genetic markers is relatively small, and typical family sizes can be orders of magnitude larger than in humans. Almost all currently available kinship reconstruction methods are statistical and thus are sensitive to noisy and incomplete data and require a priori knowledge about various parameter distributions, a difficult condition to satisfy in natural populations. The goal of the proposed research is to develop a robust computational method for reconstructing kinship relationships from microsatellite genetic data. The proposed method uses the fundamental genetic laws of inheritance to limit the genetic configurations of possible kinship relationships and powerful optimization techniques to find among those the most parsimonious. The resulting familial reconstruction method requires sampling a minimal number of generations, uses few assumptions about the structure of the data, and relies on little prior knowledge about the sampled population. The diverse tasks of this project include biological modeling, algorithm design and implementation, optimization integration, and experimental validation, many of which may be of use beyond the scope of genetics. The research team will leverage diverse expertise of its members in molecular genetics, mathematical modeling, experimental and theoretical computer sciences to develop accurate and effective methods for familial relationships reconstruction. The proposed interdisciplinary research will have broader impacts on diverse research communities. Improved methods of analysis and inference of kinship relationships open the door to asking new biological questions. The combined advantages of the proposed approach would be applicable to and useful not only for population biology but to various areas of the life sciences, including conservation and management of endangered species, animal behavior, evolutionary genetics, human genealogy, forensics, and epidemiology, any time familial relationships must be inferred from genetic data. The research and software resulting from the proposed project will be disseminated both in computational and biological communities and enhanced by cross-disciplinary training activities. The diverse scientific tasks that comprised the proposed research are suitable for a wide range of students in biology and computer science and will serve to train a new generation of interdisciplinary scientists.","title":"Collaborative Research: SEI: Computational Methods for Kinship Reconstruction","awardID":"0611998","effectiveDate":"2006-07-01","expirationDate":"2010-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7294","name":"SCIENCE & ENGINEERING INFORMAT"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7602","name":"INFORMATION INTEGRATION"}}],"PIcoPI":["555420"],"PO":["565136"]},"110485":{"abstract":"Abstract<br\/>--------<br\/><br\/>CCF-0540818<br\/>Matthias Felleisen<br\/>Northeastern University<br\/><br\/>Interface-Oriented Programming<br\/><br\/><br\/>Conventional wisdom in the software community demands that software engineers program to interfaces just like engineers in physical disciplines construct artifacts from off-the-rack components with well-defined interfaces. Empirical data shows, however, that programmers do not use interfaces even in programming languages (such as C# and Java) that support them with explicit syntax.<br\/><br\/>The objective of this project is to investigate a radical approach to interface-oriented programming. The PI and his students will design and implement a programming language in which programmers must program to interfaces. Time permitting, they will also explore the construction of supportive software tools for refactoring existing programs into interface-oriented code. Based on these first steps, they will then explore how (student) programmers work in such a radically interface-oriented context and what effects it has on software design. The lessons learned from this investigation will have a broader impact than just the immediate academic research community. It will help the designers of programming languages with the next<br\/>generation of OOP languages; it will suggest how programming environments can assist programmers with software tools to achieve certain standards; and it will provide guidance to software engineering educators who wish to teach interface-oriented programming.","title":"Interface-Oriented Programming","awardID":"0540818","effectiveDate":"2006-07-01","expirationDate":"2011-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2880","name":"SOFTWARE ENGINEERING AND LANGU"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7352","name":"COMPUTING PROCESSES & ARTIFACT"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7798","name":"SOFTWARE & HARDWARE FOUNDATION"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7943","name":"PROGRAMMING LANGUAGES"}}],"PIcoPI":["475166"],"PO":["564388"]},"116854":{"abstract":"ACLI-ware: Dynamic Data Driven Control for Wirelessly Implemented Application Systems<br\/><br\/>This project creates an end-to-end management solution for mobile computing that incorporates aspects from the physical wireless communication medium through application requirements. Our middleware<br\/>(ACLI-ware) moves abstracted information towards higher layers, making them channel aware, and conveys constraints and requirements towards lower layers, making them application aware. In providing applications channel awareness, information about the wireless channel, battery power, neighbors and their distances, lengths of routes, etc. are abstracted from the lower layers towards higher layers. For example, the appearance of a metallic wall may require selecting alternate routes and defining new communication clusters. On the other hand, a dense network requires clever interference-mitigation algorithms and fair-scheduling and routing algorithms. This information is also used by the application to throttle sending rates or adapt data fidelity. To achieve application awareness, applications' constraints such as latency, fairness, quality of service, etc. influence the algorithms used at lower layers. For example, tight latency constraints can lead to smaller communication clusters, shorter allowable routes and quick feedback algorithms from the physical medium. On the flip side, a high bandwidth\/throughput requirement entails optimal clustering and high fidelity channel-feedback.<br\/><br\/>This project couples two components seldom brought together: and use of physical channel information for adaptation and the elicitation of application constraints to impact communication characteristics. Thus, there are two key innovations in ACLI-ware: (a) interaction amongst layers, with each layer depending on the other layers' inputs and (b) dynamic solutions, with algorithms that adapt in real-time to varying channel conditions and system requirements.","title":"CSR--SMA: ACLI-Ware: Dynamic Data Driven Control for Wirelessly Implemented Application Systems","awardID":"0615061","effectiveDate":"2006-07-15","expirationDate":"2008-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["539208","527052"],"PO":["551712"]},"116887":{"abstract":"Increasingly, computing trends are leading to a new class of distributed <br\/>and highly-dynamic applications in which spatial-awareness plays a central role. <br\/>Spatially-aware applications rely on absolute or relative information about the geographic position of compute devices in order to support novel functionality. While many spatial application drivers already exist in mobile and distributed computing, very little support exists for programming these applications, expressing their spatial and temporal constraints, and supporting optimization layers for efficient implementation on real-world, highly-dynamic platforms. <br\/>This research addresses these shortcomings by providing language- and <br\/>system-layer support for expressing and optimizing spatial applications. <br\/>Since spatial computing is inherently distributed, close attention is given to resource sharing and management within and across programs. <br\/><br\/>The project's SARANA system architecture includes (i) a programming language that allows users to express the spatial region of interest and the quality of <br\/>result required, (ii) a compiler that can optimize the program so it uses resources more efficiently, and (iii) a runtime system that dynamically installs and migrates the program onto physical nodes whose resource availability match its resource needs. <br\/>A resource cost model permeates all the system layers of SARANA, permitting users to express their resource needs and quality of result requirements in terms of cost-benefit tradeoffs. . The runtime system prices resources and services, in order to broker agreements regarding resource needs and availability. <br\/>SARANA's driving applications include an early warning system to find <br\/>abducted children (Amber Alert), an earthquake monitoring system, and <br\/>multi-user gaming networks.","title":"Collaborative Research: CSR-EHS: A Resource and Space Aware Computing Architecture for Dynamic Networks","awardID":"0615175","effectiveDate":"2006-07-01","expirationDate":"2011-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["421129"],"PO":["561889"]},"119528":{"abstract":"Since 2000, voting systems and ballot designs have been the subject of an increasing volume of research on the part of political scientists and other researchers. The effort began with statistical studies of the 2000 election and accounts of what went wrong; these focused on the 'butterfly ballot' in Florida and then so-called residual vote across the United States. Many recent studies have used the residual vote concept to explore intentional under-voting, ballot formats, and variations in specific voting technologies. Another stream of researc has focused on usability concerns, such as the accuracy with which individuals cast their votes as intended on different voting systems and ballot styles. Two other issues have recently captured a great deal of public attention , the ability of voters to verify their votes were cast correctly using a paper receipt or some other medium, and the provision of an audit trail election officials can use to resolve close elections or to determine whether election tampering has occurred. This pilot project investigates the impact of different vote verification\/election audit sytems (VVEASs) on the quality of individuals' voting experiences. VVEASs allow voters to review a paper receipt, view a separate video monitor, hear an audio recording to verify that their ballot has been correctly cast, or check an Internet website to verify that their ballot has been counted. This pilot project involves expert reviews of the various systems along with systematic tests of voter responses to different verification systems. Points of comparison include the degree to which the systems are judged easy to use and understand, the confidence they instill among voters that their votes were accurately recorded and are accurately counted, their impact on the perceived privacy of the vote, whether voters find them distracting, and whether voters need help using them. This project is guided by regular interaction with practitioners and policy makers who are responsible for the administration of elections in the United States. Interaction allows these individuals and agencies to disseminate information about the project, encourage potential beneficiaries to review the findings and use the test protocol, and communicate project findings and recommendations to companies that manufacture VVEASs.","title":"SGER: Usability Study of Independent Voter Verification Systems","awardID":"0628033","effectiveDate":"2006-07-15","expirationDate":"2007-12-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1706","name":"DIGITAL GOVERNMENT"}}],"PIcoPI":[317018,"426438",317020],"PO":["371077"]},"122113":{"abstract":"Microcantilevers that are properly functionalized with chemo- or bioselective coatings have been shown to be extremely sensitive to chemical and biological analytes in both vapor and liquid media. Microcantilevers<br\/>therefore exhibit great promise as molecular and atomic recognition sensors for an extremely diverse set of<br\/>applications including environmental monitoring, contamination detection, and recognition of explosives and chemical and biological agents. Microcantilever operation is characterized by chemical reaction or adsorption of molecular species at the microcantilever surface which results in a change in the microcantelever's deflection and in properties such as its resonance frequency. While these induced changes can be very small (sub-nanometer cantilever deflection, for example), they are readily measurable with a laser beam reflection technique developed for atomic force microscope (AFM) cantilever measurements. To realize the full promise of microcantilever sensor technology, arrays of individually functionalized microcantilevers are required to enable the simultaneous detection of multiple target molecules while rejecting interference from other chemical species in the environment as well as stochastic noise such as thermal fluctuations. A critical problem is that current cantilever measurement methods do not lend themselves to practical implementation for large numbers of cantilevers that are suitable for high sensitivity operation in both vapor and liquid ambients. Asolution to this problem based on waveguide cantilevers combined with a receiver waveguide splitter structure that enables differential detection of cantilever deflection has been proposed.<br\/><br\/>Combining these elements with compact waveguide components and with grating couplers to enable fiber<br\/>coupling to off-chip detectors and an off-chip optical source permits the realization of small microcantilever-based sensors with interchangeable or disposable microcantilever array chips. Compatibility of the waveguide structures with batch microfabrication techniques suggests that such arrays can be produced very inexpensively. Initial analysis indicates that the proposed waveguide cantilever array sensor offers an attractive path for the realization of practical, highly functional sensors. <br\/><br\/>The proposed work concentrates on an important aspect of the development of a general photonic<br\/>microcantilever array-based sensor platform that relies on a compact integrated optical readout mechanism to realize scalable, small area microcantilever arrays. A successful research and development effort will lay the foundation for microcantilever arrays to become a common and easy to use high sensitivity sensor for many application areas relevant to MASINT missions. The elements of waveguide microcantilever sensors to be explored in the proposed work build directly on the experience and expertise of the PI and his group.<br\/><br\/>Microcantilever array sensors have applications in a broad variety of DoD and non-DoD arenas. These include homeland defense, pathology diagnositics, industrial process control, biomedical instrumentation and research, gene assays, proteomic research, and microfluidics.","title":"MEMS-Based Chemical and Biological Sensors [UAH_FY05_074]","awardID":"0641973","effectiveDate":"2006-07-31","expirationDate":"2011-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"H186","name":"Defense Intelligence Agency"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"I153","name":"Defense Intelligence Agency"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"I331","name":"Defense Intelligence Agency"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"T377","name":"DIA-MASINT CONSORTIUM PROJECT"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"T489","name":"DIA-MASINT CONSORTIUM PROJECT"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"T885","name":"DIA-MASINT"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"J265","name":"Defense Intelligence Agency"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"T046","name":"CIA-MIPR TO NSF GREGORY NORDIN"}}],"PIcoPI":["462857"],"PO":["565136"]},"116844":{"abstract":"0Current technology trends of silicon transistor devices are quickly reaching a stage where the atomic scale of such devices will heavily affect their reliability. Leading technology experts have started warning computer designers that device reliability will begin to wane heavily in the next five to ten years. This will lead to skyrocketing manufacturing costs and severely shortened product lifetimes. To address such an important and imminent problem, this research focuses on the development of effective, low-cost mechanisms to protect a computing system from silicon defects, both those occurring during manufacturing and those that occur while the device is in operation in the field. The objective is to provide solutions that detect the occurrence of a failure, correct any affected computation, and repair the hardware silicon fabric, all with minimal cost and performance impact. <br\/><br\/>To assess the upcoming exposure to silicon defects, this project includes the development of a high-level silicon reliability modeling infrastructure, based on high performance simulation software and high-level modeling of the failure mechanisms. Once this exposure is analytically evaluated, the core of the research investigates solutions which attack the problem by exploring a novel combination of cost-efficient online defect testing and novel memory management. These two powerful technologies combined have the potential to lead to solutions that provide at least as much reliability as traditional approaches, but at significantly lower cost. Initial studies suggest that such solutions are much less expensive than previously proposed defect-tolerance techniques, due to the time and space efficiency of the underlying mechanisms.","title":"CSR---EHS: Ultra low cost system-level defect protection","awardID":"0615005","effectiveDate":"2006-07-01","expirationDate":"2011-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":[309179,"517965"],"PO":["561889"]},"120750":{"abstract":"Evidence chaining and \"dipping\" are powerful analytical paradigms to explore entities and their connections in semantically rich, multi-source databases. Starting from a small set of seeds such as known suspects or the result of some exploratory query, an analyst can draw from various data sources to explore the space of entities connected to these seeds via any number of relations. However, since there are often many relations, facts, attributes and transactions associated with each entity, they can be richly interconnected which can quickly lead to very large numbers of objects linked to the initial seeds.<br\/><br\/>Relationship simplification is one approach to reduce this space effectively and provide a more abstract view for analysts by (1) reducing the number of different relations through abstraction and normalization, and (2) focusing on strongly and relevantly connected objects by computing a measure of connection strength or relevance. To address (1) we propose to use knowledge representation and reasoning (KR&R) technology, which allows us to represent evidence at very high fidelity, utilize sophisticated ontologies and domain theories, have a natural means to represent abstraction and meta-knowledge, map easily between different representations and exploit powerful inference procedures to make implicit relationships explicit. To address (2) we need to consolidate and aggregate all relations between two objects, statistically contrast them with connections to and among other entities and compute a measure of closeness or interestingness to filter out irrelevant or uninteresting objects and connections. To dynamically compute connection strength, we propose to use an information theoretical model to determine the weight of each relation as well as to take the context of a relationship into account. This will allow us to aggregate all relations between objects and measure closeness between them to simplify a large data space and compress it into a more abstract, simplified view.<br\/><br\/>We will integrate the Relationship Simplifier with the BLACKBOOK system for uniform access to data and results and communication with other components. In addition, our components can also access relational data directly from one or more relational databases which is useful when dealing with very large datasets.","title":"A Hybrid KR&R\/Information Theoretic Model for Relationship Simplification","awardID":"0634849","effectiveDate":"2006-07-15","expirationDate":"2008-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"T472","name":"CIA-KNOWLEDGE DISC & DISSEM PR"}}],"PIcoPI":["427568",320851],"PO":["565136"]},"120871":{"abstract":"In this research project, the PI proposes to develop novel methodology to visualize and interact with large interconnected high-dimensional datasets represented as large unstructured graphs. The underlying semantics for the nodes and edges in such a graph are to be kept flexible, but the ultimate goal is for an analyst to acquire an understanding of the data universe as a whole, and to enable him or her to issue and resolve specific data queries. An analyst should also have an easy way to inform a colleague about the insights gathered during their own interaction with the system, including evidence chains and new hypotheses.","title":"Scalable Visualization and Constrained Interaction for Large Graphs -- Supporting the Collaborative Analysis of High-dimensional Data Sets","awardID":"0635492","effectiveDate":"2006-07-15","expirationDate":"2010-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"H228","name":"CIA"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"T471","name":"CIA-KDD WORKING GROUP"}}],"PIcoPI":["558448","518684"],"PO":["565136"]},"110564":{"abstract":"Abstract<br\/>CCF-0541123<br\/>David Evans<br\/>University of Virginia<br\/><br\/>Title: CPA: Automatic Inference and Effective Use of Temporal Properties <br\/><br\/>Understanding properties that constrain the ordering and occurrence of events is crucial for the dependability of complex software systems. <br\/>Failures to satisfy needed properties can lead to deadlocks, data races, protocol violations, memory corruption, and incorrect results. There has been considerable progress in model checking and other program verification techniques which, along with improvements in available computing resources, has enabled checking temporal properties for large software systems. A substantial impediment to wider adoption and more effective use of these techniques, however, is the high degree of expertise and substantial effort required to identify important temporal properties and express them using a formal notation. This research seeks to develop techniques for automatically inferring important temporal properties and effectively using them to aid program verification, evolution, and other software development tasks. The project is developing and evaluating a dynamic analysis technique that infers properties from program traces and selects important properties using heuristics. The research will develop new theories and heuristics for measuring the importance of a temporal property that combine static and dynamic analysis techniques as well as producing methods for using inferred temporal properties to aid software development tasks.","title":"Automatic Inference and Effective Application of Temporal Specifications","awardID":"0541123","effectiveDate":"2006-07-15","expirationDate":"2010-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7352","name":"COMPUTING PROCESSES & ARTIFACT"}}],"PIcoPI":["483825"],"PO":["564388"]},"110575":{"abstract":"ABSTRACT<br\/>CCF-0541183<br\/>PI: Daniel Jackson, MIT<br\/><br\/>Deep and Scalable Software Checking<br\/><br\/>The growing role of software in civic infrastructure and the potentially huge costs of software failure make dependable software a pressing need. Technology for developing dependable software will be vital to the US economy in the coming decades.<br\/><br\/>This project is developing a new approach for checking software to ensure that it has the desired high-level properties. In industry, two techniques are widely used: testing, which cannot achieve sufficient coverage to find the defects responsible for low-probability failures, and static analysis (such as type checking), <br\/>which can typically handle only very limited properties, such as the absence of certain kinds of overflow or exception. In research, there has been a renewed interest in deeper techniques that are capable of finding the most subtle defects and thus dramatically increasing the developer's confidence in the correctness of the code. Unfortunately, these have tended not be scalable, since they often require more resources (either in computation or in human effort) than is economical. This project is exploring a new approach that promises <br\/>both depth and scalability, in which a program is checked not for every possible case (which seems to lead to scalability problems), but rather for every case within some finite bounds. The key idea is to generate a logical formula (representing the behaviours of the code), and to present it with a similar formula (characterizing failure to satisfy a required property) to a constraint solver, which then uses powerful search techniques to explore a huge space of potential executions for those that would result in failures.","title":"Deep and Scalable Software Checking","awardID":"0541183","effectiveDate":"2006-07-01","expirationDate":"2010-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7352","name":"COMPUTING PROCESSES & ARTIFACT"}}],"PIcoPI":["335202"],"PO":["562984"]},"120134":{"abstract":"The Directorate for Computer and Information Science and Engineering (CISE) and the CISE research community are planning an initiative called Global Environment for Networking Innovations or GENI to explore new networking capabilities that will advance science and stimulate innovation and economic growth. The GENI Initiative responds to an urgent and important challenge of the 21st Century to advance significantly the capabilities provided by networking and distributed system architectures.<br\/>To have significant impact, innovative research and design ideas must be implemented, deployed, and tested in realistic environments involving significant numbers of users and hosts. The initiative includes the deployment of a state-of-the-art, global experimental GENI Facility that will permit exploration and evaluation under realistic conditions. The GENI Facility will permit a range of researchers, including network engineers, policy analysts, protocol designers, system architects, and economic modelers to contribute to and study innovative new capabilities for the global network of the future. Assuming the concept proves to be as promising as currently anticipated, GENI construction will be considered for funding from NSF's MREFC account.<br\/><br\/>In support of making the case for GENI as a MREFC project, the PIs propose to undertake a set of tasks to advance the GENI project definition from the Conceptual Design, through the MREFC Readiness Stage, to Preliminary Design. This will involve addressing a set of design issues; taking the definition of various components of the facility to the next level of specificity; creating a detailed work breakdown structure (WBS), bottom up budget, schedule, contingency, and critical path analysis for each component and the facility as a whole; and taking the project management definition for construction and operation to the next level of specificity with due considerations to special requirements of GENI.","title":"Collaborative Proposal: Facility for Experimental Network Architecture Research","awardID":"0631456","effectiveDate":"2006-07-01","expirationDate":"2007-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"024F","name":"GENI CONCEPT\/DEVELOPMENT"}}],"PIcoPI":["522381"],"PO":["495796"]},"116856":{"abstract":"With the continuing advancement of MEMS technology, wireless embedded systems are deployed in various kinds of environments from well-controlled laboratories to turbulent ocean floors. System design has made simplifying and sometimes unrealistic assumptions about the resulting communication and sensing patterns. Although embedded devices are normally micro-calibrated individually before deployment, preliminary results indicate that the deployment environment is a dominating factor in communication and sensing characteristics of embedded devices. This research aims at developing a wide spectrum of modeling methodologies and related protocols for large-scale embedded systems under realistic environments. The main objective of this project lies in developing three novel modeling approaches, which complement each other and cover a large cost-benefit design space. The first is to develop a new radio irregularity model based on concepts of degree of irregularity and variance of signaling power. The second seeks a capability for abstraction of a completely repeatable physical environment, using an automated capture-and-replay process. The third features a novel way to use training events in a controlled manner to produce non-parametric realistic sensing and communication patterns. A key challenge for in-situ modeling lies in reconciling the conflict between the in-situ modeling accuracy and the related cost to build and use these models in resource-limited large-scale embedded systems.<br\/><br\/> This project seeks to develop the models from the micro to macro levels where designers can choose the appropriate level of detail based on the accuracy needs, and also the models from parametric to non-parametric types where designers can choose the models with proper costs based on the available resources. The models will be available via common simulation systems, enabling embedded systems designers to develop solutions based on realism and avoid an all-to-common problem found today where solutions developed by simulation don't work in the real world. This, in turn, is expected to have a major impact on embedded systems by saving development time and money and resulting in more efficient, robust, predictable and controllable systems. Research results will be evaluated using traffic-monitoring and management testbeds at the University of Minnesota and the University of Virginia.","title":"Collaborative Research: CSR-EHS: Obtaining Realistic Communication and Sensing In-situ Models for Wireless Embedded Systems","awardID":"0615063","effectiveDate":"2006-07-01","expirationDate":"2008-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["526936"],"PO":["561889"]},"123027":{"abstract":"Concrete Problems in Computational Complexity Theory<br\/><br\/>Nicholas Pippenger<br\/>Department of Computer Science<br\/>Princeton University<br\/><br\/>The goal of computational complexity theory is to determine the <br\/>computational resources needed to carry out various computational tasks.<br\/>The resources measured may involve hardware (such as gates used to <br\/>construct a circuit, or area on a chip) or software (such as the time or <br\/>space used in the execution of a program on a machine), and the tasks <br\/>considered may range from a simple addition of two integers to a large <br\/>algebraic or geometric computation.<br\/><br\/>The proposed research will deal primarily with \"low level\" complexity <br\/>theory, in which the resources required grow modestly (at most quadratically) <br\/>with the size of the task. Examples of such tasks are furnished by the <br\/>arithmetic operations (addition, subtraction, multiplication, division<br\/>and square-root extraction) performed by the execution of single <br\/>instructions in a computer. For these tasks, hardware-oriented resource <br\/>measures are most appropriate in most cases.<br\/><br\/>The proposed research will also explore problems involving fault-tolerant <br\/>computing. There is a classical theory concerning transient errors in <br\/>circuits that delineates fairly clearly the theoretical possibilities and <br\/>limitations in this situation. The proposed research will deal with two <br\/>aspects of fault-tolerant computing about which much less is known:<br\/>permanent errors occurring over time, and transient errors in quantum <br\/>communication and computation. For these questions, hardware-oriented <br\/>resource measures are again most appropriate.<br\/><br\/>The broader impacts of the proposed research lie in the promotion of <br\/>interdisciplinary links between theoretical computer science on one hand, <br\/>and mathematics and physics on the other. It has of course always been the <br\/>case that computer scientists have drawn heavily on techniques and results <br\/>from mathematics and physics, since mathematics and physics form the <br\/>foundations of computer science and engineering. What is proposed here, <br\/>however, is to return the favor by applying methods developed within <br\/>theoretical computer science to problems of interest to mathematicians <br\/>and physicists.","title":"Concrete Problems in Computational Complexity Theory","awardID":"0646682","effectiveDate":"2006-07-01","expirationDate":"2010-08-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"2860","name":"THEORY OF COMPUTING"}}],"PIcoPI":["409892"],"PO":["565157"]},"116878":{"abstract":"In order to eliminate the costs of proprietary systems and special purpose hardware, many real-time and embedded computing platforms are being built on commodity operating systems and generic hardware. Unfortunately, many such systems are ill-suited to the low-latency and predictable timing requirements of real-time applications. This proposal, therefore, focuses on application-specific service technologies for low-cost commodity computing platforms, so that real-time service guarantees can be met. One of the main thrusts of this work is the structure of systems software, so that a common code-base can be reused for a number of diverse applications on a range of commonly-used (but contrasting) hardware. Novel methods for providing service isolation, protection, and efficient and predictable execution are considered.<br\/><br\/>This research expands on prior efforts towards system extensibility and safety. The research seeks quality-of-service safe (QoS safe) extensions within the kernels of commodity systems such as Linux, as well as at user-level. By QoS safe we mean a service is not only memory-safe, in that it does not encroach on addresses for which it is not granted access, but also that it executes in a predictable manner according to quality of service (QoS) constraints. Lessons from prior work on user-level sandboxing (ULS) and safe kernel extensions (SafeX) are being used to design a new system software architecture, called Quest, comprising mechanisms and policies that guarantee the safe and predictable composition of user-specified services for real-time and embedded applications.","title":"CSR---EHS. Quest: A System for Application-Specific Real-Time Services","awardID":"0615153","effectiveDate":"2006-07-01","expirationDate":"2009-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["68374"],"PO":["561889"]},"120696":{"abstract":"Networking Testbed Workshop (ONT-3), which will be held on September 7-8, 2006 in Tokyo, Japan. This workshop will build on the results of the 2005 ONT-2, held at the NASA Ames Research The purpose of this grant is to seek funds for the Optical Center in Mountain View, CA. The goal of the workshop is to assist the advanced networking community in transitioning toward communication services based on next generation optical networking. Furthermore, the workshop will emphasize the theme of next generation international optical communication services. As with other ONT workshops, ONT-3 is invitation-only. The total number of participants will be approximately 125. This grant intends to cover 25% of the proposed cost of the workshop, to be used exclusively for venue expenses. This workshop has the potential to identify important areas of optical networking research that are not being addressed, or that require further development. It will have strong impact on the migration of appropriate technologies from optical r","title":"Optical Testbed Workshop 3 (ONT3)","awardID":"0634622","effectiveDate":"2006-07-15","expirationDate":"2007-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":[320720],"PO":["565090"]},"120124":{"abstract":"The Computing Research Association (CRA) will coordinate a series of public, town hall meetings for the National Science Foundation (NSF) to engage the broader research community in the GENI Initiative. This proposal seeks support for expenses related to the planning, advertising, registration, and reporting activities associated with these meetings. CRA is in a unique position to provide support to the Directorate for Computer and Information Science and Engineering (CISE): its organizational mission is to strengthen research and advanced education in computing. CRA has a proven record of managing successful meetings for NSF on behalf of the computing community. <br\/><br\/>The GENI initiative envisions the creation of new networking and distributed system architectures that, for example:<br\/> Build in security and robustness;<br\/> Enable the vision of pervasive computing and bridge the gap between the physical and virtual worlds by including mobile, wireless and sensor networks;<br\/> Enable control and management of other critical infrastructures;<br\/> Include ease of operation and usability; and<br\/> Enable new classes of societal-level services and applications.<br\/><br\/>The GENI initiative includes a research program and a global experimental facility designed to explore new architectures at scale.<br\/><br\/>CISE is encouraging broad community input and aims to engage other agencies, other countries, as well as corporate entities in the planning and execution of this new Initiative. To broaden community participation, CISE will hold, with the assistance of CRA, a series of three (3) town hall meetings in spring and summer 2006. The agenda for each meeting includes smaller group breakout sessions to provide input to CISE on specific topics regarding the facility such as: requirements for the experimental facility for networking and distributed systems research; implementation of the facility and its parts; and, the management of the process of defining and construction of a facility. A report will be generated at the end of each meeting to record the comments and suggestions. This proposal requests funds to pay for all meeting-related expenses, travel-related costs and staff time for organizing the meetings and for necessary follow-up activities. Participant support is also requested to provide for meals for the attendees as well as travel-related costs for the session chairs.<br\/><br\/>Intellectual Merit:<br\/>The reports generated from each meeting will provide CISE with valuable input from a wide range of researchers from the computing community in the deployment of the state-of-the-art, global experimental GENI Facility.<br\/><br\/>Broader Impacts:<br\/>Special effort will be made to attract participants from a diverse population through the advertisement of the town hall meetings via established networks and communication tools of two of the CRA committees, the Committee on the Status of Women in Computing Research (CRA-W) and the Coalition to Diversify Computing (CDC).","title":"GENI Initiative Townhall Workshops","awardID":"0631391","effectiveDate":"2006-07-01","expirationDate":"2008-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"024F","name":"GENI CONCEPT\/DEVELOPMENT"}}],"PIcoPI":["209556"],"PO":["565090"]},"120146":{"abstract":"The Directorate for Computer and Information Science and Engineering (CISE) and the CISE research community are planning an initiative called Global Environment for Networking Innovations or GENI to explore new networking capabilities that will advance science and stimulate innovation and economic growth. The GENI Initiative responds to an urgent and important challenge of the 21st Century to advance significantly the capabilities provided by networking and distributed system architectures.<br\/>To have significant impact, innovative research and design ideas must be implemented, deployed, and tested in realistic environments involving significant numbers of users and hosts. The initiative includes the deployment of a state-of-the-art, global experimental GENI Facility that will permit exploration and evaluation under realistic conditions. The GENI Facility will permit a range of researchers, including network engineers, policy analysts, protocol designers, system architects, and economic modelers to contribute to and study innovative new capabilities for the global network of the future. Assuming the concept proves to be as promising as currently anticipated, GENI construction will be considered for funding from NSF's MREFC account.<br\/><br\/>In support of making the case for GENI as a MREFC project, the PIs propose to undertake a set of tasks to advance the GENI project definition from the Conceptual Design, through the MREFC Readiness Stage, to Preliminary Design. This will involve addressing a set of design issues; taking the definition of various components of the facility to the next level of specificity; creating a detailed work breakdown structure (WBS), bottom up budget, schedule, contingency, and critical path analysis for each component and the facility as a whole; and taking the project management definition for construction and operation to the next level of specificity with due considerations to special requirements of GENI.","title":"Collaborative Research: Facility for Experimental Network Architecture Research","awardID":"0631552","effectiveDate":"2006-07-01","expirationDate":"2008-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"024F","name":"GENI CONCEPT\/DEVELOPMENT"}}],"PIcoPI":["564746"],"PO":["495796"]},"115944":{"abstract":"0610998<br\/>Lee<br\/><br\/>This award supports a planning visit to enable Dr. Dongwon Lee at the Pennsylvania State University in College Park to meet with Dr. Min-Yen Kan at the National University of Singapore. The planned collaborative research aims at building a next generation bibliographic search engine, improving focused crawling and indexing, metadata extraction, and quality of metadata, etc. The researchers will discuss: 1) the detailed scope and goals of the collaborative research; 2) the development of large-scale metadata cleaning algorithm under co-development; and 3) the scheduling and logistics of a proposed workshop. The primary characteristic of BSE (Barq Search Engine) versus standard search engines is the unique nature and structure of data associated with bibliographic references. This calls for a finely focused search that looks at data features more specific and limited than simple keywords. The sample data would be representative and contain many records with flawed entries (missing values, ambiguous names and titles, mixed and redundant citations). Progress would depend upon discovery of new algorithmic properties and system-level features associated with format recognition and error correction. Metadata extractions are a key and difficult research area and one that requires international collaborative efforts to make significant progress. The problems of metadata extraction are difficult. The need for new approaches to large-scale metadata manipulation and management are pressing. <br\/><br\/>Improved BSE systems could not only search bibliographic text more efficiently, but can also serve to identify and report errors and corrupted data since there is fore knowledge of what a given entry can contain. Improved BSE systems could also extract metadata across documents genres thereby enabling uniform new collection building. This would be of great benefit to communities handling specific document types.","title":"US-Singapore Planning Visit: Collaborative Research on Next Generation Bibliographic Search Engine","awardID":"0610998","effectiveDate":"2006-07-15","expirationDate":"2007-06-30","fundingAgent":[{"dir":{"id":"01","name":"Office of OFFICE OF THE DIRECTOR                  ","abbr":"O\/D"},"div":{"id":"0109","name":"Office of INTL SCIENCE & ENGINEERING","abbr":"OISE"},"pgm":{"id":"7299","name":"Catalyzing New Intl Collab"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6857","name":"DIGITAL LIBRARIES AND ARCHIVES"}}],"PIcoPI":["424618"],"PO":["563279"]},"116945":{"abstract":"Embedded and hybrid system (EHS) applications are highly networked systems with end-to-end requirements that involve interactions among multiple layers (application, middleware, network, OS, architecture) in a distributed environment. A holistic approach to understanding timing in these distributed cross layer systems is critical since:<br\/>EHS applications often face end-to-end hard or soft real-time needs; timing granularities for cross-layer systems can vary by orders of magnitude posing a challenge for timing analysis that can account for these variations; and knowledge of timing parameters at the different levels can dramatically improve the utility and performance of EHS applications that often execute in constrained environments where CPU, memory, network bandwidth and device energy is limited.<br\/><br\/>This project explores the notion of cross-layer timing in highly distributed embedded systems using a blend of formal methods and experimental systems, bringing together researchers with expertise in embedded computing, distributed systems and formal methods. The project will (1) develop novel formal methodologies for modeling and reasoning about cross-layer timing properties in distributed embedded systems, and <br\/>(2) design mechanisms\/policies that will cost-effectively address the QoS\/performance tradeoffs based on the cross-layer timing analyses. The results will be validated and tested in the context of mobile multimedia applications that execute in highly dynamic environments and present interesting opportunities for tradeoff analysis and enforcement. <br\/>A comprehensive solution to the timing issue will enable the wider applicability and adoption of distributed embedded applications and lay the groundwork for the unified treatment of other non-functional constraints across multiple abstraction levels","title":"Collaborative Research: CSR-EHS: Modeling and Exploiting Cross-Layer Timing in Distributed Embedded Systems","awardID":"0615436","effectiveDate":"2006-07-01","expirationDate":"2008-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["550115","474613"],"PO":["561889"]},"116835":{"abstract":"Increasingly, computing trends are leading to a new class of distributed <br\/>and highly-dynamic applications in which spatial-awareness plays a central role. <br\/>Spatially-aware applications rely on absolute or relative information about the geographic position of compute devices in order to support novel functionality. While many spatial application drivers already exist in mobile and distributed computing, very little support exists for programming these applications, expressing their spatial and temporal constraints, and supporting optimization layers for efficient implementation on real-world, highly-dynamic platforms. <br\/>This research addresses these shortcomings by providing language- and <br\/>system-layer support for expressing and optimizing spatial applications. <br\/>Since spatial computing is inherently distributed, close attention is given to resource sharing and management within and across programs. <br\/><br\/>The project's SARANA system architecture includes (i) a programming language that allows users to express the spatial region of interest and the quality of <br\/>result required, (ii) a compiler that can optimize the program so it uses resources more efficiently, and (iii) a runtime system that dynamically installs and migrates the program onto physical nodes whose resource availability match its resource needs. <br\/>A resource cost model permeates all the system layers of SARANA, permitting users to express their resource needs and quality of result requirements in terms of cost-benefit tradeoffs. . The runtime system prices resources and services, in order to broker agreements regarding resource needs and availability. <br\/>SARANA's driving applications include an early warning system to find <br\/>abducted children (Amber Alert), an earthquake monitoring system, and <br\/>multi-user gaming networks.","title":"CSR-EHS: A Space and Resource Aware Computing Architecture","awardID":"0614949","effectiveDate":"2006-07-01","expirationDate":"2011-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["446736","495323"],"PO":["561889"]},"119827":{"abstract":"This Small Grant for Exploratory Research (SGER) proposes to identify specific management practices that are appropriate for projects that are highly uncertain, complex, and distributed. GENI (Global Environment for Network Innovations) is an example of such a project. GENI is an ambitious, ground-breaking initiative of the National Science Foundation's Directorate for Computer and Information Science and Engineering (CISE). The goal of GENI is to enable the research community to design and build a better Internet by inventing and demonstrating the networks and architectures of the future. Unlike many other large NSF projects, GENI contains a significant software component, this characteristic contributes enormously to its risk and complexity as software projects are often prone to mismanagement and failure. The GENI project presents a rare opportunity to identify and study project management practices for high risk projects. Knowledge gained from this research will advance project management practices across disciplines, including information systems, computer science, and engineering. <br\/><br\/>The findings from this research will advance an understanding of the management of large, distributed projects within NSF and across many intellectual disciplines. Moreover, findings from this research can be directly incorporated into teaching materials, for example, into the curricula of project management courses, since the findings will have direct implications for the practice of project management. Further, by discovering management practices that can enhance the possibility of successfully managing GENI, this research has the potential to positively impact many stakeholders.","title":"GENI: Managing the Unmanageable: Recommendations for Structuring and Governing Complex, Dynamic, and Distributed Projects","awardID":"0630214","effectiveDate":"2006-07-01","expirationDate":"2007-12-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"024F","name":"GENI CONCEPT\/DEVELOPMENT"}}],"PIcoPI":["405707"],"PO":["468236"]},"120499":{"abstract":"IIS-0633422<br\/>Student Participant Support for the Workshop on the Algorithmic Foundations of Robotics (WAFR)<br\/><br\/>The Workshop on the Algorithmic Foundations of Robotics (WAFR, www.wafr.org) is a multi-disciplinary single-track workshop with submitted and invited papers on advances on algorithmic problems in robotics. It has been held every other year since 1994 and has an established reputation as one, if not the, most important venues for presenting algorithmic work related to robotics. One of the most important aspects of WAFR is its informal atmosphere, which allows a frank exchange of new, previously unpublished ideas. In particular, WAFR has been an occasion for graduate students to meet and interact with more senior researchers who many times are not accessible to students at major robotics conferences.<br\/><br\/>WAFR 2006 will be held in New York City at the Tribeca Grand Hotel in lower Manhattan. The WAFR 2006 program includes 32 papers, selected from a record number of submissions, and 6 invited speakers. There is a stellar line-up of invited speakers, including both researchers who defined the field and those who are today defining the frontiers of the field - in several cases the same people: Jacob Schwartz (NYU), Tomas Lozano-Perez (MIT), Jean-Claude Latombe (Stanford), James Gimzewski (UCLA), Jessica K. Hodgins (CMU), and Sebastian Thrun (Stanford).<br\/><br\/>This award will be used to support partial travel and conference costs for a diverse group of students, including authors of WAFR papers, those who are already working in the area, and students who are interested in learning more about robotics as a possible area of research focus for their graduate studies. Efforts will be made to encourage applications from underrepresented groups in robotics and computing.","title":"Student Participant Support for the Workshop on the Algorithmic Foundations of Robotics (WAFR)","awardID":"0633422","effectiveDate":"2006-07-15","expirationDate":"2007-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6840","name":"ROBOTICS"}}],"PIcoPI":["561154"],"PO":["335186"]},"116946":{"abstract":"Peak power dissipation and the resulting temperature rise have become the dominant limiting factors to processor performance and a significant component of its design cost. Expensive packaging and heat removal solutions are needed to achieve acceptable substrate and interconnect temperatures in high-performance microprocessors. Current thermal solutions are designed to limit the peak processor power dissipation to ensure its reliable operation under worst-case scenarios. However, the peak power and ensuing peak temperature are hardly ever observed. Dynamic thermal management (DTM) has been proposed as a class of micro-architectural solutions and software strategies to achieve the highest processor performance under a peak temperature limit. When the chip approaches its thermal limit, a DTM controller initiates hardware reconfiguration, slow-down, or shutdown to lower the chip temperature. Possible response mechanisms include micro-architectural adaptations e.g., fetch toggling, register file resizing, and issue width reduction, and\/or on-the-fly performance adjustment e.g., dynamic voltage and frequency scaling and functional unit shut-down. The proposed research aims to develop a new DTM solution that takes a global, predictive approach based on constructing and utilizing a continuous-time Markovian decision process model of the microprocessor chip and the application programs. The offline algorithms developed in this framework are provably optimal whereas the online versions of these algorithms are easily deployable and highly flexible. The project thus produces temperature-aware policies and techniques for ensuring that the microprocessor chips operate within the allowed temperature zone, having maximum possible performance yet not being over-designed.","title":"CSR--EHS: Stochastic Approaches for Dynamic Thermal Management in High Performance Microprocessor Chips","awardID":"0615437","effectiveDate":"2006-07-01","expirationDate":"2009-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["518663"],"PO":["493916"]},"116836":{"abstract":"Vahid abstract<br\/><br\/>This project is defining basic concepts for FPGA standard binaries, and developing techniques to support those concepts. FPGAs are a relatively new category of programmable chip that can implement a user-specified circuit, in contrast to programmable microprocessor chips that implement user-specified sequential instructions. Because circuits consist of thousands of concurrently-executing components rather than sequentially-executing instructions, circuits may execute certain embedded system applications thousands of times faster than microprocessors. Because FPGAs are programmable like microprocessors, configured just by downloading a bitfile, FPGAs reduce engineering costs by orders of magnitude compared to circuit-implementation chip technologies that require manufacturing of custom or semi-custom chips, and support downloading of new circuits even after deployed in a final product. Yet in contrast to microprocessors, FPGAs today lack a concept of standard binary, a bitfile that can be ported without modification to different programmable chips. For microprocessors, standard binaries would enable an ecosystem among developers of architectures, applications, and tools, that catalyzes the development of those three items. <br\/><br\/>This project seeks to define device-independent binaries for circuits, called spatial binaries. It develops techniques that use on-chip design automation tools to dynamically map a spatial binary onto any particular FPGA architecture. It develops methods like circuit swapping and circuit re-synthesis to map large circuits onto smaller FPGAs, and develops methods like circuit recompilation and circuit emulation to implement circuits on microprocessors when FPGA resources are unavailable. The project defines concepts for hybrid binaries supporting both temporal and spatial description, and develops exploration techniques to effectively map hybrid binaries onto particular chips having both microprocessors and FPGAs. Standard FPGA binaries are expected to lead to higher-quality, more robust, more reliable FPGA-based embedded computing applications, due to the longer lifetime and wider distribution of applications, which justify larger investment by the application developer.","title":"CSR -- EHS: Standard Binaries for FPGAs: Separating Function and Architecture in Modern Embedded Computing Platforms","awardID":"0614957","effectiveDate":"2006-07-01","expirationDate":"2011-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["450944"],"PO":["561889"]},"123139":{"abstract":"Abstract<br\/><br\/>Proposal ID: 0312558<br\/>Institution: Pennsylvania State University<br\/>Principal Investigator: Octavia Camps<br\/><br\/>This project focuses on problems of distributed active vision - a confluence of computer vision, ad-hoc networking and control. The objectives are to develop a paradigm for systematically designing provably robust distributed active vision systems and to characterized the performance of the resulting systems. Progress in this area offers significant benefits to a variety of application areas, such as intelligent activity monitoring systems and smart environments, aware of user activities. While prototype systems have been developed in several laboratories, these suffer from shortcomings that limit their application and testing outside of research environments. This project will build on some of that work to achieve robust systems built on sound system theoretic concepts, a common mathematical language and usable set of tools.","title":"ITR: Robust Ad-Hoc Active Vision Networks and Applications","awardID":"0647116","effectiveDate":"2006-07-01","expirationDate":"2008-07-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1686","name":"ITR SMALL GRANTS"}}],"PIcoPI":["549740"],"PO":["564316"]},"116858":{"abstract":"Project Summary<br\/>SGER\/CSR-SMA: Qualitative and Quantitative Models of Redundancy<br\/><br\/>A. Mili, NJIT<br\/><br\/>The project will conduct research to explore the following aspects with respect to redundancy: 1) Study redundancy as a system attribute in its own right, alongside such system attributes as modularity, design integrity, complexity, size, etc. While most applications of redundancy that we can envision today are in fault tolerance, it may be worthwhile to characterize it independently of fault tolerance, if we are ever going to find whether redundancy is relevant to any other system behavior or system property; and 2) Explore formal models of redundancy, with the intent of perhaps producing a formal definition for it, and a formal basis for reasoning about it. Specifically, quantitative and qualitative models of system redundancy, that have been explored so far will be further pursued to derive a comprehensive model that captures all aspects and all sources of a redundancy in a complex system.<br\/><br\/>The context of this one-year project, is to pursue exploration of the qualitative and quantitative models of redundancy, with the following goals in mind: a) Turn the individual qualitative observations into unified comprehensive model that characterizes redundancy as a system property reflecting the attributes of its state representations, system functions, and system specifications (all of which are sources of redundancy); b) Unify the qualitative and quantitative model, essentially by making the quantitative model measure the attributes that are captured in the qualitative model. We liken the contrast between the qualitative and quantitative model to characterizing a set (qualitative) and computing its cardinality (quantitative); whereas the former is a faithful reflection of the set, the latter is a convenient abstraction; c) Use the derived models to explore new insights and application; and d) Draw a longer term research plan, to the extent warranted by our preliminary results.","title":"SGER\/ SMA: Qualitative and Quantitative Models of Redundancy","awardID":"0615068","effectiveDate":"2006-07-15","expirationDate":"2007-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":[309212],"PO":["561889"]},"121985":{"abstract":"Intellectual Merit<br\/>The trusted processor model is a promising model for designing highly secure systems. However there are several drawbacks that limit its application as a highly trusted computing base.This CAREER project will address these drawbacks in a compilation and language framework to fill the gap between a secure application developer and the secure processor for the provision of a programming environment with high efficiency, usability and security. The successful development of the proposed research will greatly impact the design and implementation of system level security protection<br\/><br\/>Broader Imapct<br\/>The educational component of this proposal will be integrated in institutional efforts of curriculum development, and will have an extendeded impact nationwide on education in system security. Eventually, wide adoption of the trusted process model for developing high performance secure applications will hopefully take effect.","title":"CAREER: A Compilation Framework for the Development of High Performance Secure Applications on Trusted Processors","awardID":"0641177","effectiveDate":"2006-07-01","expirationDate":"2010-12-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"1640","name":"INFORMATION TECHNOLOGY RESEARC"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"4080","name":"ADVANCED COMP RESEARCH PROGRAM"}}],"PIcoPI":["448722"],"PO":["565272"]},"121127":{"abstract":"This is a request for travel support for U.S. graduate students and junior faculty to attend the 2006 IEEE\/RSJ International Conference on Intelligent Robots and Systems (IROS'2006) in Beijing, China, October 9-15, 2006. IEEE\/RSJ International Conference on Intelligent Robots and Systems (IROS) is one of the two major conferences on Robotics. Attending and presenting papers at IROS have been the main professional activities for the robotics researchers, educators and students. This grant will enable and encourage graduate students and junior faculty in US to attend the IROS'2006, present their papers, and participate in the activities of professional organizations. It will also foster international collaboration by providing a unique opportunity for US junior faculties and graduate students to visit Chinese universities and research organizations. The broad impact of the results of this effort will significantly broaden the view of the participating graduate students and faculty on robotics and intelligent systems, and enable them to gain aspects which may not be easily obtain in US. All of these will significantly impact on their career and contribute to the development of the US manpower for science and technologies, especially in the areas of robotics and intelligent systems.","title":"Request Travel Support for U.S. Students and Junior Faculty to Attend 2006 IEEE\/RSJ International Conference on Intelligent Robots and Systems (IROS2006)","awardID":"0636692","effectiveDate":"2006-07-15","expirationDate":"2007-12-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6840","name":"ROBOTICS"}}],"PIcoPI":["550894"],"PO":["403839"]},"111458":{"abstract":"Abstract for Proposal # 0546467<br\/><br\/>Model-Probability Planning for Mobile Robots<br\/><br\/>Robots operating in natural, dynamic domains depend on the ability to make decisions without perfect prior knowledge of the world. Robots instead use sensor data to infer a model of the world (e.g., a map) and then make decisions with respect to this map. Typically, the process of learning the map is separated from planning, simplifying both problems. In natural, populated environments, however, building a complete and accurate map becomes increasingly difficult and motion planning can become brittle. For example, a robot grasping an object on a table should not depend on having an exact and precise geometric model of the table and object. In contrast, the robot should be able to learn the model as it goes, starting with a simple probabilistic model of the table top and object. Then, to reduce uncertainty, the robot should gather new data about the world, stopping only to take more precise measurements of the world to improve its map when doing so is predicted to lead to better overall performance. The objective of the proposed research program is to develop robust autonomy in robotics by integrating mapping and planning in a tractable manner. The approach will be to develop planning systems that operate in the space of model distributions. New techniques of modeling free and occupied space probabilistically must be developed to capture map uncertainty efficiently. Unlike conventional maps that predict sensor error, the resulting maps will be designed to maximize the predicted planner performance. Secondly, motion planning algorithms must be developed that can plan with respect to a range of possible maps, generating motion plans that incorporate exploration and resolve ambiguities. The proposed scientific activity will create a new generation of more robust and capable autonomous systems through a combined research and educational program to study integrated learning and decision making. The educational program will introduce a generation of students to new principles of planning under uncertainty and mobile manipulation. The proposed research is vital to the long-term viability of mobile robots operating autonomously in complex, dynamic environments. For example, mobile manipulators have great potential in a number of assistive domains such as health care and manufacturing, but reliable operation in populated environments will require a solid understanding of decision making under uncertainty through integrated learning and planning. This research will also lead to robust autonomy in unmanned underwater, air and space vehicles.","title":"CAREER: Model Probability Planning for Mobile Robots","awardID":"0546467","effectiveDate":"2006-07-01","expirationDate":"2013-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":["485514"],"PO":["543539"]},"115715":{"abstract":"The investigators will study new variational PDE-based mathematical models and fast computational algorithms for solving them. These models have emerged recently as a powerful addition to the variety of methodologies for image processing and computer vision. They are distinguished by their use of powerful mathematical tools from differential geometry, PDE and functional analysis to handle geometry regularities and sharp feature boundaries. A particularly popular example of this class of models is the total variation based image restoration model, first introduced by Rudin, Osher, and Fatemi (ROF). The ROF model has proven to be extremely successful, both in practice and in theory, and has created a lot of interest and extensions. At this point in time, there is quite a complete understanding of its theoretical properties and both its advantages and limitations. For example, the model has been extended to include deblurring, to vector-valued images, to higher order regularization involving curvatures of the underlying level sets of the image intensity function, to deal with the \"stair-casing\" effect, Meyer's recent \"image decomposition\" (as opposed to image denoising), introduction of the dual norm of TV to extract texture information, and the idea of an \"inverse scale space\". Taken all together, there has truly been an explosion of exciting and novel ideas recently that were inspired by the original ROF model, and the field has been enjoying a revival of interest and activities. Despite all the new developments mentioned above, there remains a major drawback of nonlinear PDE-based models: their computational efficiency. There are many reasons for this difficulty: their nonlinearity (which are designed on purpose to allow the models to recover discontinuous solutions), non-smooth objective functions (making it difficult to construct Newton-type methods to achieve quadratic convergence), and globally spatial coupling (resulting in a spatial stiffness that presents a major challenge to any solution algorithm). In this proposal, the investigators will study systematically the design of robust, scalable and efficient computational algorithms for this class models. They will make use of new paradigms involving the use of a dual formulation to recover sharp discontinuities without the usual edge-smearing numerical regularization of the primal TV formulation, the use of novel Newton-type linearizations (Newton on the primal-dual system, and use of non-smooth Newton) to obtain faster than linear convergence, and the use of novel multigrid methods to deal with the spatial stiffness. The investigators will also study the TVL1 model. This seemingly simple extension of the ROF model (replacing the L2 fidelity term by a L1 term) turns out to produce fundamentally new, and often desirable, properties: contrast invariance, better scale separation, better multiscale image decomposition, and intrinsic geometric properties which allow its use to derive powerful but simple convex optimization algorithms which can find the global optimums of several non-convex shape optimization problems. The final part of the proposal is on the application of these variational PDE-based models to image processing on manifolds. This class of problems has many important applications, especially in medical imaging (e.g. brain mapping) and computer graphics. The particular approach proposed here is a novel one based on some new conformal mapping techniques developed for brain mapping that are particularly simple to use in conjunction with PDE-based image processing models. <br\/><br\/>Imaging sciences has emerged as a powerful paradigm in computational and applied mathematics. It has attracted a lot of interested from mathematicians from other fields, especially among students and young researchers. There are many applications to science, engineering, medicine and even in the entertainment industry. This proposal is on novel new ideas that are at the forefront of this relatively new field and that have aroused much interest in the field. These new developments are mathematically based and make use of powerful and subtle concepts from other parts of computational mathematics, such as duality, non-smooth optimization and multigrid methods. The focus is on key issues, such as computational efficiency, feature extraction, multiscale decomposition, global optimization, which are keys to further advances. It also leverages powerful new techniques from computational biology and combine them with PDE-based image models for new applications to the general class of problems of solving PDEs on manifolds. The ultimate goal is to produce an efficient set of algorithms for a general class of nonlinear PDE-based models that are robust, scalable, accurate, and fast.","title":"New Models and Fast Algorithms for Variational PDE Image Processing","awardID":"0610079","effectiveDate":"2006-07-01","expirationDate":"2010-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0503","name":"Division of SHARED CYBERINFRASTRUCTURE","abbr":"SCI"},"pgm":{"id":"1271","name":"COMPUTATIONAL MATHEMATICS"}}],"PIcoPI":[306467,"442494"],"PO":["562265"]},"116947":{"abstract":"Embedded and hybrid system (EHS) applications are highly networked systems with end-to-end requirements that involve interactions among multiple layers (application, middleware, network, OS, architecture) in a distributed environment. A holistic approach to understanding timing in these distributed cross layer systems is critical since:<br\/>EHS applications often face end-to-end hard or soft real-time needs; timing granularities for cross-layer systems can vary by orders of magnitude posing a challenge for timing analysis that can account for these variations; and knowledge of timing parameters at the different levels can dramatically improve the utility and performance of EHS applications that often execute in constrained environments where CPU, memory, network bandwidth and device energy is limited.<br\/><br\/>This project explores the notion of cross-layer timing in highly distributed embedded systems using a blend of formal methods and experimental systems, bringing together researchers with expertise in embedded computing, distributed systems and formal methods. The project will (1) develop novel formal methodologies for modeling and reasoning about cross-layer timing properties in distributed embedded systems, and <br\/>(2) design mechanisms\/policies that will cost-effectively address the QoS\/performance tradeoffs based on the cross-layer timing analyses. The results will be validated and tested in the context of mobile multimedia applications that execute in highly dynamic environments and present interesting opportunities for tradeoff analysis and enforcement. <br\/>A comprehensive solution to the timing issue will enable the wider applicability and adoption of distributed embedded applications and lay the groundwork for the unified treatment of other non-functional constraints across multiple abstraction levels.","title":"Collaborative Research: CSR-EHS: Modeling and Exploiting Cross-Layer Timing in Distributed Embedded Systems","awardID":"0615438","effectiveDate":"2006-07-01","expirationDate":"2008-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["541836","499298"],"PO":["561889"]},"116606":{"abstract":"Markets for interchangeable components exert pressure on manufacturers to improve their products. This is especially true if the market comes with fast dissemination of information about the quality of the components. But existing markets for software components lack quality assurance mechanisms. In this exploratory project, the PIs will study the relationship between software markets, quality assurance, and design. The PIs conjecture that if a market for software components is equipped with a uniformly enforced quality control mechanism, it will force software producers to continuously overhaul their product designs. To test this hypothesis, the PIs will conduct experiments with small controllable component markets, in which products come with explicit software contracts and the underlying software platforms monitor these contracts and publicly report violations. Producers may choose to react to these reports with technical contributions (test cases, improved contracts, etc). In this context, the PIs will validate their conjecture by conducting code inspections and interviews with producers. The outcomes of this exploratory investigation will help others construct similar markets and mechanisms; some may even directly benefit from the software developed as part of the project.<br\/><br\/>Broader Impacts: This project has the potential to change the way software components are produced and the way software reuse is taught. If the PIs' conjecture about markets is confirmed, it will provide arguments to the promoters of both public markets and markets that are internal to organizations. The very creation of a market with quality assurance mechanisms is bound to make the production of software more efficient, and to improve the quality of the components that are traded on the market. Independently of the outcome of the experiments, the idea of using a market for courses may help instructors deal with the teaching of software reuse in classes. They can use the PIs' experience and possibly their software as well to create course-focused markets; and they can use these markets to demonstrate the value of software reuse.","title":"SoD-HCER: Colloborative Research: Using Market Forces to Improve Design of Hardware","awardID":"0613687","effectiveDate":"2006-07-15","expirationDate":"2009-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7724","name":"SOFTWARE FOR REAL-WORLD SYSTMS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7372","name":"ITR-SCIENCE OF DESIGN"}}],"PIcoPI":["518591"],"PO":["565227"]},"116859":{"abstract":"The confluence of peer-to-peer and Grid computing has been described as<br\/>inevitable in several recent papers. Peer-to-peer (P2P) services show the<br\/>promise of providing robustness, reliability, and decentralization in many<br\/>areas, while Grid computing has shown great benefits for enabling<br\/>applications to take advantage of idle cycles available on machines all<br\/>across the Internet. In this project we are employing P2P services to both<br\/>allow users (peers) to submit jobs to be run in the system and to run jobs<br\/>submitted by other users on any resources available in the system. All<br\/>peers contribute resources to an ad-hoc resource pool, and all peers can<br\/>submit jobs that are executed using available resources, across<br\/>institutional boundaries. Using P2P services can provide a robust,<br\/>reliable, scalable job submission and execution system that is able to take<br\/>advantage of any computational resources that a set of users are willing to<br\/>share.<br\/><br\/>We focus on the crucial problem of completely distributed and decentralized<br\/>job placement in a Grid environment. We are working on distributed<br\/>algorithms for submitting jobs and efficiently matching them to available<br\/>resources. We use P2P techniques for both load balancing and for<br\/>resilience. From preliminary analysis and experiments, our schemes both<br\/>scale with system size and are robust against component failures and peer<br\/>departures\/joins. The work is a collaborative effort between computer<br\/>scientists and astronomers. We are designing, implementing, and validating<br\/>the algorithms using a set of applications and associated workloads from<br\/>computational astronomy.","title":"CSR--AES: Creating a Robust Desktop Grid using Peer-to-Peer Services","awardID":"0615072","effectiveDate":"2006-07-15","expirationDate":"2011-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["409678","559445","485350","548322"],"PO":["535244"]},"116309":{"abstract":"Traffic congestion and the associated delay and economic costs it causes are a source of significant concern. In the United States over the past twenty years, vehicle miles traveled for passenger cars grew 44%, but miles of interstate highway increased less than 8%! In response, transportation departments are moving towards intelligent transportation management through the use of tools such as adaptive ramp meters and traffic signals, and expanded traffic information systems. Much of the data available for use in intelligent transportation management is in the form of data streams, such as inductive loop detector data, Automatic Vehicle Location (AVL) systems on buses, and live traffic signal data.<br\/><br\/>This project investigates the use of Data Stream Management Systems (DSMS) for Intelligent Transportation Systems (ITS). Current DSMS technology is not adequate for ITS applications; ITS data is disordered, dirty and bursty and can arrive from widely varied sources (embedded detectors, active vehicles, passive transponders). Further, the live data must be compared with archived historical data and other types of information sources. In addition to the current focus on temporal aggregation, ITS data requires spatial and potentially spatio-temporal aggregation. Finally, any DSMS that processes ITS data must scale to thousands or tens of thousands of simultaneous queries.<br\/><br\/>The goals of this research are to extend the NiagaraST stream-processing system to accommodate queries that arise in intelligent transportation management and information systems (particularly those combining both live and archive data), develop improved evaluation techniques that will match transportation applications and data in speed and scale, and then thoroughly test and evaluate the results using the live and archival data sources available in the Portland State University ITS lab.<br\/><br\/>This project is a collaboration between faculty, staff and students in the Data and Information Management Laboratory (http:\/\/datalab.cs.pdx.edu\/) of the Computer Science Department and in the Intelligent Transportation Systems Laboratory (http:\/\/www.its.pdx.edu\/) of the Civil & Environmental Engineering Department in the Maseeh College of Engineering and Computer Science at Portland State University.","title":"Exploiting Live Plus Archive Data for Intelligent Transportation Systems","awardID":"0612311","effectiveDate":"2006-07-01","expirationDate":"2010-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7294","name":"SCIENCE & ENGINEERING INFORMAT"}}],"PIcoPI":["483300",307859],"PO":["565136"]},"120105":{"abstract":"The Directorate for Computer and Information Science and Engineering (CISE) and the CISE research community are planning an initiative called Global Environment for Networking Innovations or GENI to explore new networking capabilities that will advance science and stimulate innovation and economic growth. The GENI Initiative responds to an urgent and important challenge of the 21st Century to advance significantly the capabilities provided by networking and distributed system architectures.<br\/>To have significant impact, innovative research and design ideas must be implemented, deployed, and tested in realistic environments involving significant numbers of users and hosts. The initiative includes the deployment of a state-of-the-art, global experimental GENI Facility that will permit exploration and evaluation under realistic conditions. The GENI Facility will permit a range of researchers, including network engineers, policy analysts, protocol designers, system architects, and economic modelers to contribute to and study innovative new capabilities for the global network of the future. Assuming the concept proves to be as promising as currently anticipated, GENI construction will be considered for funding from NSF's MREFC account.<br\/><br\/>In support of making the case for GENI as a MREFC project, the PIs propose to undertake a set of tasks to advance the GENI project definition from the Conceptual Design, through the MREFC Readiness Stage, to Preliminary Design. This will involve addressing a set of design issues; taking the definition of various components of the facility to the next level of specificity; creating a detailed work breakdown structure (WBS), bottom up budget, schedule, contingency, and critical path analysis for each component and the facility as a whole; and taking the project management definition for construction and operation to the next level of specificity with due considerations to special requirements of GENI.","title":"Collaborative Proposal: Facility for Experimental Network Architecture Research","awardID":"0631297","effectiveDate":"2006-07-01","expirationDate":"2007-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"024F","name":"GENI CONCEPT\/DEVELOPMENT"}}],"PIcoPI":[318872],"PO":["495796"]},"116904":{"abstract":"Microprocessor performance has been increasing exponentially due in large part to smaller and faster transistors enabled by improved fabrication technology. While such transistors yield performance enhancements, their lower threshold voltages and tighter noise margins make them less reliable, rendering processors that use them more susceptible to transient faults. While many fault-tolerance techniques have been proposed for high-end systems, the high hardware costs of these solutions make them impractical for the desktop and embedded computing markets.<br\/><br\/>This work develops the concept of software-modulated fault tolerance (SMFT) to reduce the cost of reliability by taking advantage of naturally occurring non-uniformity in programs. By letting the system, the programmer, or even the user decide when and how to apply protection, the impact of fault tolerance can be adapted to best suit the needs of the constantly varying system. By increasing reliability only when warranted, SMFT frees up resources to either increase performance or reduce power. With the development of a set of profiler, compiler, and language techniques, this work allows designers to continue scaling processor performance for all markets despite the presence of transient faults.","title":"CSR---EHS: Software-Modulated Fault Tolerance","awardID":"0615250","effectiveDate":"2006-07-01","expirationDate":"2009-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["511660"],"PO":["493916"]},"116948":{"abstract":"Virtual machines (VMs) are widely-used computer-based execution frameworks that isolate an application from the underlying hardware and system software platform and implement programming language run-time semantics.. This project focuses on efficient execution of virtual machine code on resource-constrained devices by way of trace-driven dynamic compilation. Many optimization algorithms that are expensive to perform on graphs can be performed in linear time on a trace. Furthermore, a trace-directed compiler can in-line method calls in a straightforward manner, significantly reducing the modularization overhead of object-oriented programming where it is most critical. This approach thereby paves the way for good software engineering practice and component-oriented programming in embedded software without the accompanying performance penalties that are often associated with these techniques. The project is founded on a novel use of Static Single Assignment form and preliminary results point the way to a completely new way of designing embedded hybrid VMs. The main focus is on systematically exploring and further developing this approach, initially targeting the Java Virtual Machine (JVM) platform. A second focus is on developing a scalable VM layer that is optimally situated to support a wide variety of embedded software, but that can yet be efficiently mapped onto current and future embedded processor platforms. <br\/><br\/>Embedded systems present an application of the 'write once, run forever after' computing paradigm that has not yet reached its true potential. The project is expected to lead to significant improvements in the way embedded software is developed. It will enable reuse of embedded software where no such reuse is currently possible and simplify the transition to increasingly evolved embedded processors. This is expected to have impact in significantly lower cost and significantly increased reliability of embedded software.","title":"CSR-EHS: Virtual-Machine Techniques for Resource-Constrained Devices: Reconciling Reliability With Reusability and Low Development Costs in the Embedded Systems Space","awardID":"0615443","effectiveDate":"2006-07-01","expirationDate":"2010-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["486136"],"PO":["561889"]},"121206":{"abstract":"ABSTRACT<br\/><br\/>This project seeks to investigate fundamental questions about how to define and represent concepts, particularly in contexts where robots need to identify and use objects. This project focuses on representations that result from observations about object usage. The underlying assumption is that usage reveals fundamental information about the nature of objects. The fundamental question to be addressed in this project is: How can concepts be defined in terms of multiple representations for the purpose of effective recognition? This project will investigate how context and usage can allow recognition that might not be possible when an object is observed in isolation, and how the enormous variation in the visual appearance of objects can be accounted for through combination of functional definitions and simple visual descriptions. The project is organized around three tasks: (1) investigation of multi-faceted knowledge representation techniques that include exemplar-based and usage-based representations, and the use of weighted (probabilistic) representations; (2) multi-representation recognition algorithms that allow for probabilistic balancing of evidence and weighted representations and the combining of exemplar-based and non-exemplar-based representations; and (3) parameter and structure learning that allows adaptation of weights used in concept representations and definitions. The project will use mobile robots equipped with various sensors as a test bed. In addition to its own sensory input, the robot will use observations of humans interacting with objects in its environment. The project will build on the PIs ongoing work on object definition and recognition techniques that use visual features and functional representations. This project has potential Broader Impact not only on robotics and artificial intelligence but also on cognitive science and psychology in general.","title":"SGER: Concepts in Context: Representations for Recognition","awardID":"0637069","effectiveDate":"2006-07-15","expirationDate":"2007-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6856","name":"ARTIFICIAL INTELL & COGNIT SCI"}}],"PIcoPI":["518535"],"PO":["387198"]},"116949":{"abstract":"A program is a detailed description of how to manipulate data to achieve some end. Unfortunately, programs often do not achieve what their programmers intended. Fortunately, it is usually possible to specify logically what is intended through in-line assertions and function preconditions and postconditions. A function precondition is an assertion that describes the expected input, while a postcondition describes the relation between the returned data and the given data. The challenge is then to prove that a program meets its specification.<br\/><br\/>It is well known that proving that each of a program's functions adheres to its specification is undecidable. In practice, though, many program properties can be analyzed. The goal of this work is to extend the range of programs that can be verified mostly automatically with a verifying compiler. A modern verifying compiler must do two tasks well. First, it must strengthen the given annotations by generating inductive invariants. An inductive invariant has the properties that it holds initially, and that each instruction of the program maintains it. Second, it must prove that the given annotations are inductive relative to the generated ones, thus proving correctness.This work addresses the first task by scaling constraint-based invariant generation and ranking function synthesis to whole programs. Automatic invariant generation and ranking function synthesis reduces the need for annotations beyond the program specification. It addresses the second task by finding expressive and decidable fragments of first-order theories relevant for verification. Finally, the theoretical results are implemented in a verifying compiler that is used in an undergraduate course on program verification and decision procedures. <br\/><br\/>This is expected to have impact for the discipline of Computer Science, where increased demand is predicted for specialized static analysis techniques and decision procedures that will improve efficiency and accuracy. This is especially true in the area of embedded systems, where achieving correct and reliable systems without the assistance of analysis tools is particularly difficult.","title":"CSR---EHS: A Modern Verifying Compiler","awardID":"0615449","effectiveDate":"2006-07-01","expirationDate":"2008-09-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":[309451],"PO":["561889"]},"129918":{"abstract":"0203528<br\/>Tara Hutchinson<br\/>University of California Irvine<br\/>\"Expanding Engineering Thinking: Interactive Visualization of Numerical Models\"<br\/><br\/>This project involves the development and application of a new interactive learning tool and the use of visualization techniques, enabled by the tool, in teaching engineering. The overall goal of this project is to contribute to a redesigned engineering curriculum that better matches the practice of engineering in the 21st century. The curriculum focuses on (1) visualization and hands-on manipulation, (2) computer-assisted design and virtual reality, (3) interactive learning, (4) critical thinking, (5) creative problem solving, and (6) problem-based learning. These objectives are achieved through the redesign of existing courses and through the creation of a new interdisciplinary course. The project directly addresses the connection of engineering with the changing needs of industry and society in merging technology areas by educating future engineers in the 'office of the future' environment. This instructional environment (VizClass) includes tele-conferencing capabilities, interactive whiteboards, spatial tracking and semi-immersive visualization operating within a completely wireless environment. The VizClass system uses readily deployable, cost effective components, such that other academic institutions may easily replicate it. The hardware configuration leverages existing technology where possible and introduces system components for the real-time control and the middleware required for fusing numerical solvers with visualization tools and hardware components. Components of the environment include a series of interactive projection display boards (white boards) and a semi-immersive projection table or wall display controlled by a dedicated visualization server. Digital whiteboards, with touch sensitive input surfaces, enable more accurate tracking of user input. Active white board screens providing either an input or output workspace are linked via a high-speed (large storage capacity) server. This in turn is connected to a numerical solver. The solver receives feedback from the input or 'working' screen in the form chosen by the user. If the input-mode is of type equation, the solver manipulates the equations and outputs the solution as either a 2- or 3-dimensional visual object to the selected output device in either mono- or stereoscopic form, respectively. Visual output can be a distorted or contoured mesh (with, for example stresses, strains or heat distribution), or figures annotating important engineering parameters. The advantage of teaching in this environment is the near-real time visual feedback articulating results of the solved equations utilizing the finite element method approach as applied to structural engineering, mechanics or electronics problems. The VizClass is equipped with a wireless network, giving collaborators and students instant access to all available on-line resources.","title":"CRCD: Expanding Engineering Thinking: Interactive Visualization of Numerical Models","awardID":"0723516","effectiveDate":"2006-07-01","expirationDate":"2008-01-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"1709","name":"CISE EDUCAT RES & CURRIC DEVEL"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0705","name":"Division of ENGINEERING EDUCATION AND CENT","abbr":"EEC"},"pgm":{"id":"1340","name":"ENGINEERING EDUCATION"}}],"PIcoPI":["423906"],"PO":["551712"]},"120327":{"abstract":"The purpose of the workshop is to devote national attention to the need for identifying and comprehensively examining the major challenges in the area of information integration (II) and the required long-term research, engineering and development that will be needed to advance the state of the art and state of the practice in the application of advanced IT to resolve these challenges in the near- and long-term. The type and modality of information available in digital form is vast - image, video, text, audio, sensor and other forms of streaming data, as well as structured data such as databases and XML\/ HTML documents. Although the data may be geographically distributed, collected and designed for specific uses and applications (\"silos\" of information), it is often logically inter-related, and many important questions can only be answered by accessing it collectively. However, despite considerable research and development over the last 20 years, truly ad hoc II, where disparate information systems are accessed efficiently in real time in response to unanticipated information needs and data is combined to form reliable answers to queries, remains an elusive goal. A systematic development of II technologies is needed to provide the necessary infrastructure leading to significant advances in the access to and analysis of widely distributed, heterogeneous, disparate information resources. Of particular importance to this workshop will be issues associated with the integration of science and engineering data and Federal, medical, and other records.","title":"SEIII: Workshop on Information Integration","awardID":"0632541","effectiveDate":"2006-07-01","expirationDate":"2007-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7602","name":"INFORMATION INTEGRATION"}}],"PIcoPI":["541878","517980"],"PO":["565136"]},"120107":{"abstract":"The Directorate for Computer and Information Science and Engineering (CISE) and the CISE research community are planning an initiative called Global Environment for Networking Innovations or GENI to explore new networking capabilities that will advance science and stimulate innovation and economic growth. The GENI Initiative responds to an urgent and important challenge of the 21st Century to advance significantly the capabilities provided by networking and distributed system architectures.<br\/>To have significant impact, innovative research and design ideas must be implemented, deployed, and tested in realistic environments involving significant numbers of users and hosts. The initiative includes the deployment of a state-of-the-art, global experimental GENI Facility that will permit exploration and evaluation under realistic conditions. The GENI Facility will permit a range of researchers, including network engineers, policy analysts, protocol designers, system architects, and economic modelers to contribute to and study innovative new capabilities for the global network of the future. Assuming the concept proves to be as promising as currently anticipated, GENI construction will be considered for funding from NSF's MREFC account.<br\/><br\/>In support of making the case for GENI as a MREFC project, the PIs propose to undertake a set of tasks to advance the GENI project definition from the Conceptual Design, through the MREFC Readiness Stage, to Preliminary Design. This will involve addressing a set of design issues; taking the definition of various components of the facility to the next level of specificity; creating a detailed work breakdown structure (WBS), bottom up budget, schedule, contingency, and critical path analysis for each component and the facility as a whole; and taking the project management definition for construction and operation to the next level of specificity with due considerations to special requirements of GENI.","title":"Collaborative Research: Facility for Experimental Network Architecture Research","awardID":"0631303","effectiveDate":"2006-07-01","expirationDate":"2008-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"024F","name":"GENI CONCEPT\/DEVELOPMENT"}}],"PIcoPI":["458851","336959","561510"],"PO":["521752"]},"111527":{"abstract":"Abstract<br\/>0546907<br\/>Bevan Baas<br\/>U of California - Davis<br\/><br\/>CAREER: Processors for the Computation of Future Digital Signal Processing Applications<br\/><br\/>Applications requiring significant levels of Digital Signal Processing (DSP) are becoming increasingly commonplace examples include GPS receivers, Wi-Fi wireless networking, 3D medical imaging, and cell phones. As these applications become increasingly sophisticated and more frequently portable, their performance and power dissipation requirements often exceed the capabilities of modern DSP processors. The<br\/>goal of this research is to develop novel architectures, circuits, and software for high performance and low power DSP processors that meet the demands of emerging and future DSP applications, and that are also well-suited to future semiconductor fabrication processes. Research results are introduced into both undergraduate and graduate level courses and other investigators are involved in collaborative efforts. Results of this research are expected to enable new embedded, medical, environmental, and consumer applications.<br\/>To achieve project goals, the investigators develop DSP systems with features that are new on several levels. First, easily-scalable programmable building block processors with high performance and high energy efficiency are developed using innovative architectures, granularity, clocking, interconnection, and circuits. Second, efficient architectures are developed for shared blocks such as large memory arrays and specialpurpose DSP processors, as well as methods for effectively integrating these blocks into the programmable DSP array. Third, software tools including a compiler and automatic mapping tools are developed to more easily program the system. Fourth, to demonstrate gains in performance and energy efficiency, the system is implemented in silicon, tested, and characterized.","title":"CAREER: Processors for the Computation of Future Digital Signal Processing Applications","awardID":"0546907","effectiveDate":"2006-07-01","expirationDate":"2013-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7352","name":"COMPUTING PROCESSES & ARTIFACT"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7945","name":"DES AUTO FOR MICRO & NANO SYST"}}],"PIcoPI":["551167"],"PO":["562984"]},"111506":{"abstract":"n many technical disciplines, from electrical to mechanical engineering, the simplest and most straightforward way to communicate an idea is to draw a picture. Diagrams are particularly powerful in education when they are combined with computer simulation programs because, unlike paper, simulation programs allow students to explore the behavior of a physical system, such as a circuit or a mechanical device. Unfortunately, the mouse and keyboard interface to these programs prevent students from drawing their diagrams freely, forcing them continually to consult menus to choose pieces of the diagram. The hardware to draw on the computer exists; the bottleneck is the computer's inability to understand diagrams.<br\/><br\/>The PI's central research goal is to construct and deploy computer simulation tools capable of understanding students' hand-drawn diagrams. The results of free-sketch recognition research cannot yetbe incorporated into end-user applications for two reasons. First, free-sketch recognition is not sufficiently robust to incorporate into useful tools. Second, little is known about how to build usable interfaces that incorporate free-sketch recognition.<br\/>This work will bridge the gap between free-sketch recognition technology and its end-users by focusing on its application to undergraduate engineering design. The outcome of this work will be improved techniques for free-sketch recognition, guidelines for incorporating free-sketch recognition into usable interfaces, and educational sketch-based simulation tools. This project also includes a significant outreach component aimed at establishing a community of educational and technological researchers with the combined expertise necessary to evaluate the effectiveness of these tools on learning.<br\/><br\/>This research project directly supports the PI's educational goal of increasing the number and diversity of students who use and who develop technology. First, technology that can understand hand-drawn diagrams will provide students with a more familiar interface to simulation programs, lowering the barrier to using technology in the classroom, particularly for students with less computer experience including women and underrepresented minorities. Second, this research will be performed at Harvey Mudd College, an exclusively undergraduate institution. The small size of the college and low faculty to student ratio (1:9) will enable the PI to work closely with undergraduates, teaching them the basics of performing research and preparing many for graduate work.","title":"CAREER: Smarter Educational Software through Sketch Recognition","awardID":"0546809","effectiveDate":"2006-07-01","expirationDate":"2013-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7496","name":"COLLABORATIVE SYSTEMS"}}],"PIcoPI":["558317"],"PO":["564318"]},"112507":{"abstract":"Abstract<br\/><br\/>Program: NSF 04-588 CISE Computing Research Infrastructure<br\/>Title: CRI: Enhancing the Open Network Laboratory <br\/>Proposal: CNS 0551651<br\/>PI: Turner, Jonathan S.<br\/>Institution: Washington University<br\/><br\/><br\/>The principal investigators at Washington University will extend and upgrade the Open Network Laboratory as a community resource. The Open Network Laboratory (ONL) provides community access to extensible, gigabit routers; it allows remote users to conduct experiments and demonstrations for research and education. It can be used to prototype new network architectures and services, monitor network traffic at various levels of detail, and provide experimenters with real time interaction and display. This award will expand ONL with eight additional routers using new network processor platforms; these will allow packet classification, per-flow queueing, flexible measurement, and plug-ins for developing new features. The existing ONL is heavily used by networking researchers and educators. These enhancements will enable more users to access the resources, expand the realism of experiments, and enable research and experimentation that is better suited to emerging networking architectures. Broader impacts include providing a broadly accessible facility for research and education, supporting research and education that complements a leading industry sector, and providing a facility that uniquely supports realistic experimentation for education uses.","title":"CRI: Enhancing the Open Network Laboratory","awardID":"0551651","effectiveDate":"2006-07-01","expirationDate":"2009-12-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"024F","name":"GENI CONCEPT\/DEVELOPMENT"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7359","name":"COMPUTING RES INFRASTRUCTURE"}}],"PIcoPI":["522381","316262","522382"],"PO":["565090"]},"112518":{"abstract":"Abstract<br\/><br\/>Program: NSF 04-588 CISE Computing Research Infrastructure<br\/>Title: CRI: Acquisition of Research Instrumentation Infrastructure for Next-Generation Broadband Communication Systems <br\/><br\/>Lead Proposal: CNS-0551686<br\/>PI: Henderson, Thomas R.<br\/>Institution: University of Washington<br\/><br\/>Proposal: : CNS-0551378 <br\/>PI : Riley, George F.<br\/>Institution: Georgia Tech Research Corporation - GA Institute of Technology <br\/><br\/>Proposal: : CNS-0551706<br\/>PI : Floyd, Sally<br\/>Institution: International Computer Science Institute<br\/><br\/><br\/>Investigators at the University of Washington, the Georgia Institute of Technology and the International Computer Science Institute will re-design, enhance and maintain the Network Simulator to address research and education challenges for the next generation of data networks. Improvements will include a new simulator architecture, new models for wireless networks, provide for software encapsulation, and integration of the tools with virtual network testbeds. The changes will enhance scalability, extensibility, and new application program interfaces that open the simulator to open source networking software. Emulation capability will be improved to allow integration with testbeds.Wireless modules will be rewritten to track advances in wireless networking. Educational scripts will be facilitated in the enhanced version. The Network Simulator is heavily used in research; these improvements will allow it to continue to be a leading resource for","title":"CRI: Collaborative Proposal: Developing the Next-Generation Open-Source Network Simulator (ns-3)","awardID":"0551686","effectiveDate":"2006-07-01","expirationDate":"2010-12-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7359","name":"COMPUTING RES INFRASTRUCTURE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"J197","name":"NAVAL RESEARCH LAB"}}],"PIcoPI":["429182","529904"],"PO":["564778"]},"116819":{"abstract":"With the continuing advancement of MEMS technology, wireless embedded systems are deployed in various kinds of environments from well-controlled laboratories to turbulent ocean floors. System design has made simplifying and sometimes unrealistic assumptions about the resulting communication and sensing patterns. Although embedded devices are normally micro-calibrated individually before deployment, preliminary results indicate that the deployment environment is a dominating factor in communication and sensing characteristics of embedded devices. This research aims at developing a wide spectrum of modeling methodologies and related protocols for large-scale embedded systems under realistic environments. The main objective of this project lies in developing three novel modeling approaches, which complement each other and cover a large cost-benefit design space. The first is to develop a new radio irregularity model based on concepts of degree of irregularity and variance of signaling power. The second seeks a capability for abstraction of a completely repeatable physical environment, using an automated capture-and-replay process. The third features a novel way to use training events in a controlled manner to produce non-parametric realistic sensing and communication patterns. A key challenge for in-situ modeling lies in reconciling the conflict between the in-situ modeling accuracy and the related cost to build and use these models in resource-limited large-scale embedded systems.<br\/><br\/> This project seeks to develop the models from the micro to macro levels where designers can choose the appropriate level of detail based on the accuracy needs, and also the models from parametric to non-parametric types where designers can choose the models with proper costs based on the available resources. The models will be available via common simulation systems, enabling embedded systems designers to develop solutions based on realism and avoid an all-to-common problem found today where solutions developed by simulation don't work in the real world. This, in turn, is expected to have a major impact on embedded systems by saving development time and money and resulting in more efficient, robust, predictable and controllable systems. Research results will be evaluated using traffic-monitoring and management testbeds at the University of Minnesota and the University of Virginia.","title":"Collaborative Research: CSR--EHS: Obtaining Realistic Communication and Sensing In-situ Models for Wireless Embedded Systems","awardID":"0614870","effectiveDate":"2006-07-01","expirationDate":"2009-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["550342"],"PO":["561889"]},"121507":{"abstract":"There is a clear and urgent need to plan and develop information infrastructure to provide fast and effective relief during emergencies. During Katrina, the team provided the capability to create an amalgamated list of \"missing\" and \"safe\" people, updated daily. The systems and processes for collecting, cleansing and collating names were developed as the disaster was unfolding. Leveraging this first-hand experience permits the team to do a careful analysis of the needs and requirements of such an emergency response application. A planned and principled approach to the design and develop will provide an even more effect response in future emergencies. The specifications include appropriate systems for relief workers, field data collection systems, and adaptable backup system. The design and best practices will help the nation be ready for the next such emergency.","title":"SGER: Cyberinfrastructure Preparedness for Emergency Response and Relief: Learning the lessons from Hurricane Katrina","awardID":"0638561","effectiveDate":"2006-07-15","expirationDate":"2007-12-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7602","name":"INFORMATION INTEGRATION"}}],"PIcoPI":["559496"],"PO":["565136"]},"123718":{"abstract":"In this project the PIs will design, develop, and clinically test a vision-based user interface for enhancing the efficacy of wheelchair mounted assistive robot arms in unstructured environments. The target population is wheelchair bound individuals with limited upper extremity movement, such as patients diagnosed with Cerebral Palsy, ALS, Poliomyelitis, Multiple Sclerosis, Spinal Cord Injury, Muscular Dystrophy, and similar conditions that affect use of the upper limbs. The goal is to allow these people to function independently with comfort and speed in a variety of unstructured environments such as a grocery store, a living room, or an office. The innovation in this project that sets it apart from existing approaches is the segregation of robot motion into gross and fine components instead of unnatural joint or Cartesian motion as is currently the norm. To transform their bold vision into reality, the PIs will: develop a gross motion human-robot interface utilizing computer vision techniques and the human in the loop; utilize computer image processing algorithms for implementing a real-time robust feature identifier that is able to suggest to the user areas of interest, using computer vision techniques to segment by color, depth and other criteria; effect fine motion of the robot end-effector to facilitate pick-and-place tasks via fusion of geometric ideas from vision and adaptive control; develop a working prototype through unification of HRI, sensing, and control algorithms; and demonstrate benchmark activities of daily living tasks for wheelchair bound individuals with upper extremity impairments by tapping into the human resources available at Good Shepherd Rehabilitation Hospital located in Pennsylvania's Lehigh Valley. <br\/><br\/>Broader Impacts: The design of an enhanced functionality wheelchair robot will be a major leap toward rehabilitation of a broad segment of society whose members otherwise have only limited access to resources and opportunity. The PIs expect their approach to be directly relevant to any mobile device with on-board vision and where one can take advantage of the human in the loop, and thus to provide a new model of human-robot interaction for assistive technology. Interaction methods developed will be adaptable to a wide range of access devices, ranging from single switch scanning to sip-and-puff to a joystick. Moreover, the PIs expect that the fusion of vision and nonlinear control demonstrated in this project will advance the theory and applicability of computer vision and visual servoing.","title":"Collaborative Research: A Novel User Interface for Operating an Assistive Robot Arm in Unstructured Environments","awardID":"0649736","effectiveDate":"2006-07-01","expirationDate":"2011-11-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6846","name":"UNIVERSAL ACCESS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":[328286],"PO":["565227"]},"120719":{"abstract":"Costly effort is spent each year on wildlife population surveys performed through call-and-response. The population of Spotted Owls for example, an endangered species, is estimated by such method in California and other states. An automated system leveraging cellular telephones as remote audio transport offers the potential to greatly automate the process of call-and-response survey.<br\/><br\/>This study is investigating the potential of cellular-grade communication in playback experiment results and is comparing its performance with that of direct human calls or by high quality broadcast audio equipment. The experiments, conducted in the Yale-Myers Forest in northeastern CT, evaluate the behavioral response of mobbing birds to squirrel and great-horned owl calls originating from cellular telephone. Success of this work will enable better monitoring of endangered and threatened species and enhance our knowledge of biodiversity.","title":"SGER: Cellular Telephone Playback in Bioacoustic Experiments","awardID":"0634690","effectiveDate":"2006-07-01","expirationDate":"2007-12-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7294","name":"SCIENCE & ENGINEERING INFORMAT"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":["427498"],"PO":["565136"]},"116270":{"abstract":"This project will develop a combination of novel computational methods to improve inferences of human genomic history from data on genetic variability between individuals. Large amounts of data have recently been gathered on the small genetic differences that distinguish one person from another. Such information is valuable for inferring how the genome has changed over the course of human history and for understanding the specific biological processes that have shaped it over time. These basic scientific results in turn have relevance to many practical problems in identifying the functions of genes, facilitating future genetic studies, and finding and mitigating risk factors for disease. Making optimal use of this information will, however, require new advances in mathematical models of how genetic variations are produced and in the computer algorithms needed to use those models to analyze real sequence data. The proposed work is based on a strategy to overcome limitations of the data and current computational capabilities by combining theoretical tools for haplotype structure identification, which finds segments of DNA that have been largely conserved over long periods of human history, with tools for phylogenetics, which infers how different individuals or populations are related to one another. Executing this strategy will involve a multidisciplinary effort, bringing together techniques from population genetics, computer science, mathematics, and operations research. In addition to its direct scientific outputs, the project will develop human resources by creating new course material and student research projects to help prepare future scientists to work at the intersection of these fields.","title":"Generalizing Haplotype Models for Phylogenetics","awardID":"0612099","effectiveDate":"2006-07-01","expirationDate":"2011-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7294","name":"SCIENCE & ENGINEERING INFORMAT"}}],"PIcoPI":["561985","548200","563452"],"PO":["565136"]},"116281":{"abstract":"In every scientific discipline, researchers are digitizing their knowledge and using computational methods. This process has generated enormous amounts of ad hoc data, data for which standard data processing tools are not readily available. This kind of data poses challenges to both the users and the software that manipulate it. In order to maximize the efficiency and accuracy with which scientists deal with ad hoc data, new work will expand the existing data description and processing language. The ability to process prevalent kinds of data sources will be expanded and the system modified to generate tools in a robust and automatic way. This will permit the system to provide a way to provide descriptive information about the data directly to the tools. The system will be formalized to prove the correctness of the tools. The research combines novel programming language design, high-performance system engineering and theoretical analysis to solve crucial data processing problems. The system will be tested to address real problems such as fraud detection and in the context of genomic pathway modeling, as well as in cosmology data. Both graduate and undergraduate students are engaged in the interdisciplinary research.","title":"SEIII: Automatic Tool Generation for Ad Hoc Scientific Data","awardID":"0612147","effectiveDate":"2006-07-15","expirationDate":"2010-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7602","name":"INFORMATION INTEGRATION"}}],"PIcoPI":["483683"],"PO":["565136"]},"118041":{"abstract":"OISE 0620430<br\/><br\/>This U.S.-European workshop will bring together a diverse group of researchers and students from the United States, Hungary, and Italy with expertise in control of hybrid engineering and computer systems. The U.S. principal organizer, Gary Balas of the University of Minnesota, will work with international partners, Jozsef Bokor at the Budapest Technical University and Francesco Borrelli, from the Italian University del Sannio in Benevento, to conduct a workshop focused on problems associated with algorithms for design, implementation, verification and validation of safety systems. Discussions should benefit from U.S. expertise in robust control theory and implementation of adaptive control algorithms and from European strengths in power plant fault detection and isolation, vehicle control systems, and embedded control software design. Results are expected to address questions at the nexus of hybrid and robust control and lead participants to identification of common theoretical and computational issues that, with further research, could yield novel approaches to real time control for hybrid systems. Success would have implications for safety critical systems, ranging from aircraft flight control, to medical devices and nuclear power plants. <br\/><br\/>This interdisciplinary workshop fulfills the program objective of advancing scientific knowledge by enabling experts in the United States and Europe to combine complementary talents and share research resources in areas of strong mutual interest and competence. Broader impacts include early career introduction of junior U.S. faculty and graduate students to leading control theorists and engineers in the international research community.","title":"International: Workshop on Real Time Control of Hybrid Systems: Design, Implementation, Verification, and Validation","awardID":"0620430","effectiveDate":"2006-07-01","expirationDate":"2008-06-30","fundingAgent":[{"dir":{"id":"01","name":"Office of OFFICE OF THE DIRECTOR                  ","abbr":"O\/D"},"div":{"id":"0109","name":"Office of INTL SCIENCE & ENGINEERING","abbr":"OISE"},"pgm":{"id":"7299","name":"Catalyzing New Intl Collab"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0701","name":"Division of ELECTRICAL, COMMUN & CYBER SYS","abbr":"ECCS"},"pgm":{"id":"7607","name":"ENERGY,POWER,ADAPTIVE SYS"}}],"PIcoPI":["429261"],"PO":["561352"]},"118383":{"abstract":"The Symposium on Control of Mechanical Systems (SCMS) will be held on June 19-20, 2006 at<br\/>the University of California, Berkeley in Honor of Professor Masayoshi Tomizuka. The<br\/>conference, chaired by Professor Roberto Horowitz (University of California, Berkeley)<br\/>will bring leading researchers and practitioners from academics, industry, and government<br\/>agencies to interact on the latest advances in modeling and control of mechanical systems.<br\/>SCMS will bring together leading researchers in the field to assess the current state of<br\/>research and areas for future research and application. Participation is open and the<br\/>Symposium has been announced in important conferences and in relevant electronic media.<br\/>SCMS draws upon many disciplines, including system theory, control theory, computer and<br\/>communication networks, signal processing, and a wide array of application areas. A total<br\/>of approximately 120 attendees are expected to participate in this conference, of which 60<br\/>will be students. An amount of $20,000 is requested to support this conference. The funds<br\/>will be used to partially pay for the travel expenses of a number of graduate and<br\/>undergraduate students that will be selected from among the students that attend this<br\/>symposium and apply for travel support and for student dinning expenses. The remaining<br\/>funds will be used to partially support the travel expenses of some of the invited<br\/>speakers, who have retired and do not have other sources to support their travel.<br\/>Intellectual Merit: The purpose of this workshop is to bring leading researchers and<br\/>practitioners from academics, industry, and government agencies to interact on the latest<br\/>advances in modeling and control of mechanical systems. The primary goal of this proposal<br\/>is to seek financial support from NSF to invite approximately 60 students to the symposium<br\/>and expose them to current advances in the control of mechanical systems and its<br\/>applications. The invited students will present posters or orally in the workshop. We<br\/>also seek financial support to fund some of the invited speakers who have retired and do<br\/>not have other sources to support their travel. A book will be published, which will<br\/>contain the symposium memories and will include a series of tutorial and survey chapters,<br\/>written by many of the symposium presenters, in diverse subjects of mechanical systems<br\/>control, including adaptive, repetitive, nonlinear and optimal control ad estimation, as<br\/>well as state of the art applications.<br\/>Travel support for student attendees will be advertised nationally. Women, minorities, and<br\/>disabled students will be especially encouraged to apply.<br\/>Broader Impacts: Undergraduate and graduate students who attend the conference, present<br\/>papers, and participate in student-oriented activities are likely to pursue careers in the<br\/>field of control theory and its applications. The book that will be published as the<br\/>memories of this symposium will be a valuable reference and learning tool for many<br\/>undergraduate and graduate students, who may be pursuing or considering entering the field<br\/>of mechanical systems control.","title":"Symposium on Control of Mechanical Systems. To be Held June 19-20, 2006 at the University of California.","awardID":"0621997","effectiveDate":"2006-07-01","expirationDate":"2007-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6840","name":"ROBOTICS"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0701","name":"Division of ELECTRICAL, COMMUN & CYBER SYS","abbr":"ECCS"},"pgm":{"id":"7607","name":"ENERGY,POWER,ADAPTIVE SYS"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0703","name":"Division of CIVIL, MECHANICAL, & MANUFACT","abbr":"CMMI"},"pgm":{"id":"1632","name":"CONTROL SYSTEMS"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0703","name":"Division of CIVIL, MECHANICAL, & MANUFACT","abbr":"CMMI"},"pgm":{"id":"1639","name":"SENSORS AND SENSING SYSTEMS"}},{"dir":{"id":"07","name":"Directorate for DIRECTORATE FOR ENGINEERING             ","abbr":"ENG"},"div":{"id":"0703","name":"Division of CIVIL, MECHANICAL, & MANUFACT","abbr":"CMMI"},"pgm":{"id":"7478","name":"DYNAMICAL SYSTEMS"}}],"PIcoPI":["426344"],"PO":["564728"]},"118284":{"abstract":"CMU proposes to explore methodologies and algorithms for automating analysis of failures and performance degradations in large-scale storage systems. Problem analysis includes such crucial tasks as identifying which component(s) misbehaved, likely root causes, and supporting evidence for any conclusions. Combining statistical tools with appropriate instrumentation, we hope to dramatically reduce the difficulty of analyzing performance and reliability problems in deployed storage systems. Such tools, integrated with automated reaction logic, also provide an essential building block for the longer-term goal of self-healing.<br\/>Automating problem analysis is crucial to achieving cost-effective storage at the scales needed for tomorrow's high-end computing systems. The number of hardware and software components will make problems common rather than anomalous, so it must be possible to quickly move from problem to fix with little-to-no system downtime for analysis. Further, the distributed software complexity of such systems make by-hand analysis increasingly untenable. More nuanced, but perhaps of most concern, implementors of these storage systems are increasingly unable to test in representative high-end computing environments because they simply cannot afford to recreate the necessary system scale. As a result, scale-related problems must be analyzed in the field to allow improvements to be made, which introduces delays and productivity reductions for customers\/users plus issues of clearance for systems deployed to support highly sensitive activities. Current designs and tools fall far short of what is needed.","title":"HECURA: Toward Automated Problem Analysis of Large Scale Storage Systems","awardID":"0621508","effectiveDate":"2006-07-15","expirationDate":"2009-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7583","name":"ITR-HECURA"}}],"PIcoPI":["486330","486331",313442],"PO":["565272"]},"119682":{"abstract":"ABSTRACT<br\/>0629001<br\/>Kavraki, Lydia<br\/>William Marsh Rice U<br\/><br\/>Support for Federated Logic Conference<br\/><br\/>In 1996, as part of the Special Year on Logic and Algorithms, DIMACS hosted the first Federated Logic Conference (FLoC). It was modeled after the successful Federated Computer Research Conference (FCRC), and synergetically brought together conferences that apply formal methods to computer-science problems. The second Federated Logic Conference (FLoC'99) was held in Trento, Italy, in July 1999, and the third Federated<br\/>Logic Conference (FLoC'02) was held in Copenhagen, Denmark in July2002. It consisted of seven major conferences and 35 workshops, attracting about 900 participants. The fourth Federated Logic Conference, will be held in Seattle, Washington, in August 2006. The following conferences will participate in FLoC'05:<br\/>Conference on Computer-Aided Verification (CAV)<br\/>International Conference on Logic Programming (ICLP)<br\/>International Joint Conference on Automated Reasoning (IJCAR)<br\/>IEEE Symposium on Logic in Computer Science (LICS)<br\/>Conference on Rewriting Techniques and Applications (RTA)<br\/>International Conference on Theory and Applications of<br\/>Satisfiability Testing (SAT)<br\/>Intellectual Merit:<br\/>The federated logic conference is a back-to-back event of all the major international conferences in the area of Formal Methods. While the participating conferences are normally held individually by their local conference organization on an annual basis, they all agree to this joint and federated event to be held every three-four years. The number of participants is near one thousand, and a third to one half of the participants are expected to be young researchers.<br\/>Broad Impact:<br\/>Enhancing the security, privacy, usability, and reliability of computing systems is widely accepted as one the grand challenges facing the computing-research community. Formal Methods have emerged as one of the primary approaches towards that goal. A federated conference provides an opportunity for accelerating research via synergy between the different strands of research in Formal Methods. It is also an outstanding training opportunity for young researchers, as it offers them a grand view of the whole area.","title":"Support for Federated Logic Conference","awardID":"0629001","effectiveDate":"2006-07-01","expirationDate":"2007-06-30","fundingAgent":[{"dir":{"id":"03","name":"Directorate for DIRECT FOR MATHEMATICAL & PHYSICAL SCIEN","abbr":"MPS"},"div":{"id":"0304","name":"Division of MATHEMATICAL SCIENCES","abbr":"DMS"},"pgm":{"id":"1268","name":"FOUNDATIONS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7351","name":"THEORETICAL FOUNDATIONS (TF)"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7352","name":"COMPUTING PROCESSES & ARTIFACT"}}],"PIcoPI":["557516"],"PO":["564388"]},"109573":{"abstract":"The motivation for this research is to improve time-critical government services such as emergency medical services (EMS). The research objectives are three-fold: (1) Assess operational, organizational, and governance dimensions of inter-organizational information-sharing in EMS, (2) Examine end-to-end performance of EMS systems under both normal and extreme conditions, and (3) Analyze local and national policy implications for deploying new organizational models for encouraging collaborative IT efforts by EMS providers.<br\/><br\/>To accomplish this research objective, the research team will conduct a multi-method approach involving four discrete activities. First, a model outlining critical interfaces among EMS providers will be refined based on examination of the literature from organizational theory, information science, and associated disciplines (e.g. public administration) as well as from expert input (including an advisory panel). The result will be descriptions of operational, organizational, and governance dimensions and guidelines for case studies. The second activity will be to conduct case studies in California and Minnesota that will examine these dimensions with specific reference to the role of information technology (IT) in supporting end-to-end performance. The third activity will be to synthesize case study information through a combination of quantitative simulation analysis and qualitative analysis. A key result of this synthesis will be an institutional framework for deploying IT in support of collaborative EMS activities. Finally, a national workshop will be held in Washington DC to facilitate the discussion of policy implications and dissemination of research findings.<br\/><br\/>Intellectual Merit. While there is a burgeoning literature on digital government processes, to date, there<br\/>has been minimal attention to the time-criticality dimension of information services. This research will<br\/>develop a foundation for conceptual and empirically-based tools that can improve scientific understanding<br\/>about how information and organizational systems interact to facilitate and\/or thwart the delivery of<br\/>emergency response services. The findings can also be used beyond the application of EMS and contribute to our understanding of how public services, broadly construed, perform during time-critical conditions, with particular attention to the interweaving influences of organizational and information technology dynamics. From a methodological perspective, the project will explore how both qualitative (e.g., case studies) and quantitative (e.g., simulation) methods can aid in understanding end-to-end performance of government services.<br\/><br\/>Broader Impacts. The research team intends to help EMS responders and agencies enhance service quality, reduce disability consequences, and save lives. The immediate area for impact is improving emergency response services to benefit a broad range of citizen needs; accident and fatalities statistics show that mobile emergency needs cut across race, income, and ethnic backgrounds. This multi-dimensional analysis is also aimed to help policy makers and program managers understand how technology enhancements to one dimension (i.e., inter-organizational cooperation) can have impacts on citizen-level performance.","title":"Multi-Dimensional Electronic Collaboration For Time-Critical Mobile Emergency Response","awardID":"0535273","effectiveDate":"2006-07-01","expirationDate":"2010-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7496","name":"COLLABORATIVE SYSTEMS"}}],"PIcoPI":[290087,290088],"PO":["469867"]},"119650":{"abstract":"The goal of this exploratory project is to determine whether people can learn to write legibly without visual feedback. Specifically, the PI will explore ways to train blind individuals to use handwriting as an accurate and convenient method for entering text into a Personal Data Assistant (PDA). He will determine equipment requirements, and design and implement proof-of-concept software and hardware that will enable low-cost, off-the-shelf PDAs or smart remote controls, which are currently unusable by people who are blind, to replace expensive Braille devices. If this is possible, determining the optimum feedback strategy will require evaluation of many different modalities and techniques. Blind and visually impaired subjects will learn the shapes of letters by tracing them out on laser-cut stencils. Various sizes and fonts will be evaluated to determine the best fit for writing on a PDA screen. Various audio and haptic feedback techniques will be evaluated for reinforcing muscle memory, with the goal of providing a virtual audio and haptic template, whose exact nature is not yet known, after the mechanical template is removed. The software will remember the trajectory of the physical template, and any deviation from it will result in changes in sounds or pseudo-haptic vibration patterns in the stylus. Similar feedback will be used to provide the user with information relating to position and orientation of the writing. In addition to providing feedback that guides the handwriting, it will also be necessary to integrate feedback such as synthesized speech from the application that is being accessed; this will lead to interesting research questions such as how to minimize the cognitive load imposed on the user and how to prevent different feedback channels from interfering with each other. As time allows, the PI plans to also explore whether strategies similar to those that turn out to be effective for blind users will prove effective as well for sighted people who must function in eyes-busy or poorly illuminated situations. <br\/><br\/>Broader Impacts: If successful, this project will lead to low-cost alternatives to Braille devices, will enable blind people to pick and choose from off-the-shelf consumer devices, and will eliminate the need to learn Braille for people who lose their sight after they have already learned handwriting. The project will lead to alternative ways for aging people to interact with devices, such as TV remotes, when physical or visual impairment make it difficult for them to read the legends on the buttons or to operate the buttons. These benefits are not limited to aged or disabled people, however. Handwriting input provides a convenient input modality for any device that employs natural language processing. Most current devices that use natural language input require the use of either a keyboard or a speech recognition system. Unfortunately, speech recognition is still unreliable in many domestic and work environments, and inappropriate in many social situations. Initial experiments with a PDA have shown that it is much easier and quicker to write commands (such as \"tv on\") than to navigate menus and select the required option. The PI's Archimedes Project has previously developed, and received several patents for, an Intent Driven Interface called iTASK that uses natural language text input to control computers or appliances and enter information into a computer. The proposed handwriting input strategies will be fully compatible with iTASK and will enhance its usability in a very broad range of home, work, school, and leisure applications.","title":"Teaching Handwriting to Persons who are Blind and Developing a Handwriting Accessor","awardID":"0628794","effectiveDate":"2006-07-01","expirationDate":"2007-12-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6846","name":"UNIVERSAL ACCESS"}}],"PIcoPI":["433796"],"PO":["565227"]},"118451":{"abstract":"The U.S. National Committee (USNC) for the international Committee on Data for Science and Technology (CODATA) of the International Council for Science (ICSU) will lead and coordinate participation by the U.S. scientific community in the work of CODATA. CODATA is concerned with all types of quantitative data resulting from experimental measurements or observations in the natural and social sciences and in the engineering disciplines. <br\/><br\/>The overall objectives of CODATA are to: improve the quality and accessibility of data, as well as the methods by which data are acquired, managed, and analyzed; facilitate international cooperation among those collecting, organizing, and using data; and promote an increased awareness in the scientific and technical community of the importance of these activities and issues. <br\/><br\/>The USNC\/CODATA proposes to continue to advance these data management and policy objectives by organizing in-depth studies, national and international data conferences, bilateral symposia, federal data forums, Committee meetings at the National Academies, and related Web sites.<br\/><br\/>The USNC will also identify and suggest ways in which the rapidly changing technological capabilities for creating, manipulating, disseminating, and using digital scientific and technical (S&T) data can address new opportunities and challenges. The opportunities arise primarily in data-intensive research and applications, in the integration of heterogeneous data for new results, and in making vast amounts of factual information available for a broad spectrum of users. The inherent challenges are in effectively managing these data resources for optimal access and use, and for developing the appropriate policies and institutional models.<br\/><br\/>The Committee will: coordinate its activities within the National Academies with other data and information technology groups; build on its established relationships with federal and academic data centers, and professional organizations and experts in the United States; and promote U.S. data policies and practices internationally through its many contacts with foreign and intergovernmental scientific umbrella organizations and data activities.","title":"U.S. National Committee for CODATA","awardID":"0622279","effectiveDate":"2006-07-15","expirationDate":"2012-06-30","fundingAgent":[{"dir":{"id":"01","name":"Office of OFFICE OF THE DIRECTOR                  ","abbr":"O\/D"},"div":{"id":"0109","name":"Office of INTL SCIENCE & ENGINEERING","abbr":"OISE"},"pgm":{"id":"7731","name":"OTHER GLOBAL LEARNING & TRNING"}},{"dir":{"id":"04","name":"Directorate for DIRECT FOR SOCIAL, BEHAV & ECONOMIC SCIE","abbr":"SBE"},"div":{"id":"0406","name":"Office of INTL SCIENCE & ENGINEERING","abbr":"OISE"},"pgm":{"id":"7299","name":"Catalyzing New Intl Collab"}},{"dir":{"id":"04","name":"Directorate for DIRECT FOR SOCIAL, BEHAV & ECONOMIC SCIE","abbr":"SBE"},"div":{"id":"0406","name":"Office of INTL SCIENCE & ENGINEERING","abbr":"OISE"},"pgm":{"id":"7328","name":"ICSU"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7602","name":"INFORMATION INTEGRATION"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0503","name":"Division of SHARED CYBERINFRASTRUCTURE","abbr":"SCI"},"pgm":{"id":"7475","name":"HEC CORE FACILITIES"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"4095","name":"SPECIAL PROJECTS IN NET RESEAR"}},{"dir":{"id":"06","name":"Directorate for DIRECTORATE FOR GEOSCIENCES             ","abbr":"GEO"},"div":{"id":"0600","name":"Division of A\/D FUND","abbr":"A\/D"},"pgm":{"id":"1679","name":"INTERNATIONAL COORDINATION ACT"}},{"dir":{"id":"08","name":"Directorate for DIRECT FOR BIOLOGICAL SCIENCES          ","abbr":"BIO"},"div":{"id":"0808","name":"Division of BIOLOGICAL INFRASTRUCTURE","abbr":"DBI"},"pgm":{"id":"1101","name":"RESEARCH RESOURCES"}},{"dir":{"id":"08","name":"Directorate for DIRECT FOR BIOLOGICAL SCIENCES          ","abbr":"BIO"},"div":{"id":"0808","name":"Division of BIOLOGICAL INFRASTRUCTURE","abbr":"DBI"},"pgm":{"id":"1165","name":"ADVANCES IN BIO INFORMATICS"}}],"PIcoPI":["499569"],"PO":["445301"]},"116284":{"abstract":"Biomarkers measured in a minimally invasive and repeatable way can expedite the early diagnosis of disease, the indication of disease prognosis, and the discovery of new drug targets for therapy. Serum proteomic profiling for biomarker detection may reflect the abnormality or pathologic state of various diseases through the protein\/peptide peaks that are expressed differently between diseased and healthy individuals. Since the procedures are simple, inexpensive, and minimally invasive, serum proteomic methods readily lend themselves to screening-test development; their robustness and ease promise to translate into routine clinical practice. The objective of this project is to construct a high-throughput proteomic profiling analysis toolset, Proteomics Biomarker Information System (ProBIS), which can provide early biomarker detection and identification for clinical proteomics healthcare. Our main contributions are: (1) High Resolution Proteomic Profiling: different from traditional low resolution mass spectrometry analysis, we will use high resolution profile to analyze the low-molecular weight (LMW) end of the proteomic spectrum for more precise analysis; and (2) Integrated System for Biomarker Discovery and Identification: identification and sequencing of the underlying discriminatory proteins\/peptides will reveal the insights of biomarkers and characterize disease pathway. The results of this project will have an impact on the computer science community and an equal, if not greater, impact on the broad medical community that is in need of such a proteomic profiling data analysis tool. The experiments will be driven by a series of case studies, including ovarian cancer early relapse monitoring and prostate cancer diagnosis. The solutions for these case studies will have a direct impact on individual areas. Our source code and data will be available for general dissemination over the internet, and discoveries will be integrated into the classroom.","title":"Collaborative Research: Proteomics Biomarker Information System (ProBIS)","awardID":"0612152","effectiveDate":"2006-07-01","expirationDate":"2010-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7294","name":"SCIENCE & ENGINEERING INFORMAT"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":[307782],"PO":["565136"]},"109420":{"abstract":"Researchers at New York University, Monmouth University and the<br\/>University of Colorado are constructing Japanese\/English and<br\/>Chinese\/English machine translation systems which automatically acquire<br\/>rules from ``deep'' linguistic analyses of parallel text. This work<br\/>is a natural culmination of automated example-based Machine<br\/>Translation (MT) projects that have become increasingly sophisticated<br\/>over the last two decades. The following recent advances in Natural<br\/>Language Processing (NLP) technologies make this inquiry feasible: (1)<br\/>annotated data including bilingual treebanks and processors trained on<br\/>this data (parsers, PropBankers, etc.); (2) semantic post-processors<br\/>of parser output; (3) programs that automatically align bitexts; and<br\/>(4) bilingual tree to tree translation models.<br\/><br\/>Natural languages vary widely in the ordering of corresponding words<br\/>for equivalent expressions across linguistic boundaries and within a<br\/>single language. This research investigates ways to minimize the<br\/>variations within a single language using a type of semantic<br\/>representation (GLARF) that is derived automatically from syntactic<br\/>trees. Such semantic representation provides for: (1) a reduction in the<br\/>number of ways of representing the same underlying message, and (2)<br\/>a way to handle long distance dependencies (e.g. relative<br\/>clauses) as local phenomena. Therefore, there is no need to resort to<br\/>arbitrarily long sentence fragments or large trees for<br\/>training. Furthermore, since less data is needed, it<br\/>minimizes the sparse data problem.<br\/><br\/>In the training of this translation model, because of (1), the number<br\/>of mapping rules between the source tree and the target tree is<br\/>reduced. The translation model, then, is a tree transducer, with<br\/>``deep'' linguistically analyzed trees for both source and target<br\/>representations. In order to provide efficient computer algorithms<br\/>for such partial mappings, this research needs to focus on<br\/>(a) the training algorithm and the (b) the constraints over the<br\/>mapping rules in order to reduce the computational complexity.<br\/><br\/>This research is expected to yield several advantages: The core<br\/>architecture of this transducer using ``deep'' linguistic analyses<br\/>should yield more accurate results. The GLARF architecture allows<br\/>control over different granularity of automatically-obtained<br\/>linguistic analyses.<br\/><br\/>Broader Impact: The demand for machine translation spans from the<br\/>local government (e.g. police forces) to national government<br\/>(e.g. CIA) and the private sector. Given the growth of the Internet<br\/>outside the English speaking world, better machine translation is of<br\/>critical importance for the broader community. This work directly<br\/>affects the ability of English speakers to understand websites written<br\/>in Chinese and Japanese, two of the most widely used languages on the<br\/>Internet. The technique is generalizable to other language pairs and<br\/>can ultimately have even wider impact.","title":"Collaborative Research: Structure Alignment-based Machine Translation","awardID":"0534325","effectiveDate":"2006-07-01","expirationDate":"2010-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":[289668],"PO":["565215"]},"118264":{"abstract":"IIS-0621438<br\/>Johannes E Gehrke <johannes@cs.cornell.edu><br\/>Cornell University<br\/><br\/>Developing Formal Semantics for Data Streams<br\/><br\/>In many applications, for example stock monitoring to large-scale system<br\/>monitoring, data is not static but arrives in high-speed data streams. Unlike<br\/>in traditional Database Management Systems, research in data streams has been<br\/>driven by the development of many application-specific systems and languages.<br\/>The result has been a plethora of stream query languages, with no unified<br\/>formal framework for optimization or general study. <br\/><br\/>This project is developing a formal semantics to unify data stream query<br\/>languages, like what already exists for traditional relational databases.<br\/>This project is (1) developing a formal data stream language powerful enough<br\/>to encompass all of the existing data stream query languages, (2) using this<br\/>framework to identify the expressive power of these existing languages, and<br\/>(3) developing a language hierarchy within this framework that identifies the<br\/>trade-off between expressiveness and performance. The proposed educational<br\/>program will train a graduate student for research in the theory of data<br\/>streams. Success in this project will bring tremendous benefits to data<br\/>stream processing, as it will provide a uniform framework for studying<br\/>optimization of data stream queries. It will also connect the area of<br\/>mathematical logic with data stream systems, a connection that has already<br\/>been shown to be beneficial for traditional database systems. Our results<br\/>will be disseminated via the following website:<br\/>http:\/\/www.cs.cornell.edu\/database\/cayuga\/expressiveness\/.","title":"A Formal Approach to Data Stream Processing","awardID":"0621438","effectiveDate":"2006-07-01","expirationDate":"2008-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7496","name":"COLLABORATIVE SYSTEMS"}}],"PIcoPI":["448955","466933"],"PO":["355797"]},"116285":{"abstract":"An inverted repeat (IR) consists of two copies of homologous DNA separated by a spacer region, with one copy inverted and complemented relative to the other. IRs occur frequently in genomic DNA and can have profound effects on chromosomal function and gene expression. IRs are a common component of RNA secondary structure, and are known to contribute to RNA interference and micro-RNA formation. A lack of sensitive, comprehensive, and efficient detection programs and databases has hampered the identification, annotation, and the study of IR functions. This project will explore and test new, efficient algorithmic methods for detecting approximate and exact IRs in genomic length sequences and create new data sets on the occurrence and characteristics of IRs in many genomes. It has three major goals: 1) To develop an Inverted Repeats Finder (IRF) program to detect approximate and exact IRs in long genomic sequences. 2) To develop a web-accessible, user-friendly, Inverted Repeats Database (IRDB) which will contain comprehensive information on IRs occurring in publicly available genomes. 3) To conduct collaborative research studies using IRF. The first study will examine the occurrence of cruciform structures in the human and other genomes in order to identify IR characteristics that make cruciform extrusion likely. The second study will examine the relationships, in mitochondrial DNA, among short imperfect repeats, age related deletions, and species life span.<br\/><br\/>The IRF\/IRDB software and data sets they produce will directly enhance the broader infrastructure for research in genome biology, genome evolution, chromosome architecture, and comparative genomics. This project will provide opportunities in research to graduate, undergraduate and high school students in the PI's lab, including participation by members of underrepresented groups, and it will include outreach to high school mathematics and biology teachers through curriculum development in interdisciplinary topics in computational biology and bioinformatics. As with other resources previously developed by the PI, all computer tools resulting from this project will be freely available to the research community through a high capacity website maintained in the PI's lab.","title":"SEI(BIO): DNA Inverted Repeats: Sensitive Detection Methods and Research Database","awardID":"0612153","effectiveDate":"2006-07-01","expirationDate":"2010-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7294","name":"SCIENCE & ENGINEERING INFORMAT"}}],"PIcoPI":["451346"],"PO":["565136"]},"109520":{"abstract":"This project investigates a new dynamic, adaptable approach for constructing<br\/>evaluation metrics and methods for various NLP applications, with a specific<br\/>focus on Machine Translation and Summarization. The main objective is to<br\/>establish a general framework that can easily support constructing automatic<br\/>evaluation metrics for a variety of specific NLP tasks and based on a variety<br\/>of quality criteria. For a given NLP task (e.g. Machine Translation) and a<br\/>given set of established quality criteria, the framework supports learning a<br\/>set of parameters that result in an \"instance\" evaluation metric that has<br\/>optimal correlation with the desired quality criteria. Training a new<br\/>\"instance\" metric for a different task, or for a different set of quality<br\/>criteria, can be accomplished by a fast training procedure using available<br\/>training data consisting of system produced outputs, human-quality reference<br\/>outputs for the same source data, and human quality judgments for the system<br\/>outputs.<br\/><br\/>A powerful new innovation of the new framework is its ability to use the set<br\/>of all overlapping sub-sequences (also known as \"skip ngrams\") of the two<br\/>strings being compared. The process of skip n-gram matching is augmented with<br\/>a powerful word-to-word alignment algorithm that pre-constrains the set of<br\/>skip n-gram matches, while allowing matches between words that are<br\/>morphological variants, synonyms or otherwise related. Furthermore, our<br\/>framework uses a well-founded parameterized model for establishing the weight<br\/>or significance that should be assigned to each detected overlapping<br\/>subsequence, and can calculate these weights as an integral process during the<br\/>detection of the matching skip ngrams. The result is an extremely powerful<br\/>\"metric-producing\" framework. Under this framework, the project will produce<br\/>(instantiate) specific metrics for machine translation, summarization, and<br\/>other NLP tasks, that are more robust, sensitive, and have high-levels of<br\/>correlation with human judgments. The project also explores methods for<br\/>reducing the reliance of our resulting metrics on human judgments. The<br\/>resulting framework and task-specific trained metrics will be made publicly<br\/>available to the NLP research community. The impact of automatic evaluation<br\/>methods extends beyond providing a flexible performance measuring mechanism<br\/>for NLP tasks. We expect our work to enable customizing evaluation metrics<br\/>for specific tasks within a variety of cross-lingual applications, which<br\/>should significantly boost the overall performance of these applications.","title":"A Framework for Learning High Accuracy Evaluation Metrics for NLP Applications","awardID":"0534932","effectiveDate":"2006-07-01","expirationDate":"2009-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7274","name":"HUMAN LANGUAGE & COMMUNICATION"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":["502549"],"PO":["565215"]},"109476":{"abstract":"Researchers at New York University, Monmouth University and the<br\/>University of Colorado are constructing Japanese\/English and<br\/>Chinese\/English machine translation systems which automatically acquire<br\/>rules from ``deep'' linguistic analyses of parallel text. This work<br\/>is a natural culmination of automated example-based Machine<br\/>Translation (MT) projects that have become increasingly sophisticated<br\/>over the last two decades. The following recent advances in Natural<br\/>Language Processing (NLP) technologies make this inquiry feasible: (1)<br\/>annotated data including bilingual treebanks and processors trained on<br\/>this data (parsers, PropBankers, etc.); (2) semantic post-processors<br\/>of parser output; (3) programs that automatically align bitexts; and<br\/>(4) bilingual tree to tree translation models.<br\/><br\/>Natural languages vary widely in the ordering of corresponding words<br\/>for equivalent expressions across linguistic boundaries and within a<br\/>single language. This research investigates ways to minimize the<br\/>variations within a single language using a type of semantic<br\/>representation (GLARF) that is derived automatically from syntactic<br\/>trees. Such semantic representation provides for: (1) a reduction in the<br\/>number of ways of representing the same underlying message, and (2)<br\/>a way to handle long distance dependencies (e.g. relative<br\/>clauses) as local phenomena. Therefore, there is no need to resort to<br\/>arbitrarily long sentence fragments or large trees for<br\/>training. Furthermore, since less data is needed, it<br\/>minimizes the sparse data problem.<br\/><br\/>In the training of this translation model, because of (1), the number<br\/>of mapping rules between the source tree and the target tree is<br\/>reduced. The translation model, then, is a tree transducer, with<br\/>``deep'' linguistically analyzed trees for both source and target<br\/>representations. In order to provide efficient computer algorithms<br\/>for such partial mappings, this research needs to focus on<br\/>(a) the training algorithm and the (b) the constraints over the<br\/>mapping rules in order to reduce the computational complexity.<br\/><br\/>This research is expected to yield several advantages: The core<br\/>architecture of this transducer using ``deep'' linguistic analyses<br\/>should yield more accurate results. The GLARF architecture allows<br\/>control over different granularity of automatically-obtained<br\/>linguistic analyses.<br\/><br\/>Broader Impact: The demand for machine translation spans from the<br\/>local government (e.g. police forces) to national government<br\/>(e.g. CIA) and the private sector. Given the growth of the Internet<br\/>outside the English speaking world, better machine translation is of<br\/>critical importance for the broader community. This work directly<br\/>affects the ability of English speakers to understand websites written<br\/>in Chinese and Japanese, two of the most widely used languages on the<br\/>Internet. The technique is generalizable to other language pairs and<br\/>can ultimately have even wider impact.","title":"Collaborative Research: Structure Alignment-based Machine Translation","awardID":"0534700","effectiveDate":"2006-07-01","expirationDate":"2010-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":["429881"],"PO":["565215"]},"119883":{"abstract":"ABSTRACT<br\/>0630455<br\/>Adriaan W. Van Der Hoek<br\/>University of California - Irvine<br\/><br\/>Today more than ever a need exists to encourage American students matriculating in computer science to<br\/>pursue doctorate degrees. According to the 2003-2004 Taulbee Survey published in May 2005, there was<br\/>an 8% decrease in the number of students enrolling in U.S. computer science doctoral programs and the<br\/>previous year there was a 5% decrease. In addition to this decrease in new enrollments, the Taulbee Survey<br\/>indicates that only a very small number of the underrepresented population are pursuing doctorates in<br\/>computer science (African-American 1.6%, Native American 0.2%, Hispanic 1.2%, with Asian leading at<br\/>11%). The survey furthermore indicates that 30% of the enrollment is white and over 50% of the enrollment is nonresident alien. Finally, the gender gap still remains and, in fact, has worsened in recent years. This trend is as equally visible in Software Engineering as it is in other subdomains of computer science. Combining this serious decline in applications from abroad with an ever-strong demand for computer science technologists trained with advanced degrees, it is critical that a racially and gender diverse group of bright undergraduate and M.S. students in the United States be encouraged to pursue doctoral degrees.<br\/>The inaugural Inspirations Ph.D. orientation will be held at the ACM SIGSOFT 2006\/FSE 14 conference,<br\/>which will take place November 5-11, 2006. This orientation aims to increase the number of students interested in pursuing doctorates in software engineering. Inspirations will be a three-day event intending to<br\/>give the student a taste of active research in the area of software engineering, consisting of interactive<br\/>sessions with established researchers and current Ph.D. students, audit of the doctoral symposium and<br\/>poster session, and attendance of the first day of the conference.<br\/>To help support our effort, we request NSF funding to provide travel grants for the participants, who otherwise will not have sufficient institutional funding to attend.","title":"Student Travel Support for ACM SIGSOFT 2006\/FSE 14 INSPIRATIONS: A Ph.D. Orientation for Undergraduate and M.S. Students","awardID":"0630455","effectiveDate":"2006-07-01","expirationDate":"2007-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"7352","name":"COMPUTING PROCESSES & ARTIFACT"}}],"PIcoPI":["551130","531513"],"PO":["564388"]},"116297":{"abstract":"Biomarkers measured in a minimally invasive and repeatable way can expedite the early diagnosis of disease, the indication of disease prognosis, and the discovery of new drug targets for therapy. Serum proteomic profiling for biomarker detection may reflect the abnormality or pathologic state of various diseases through the protein\/peptide peaks that are expressed differently between diseased and healthy individuals. Since the procedures are simple, inexpensive, and minimally invasive, serum proteomic methods readily lend themselves to screening-test development; their robustness and ease promise to translate into routine clinical practice. The objective of this project is to construct a high-throughput proteomic profiling analysis toolset, Proteomics Biomarker Information System (ProBIS), which can provide early biomarker detection and identification for clinical proteomics healthcare. Our main contributions are: (1) High Resolution Proteomic Profiling: different from traditional low resolution mass spectrometry analysis, we will use high resolution profile to analyze the low-molecular weight (LMW) end of the proteomic spectrum for more precise analysis; and (2) Integrated System for Biomarker Discovery and Identification: identification and sequencing of the underlying discriminatory proteins\/peptides will reveal the insights of biomarkers and characterize disease pathway. The results of this project will have an impact on the computer science community and an equal, if not greater, impact on the broad medical community that is in need of such a proteomic profiling data analysis tool. The experiments will be driven by a series of case studies, including ovarian cancer early relapse monitoring and prostate cancer diagnosis. The solutions for these case studies will have a direct impact on individual areas. Our source code and data will be available for general dissemination over the internet, and discoveries will be integrated into the classroom.","title":"Collaborative Research: Proteomics Biomarker Information System (ProBIS)","awardID":"0612214","effectiveDate":"2006-07-01","expirationDate":"2008-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7294","name":"SCIENCE & ENGINEERING INFORMAT"}}],"PIcoPI":[307822,"380538"],"PO":["565136"]},"109445":{"abstract":"Search engines and other information retrieval technologies are critical in the digital age. The goal of the proposed research is to investigate novel frameworks for analyzing and efficiently evaluating measures of retrieval performance, with an eye toward fostering and enabling research leading to better search engines and other retrieval technologies. <br\/><br\/>Two novel frameworks are proposed: (1) an information-theoretic framework within which one can quantifiably assess what various measures of retrieval performance are measuring and (2) a statistical framework within which one can efficiently estimate these measures of retrieval performance. The former provides a theoretical underpinning for retrieval evaluation and analysis; the latter provides a practical methodology for efficiently evaluating search engines on a large scale. Each will foster and enable research leading to better search engines and search technology. <br\/><br\/>The potential impacts of this project are many. From a research and infrastructure perspective, the project will yield published research results and freely available software artifacts (via http:\/\/www.ccs.neu.edu\/home\/jaa\/IIS-0534482\/), which will permit large-scale retrieval evaluation with minimal effort. Academics and other technologists will be able to efficiently test and evaluate new retrieval algorithms on novel data sets without incurring the high costs associated with the standard information retrieval evaluation paradigm. As such, one aspect of the project is an enabling technology that will foster the more rapid development of new search algorithms, vital in the current digital age. From an educational perspective, the project will train graduate and undergraduate students.","title":"Analysis and Evaluation of Measures of Information Retrieval Performance","awardID":"0534482","effectiveDate":"2006-07-01","expirationDate":"2010-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6855","name":"INFORMATION & KNOWLEDGE MANAGE"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":["535376"],"PO":["563751"]},"120192":{"abstract":"ABSTRACT<br\/><br\/>Proposal 0631821<br\/>Ttitle: \"Qualitative Reasoning Workshop Graduate Student Travel Support\"<br\/>PI: Christopher Bailey-Kellogg<br\/>Dartmouth College<br\/><br\/>This award provides funding to help defray travel costs of graduate student participating in the 20th International Conference on Qualitative Reasoning (QR-06) to be held July 10-12, 2006 at Dartmouth College. Qualitative Reasoning is an important core area in Artificial Intelligence and addresses issues in knowledge representation, cognitive modeling, qualitative simulation, dynamical systems, and task-level reasoning. Its concerns are at the interface of AI, Cognitive Science, Engineering and Science. The conference will hold a special session on graduate study in QR. It will be designed to enable students to receive feedback on their work from leading researchers in QR and to become integrated into the international QR community. The session will discuss the rewards and challenges of graduate study in interdisciplinary research areas such as Qualitative Reasoning. Topics to be addressed include selection of appropriate research problems, evaluation of results with respect to the standards of multiple fields, and publication in multiple venues. These activities will deepen the base of researchers by enabling graduate students to become knowledgeable in both qualitative reasoning and the rigors of interdisciplinary research.","title":"Qualitative Reasoning Workshop Graduate Student Travel Support","awardID":"0631821","effectiveDate":"2006-07-01","expirationDate":"2007-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6856","name":"ARTIFICIAL INTELL & COGNIT SCI"}}],"PIcoPI":["511584"],"PO":["565136"]},"111392":{"abstract":"While sensor applications promise profound scientific and economic impacts on our society, their success is nonetheless determined by whether the sensor networks can provide a steady stream of correct data. This need for continuous data provisioning over a significant time period, however, imposes great challenges to the underlying system. Specifically, wireless sensor networks are prone to a large array of hazards, such as frequent node failures, congestion, and sensing errors. These challenges are further complicated by the fact that sensor systems are usually seriously energy constrained.<br\/><br\/>This project has three main components: DADA, TARA, and MARA. DADA, a 2-Dimensional Adaptive Scheduling Framework, rapidly repairs network coverage and connectivity by cleverly waking up the redundant nodes that are needed for repairing holes created by the node failure. TARA, a Topology-Aware Resource Adaptation Framework, strives to increase the resource provisioning by bringing more sensor nodes online to accommodate those packets that contain valuable data, potentially regarding the source of the congestion. MARA, a Measurement Assurance and Robust Aggregation Framework, provides a set of data classification and cleansing tools that validate the data before they flow into the network. This project attempts to deliver the guarantee that sensor systems must gracefully recover themselves in the presence of network exceptions, in order to satisfy the application needs as well as lower the network management costs. In addition to technical papers that report the research results, this project will also produce a suite of software tools that will be made available to the community.","title":"CAREER: PROSE: Providing Robustness in Systems of Embedded Sensors","awardID":"0546072","effectiveDate":"2006-07-01","expirationDate":"2012-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"4090","name":"ADVANCED NET INFRA & RSCH"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["564747"],"PO":["565303"]},"116277":{"abstract":"Scientists in disciplines such as astronomy are facing increasing challenges in order to keep abreast of research fronts and maintain a good understanding of scientific data due to massive volumes of new scientific data and rapidly growing bodies of dynamic and highly specialized scientific knowledge. Information technology has the potential to augment scientists' abilities to deal with the complexity, dynamics, and scale of these challenges. This interdisciplinary project aims to advance information integration techniques and their applications to astronomy and support the analysis of astronomical data in an integral context of astronomical literature. The research focuses on the analysis and modeling of patterns to be identified from four data sources in association with the Sloan Digital Sky Survey (SDSS): the SDSS astronomical data, the search query log data from the SDSS SkyServer, an SDSS-specific bibliographic dataset drawn from the NASA Astrophysics Data System (ADS), and an interdisciplinary bibliographic dataset drawn from the Science Citation Index (SCI). The research advances the integration and innovative use of techniques for tracking thematic trends and detecting conceptual changes, integrated text mining and citation network analysis, and visualizing spatial-semantic structural and temporal patterns, and incorporating visual analytics tools for hypothesis generation and testing. The project are (1) to establish a conceptual and operational platform for coordinated access, visualization, and analysis of astronomical data and literature; (2) to develop scalable algorithms and tools for tracking the evolution and diffusion of knowledge and for facilitating hypothesis generation and testing; (3) to develop scalable algorithms and tools for incrementally visualizing large-scale astronomical data and scholarly publications; and (4) to evaluate the use of knowledge visualization and tracking in astronomy and a broader range of disciplines. The project will produce an interactive 3D sky browser, coordinated astronomical-bibliographic visualizations, visual explorers of scientific discoveries, and tools for hypothesis generation. The research has broader impacts in terms of enabling scientists to keep track of the advances of their own fields and facilitating the study and evaluation of the role of massive new data in scientific discovery and scholarly communication. These visualization tools and metrics will measure the rate of dissemination and acceptance of new astronomical discoveries made with SDSS, identify the highest impact discoveries, illuminate patterns of interaction and feedback among different research groups, and measure the scientific effectiveness of the NSF-supported SDSS and aid planning for future astronomical survey projects. The research has direct implications on education and outreach of science and technology in terms of improving public understanding of science and guiding new researchers through a field of study with a clear intellectual roadmap. For the astronomical community, the impact of these tools will include aiding new researchers in the field, particularly students, by identifying the most important papers and connecting these to the original SDSS data through the SkyExplorer interface. The network of SDSS-related citations will provide a roadmap to possible analysis of similar datasets from other surveys and at other wavelengths. The tools will be also valuable to the development of timely educational materials.","title":"SEI: Coordinated Visualization and Analysis of Sky Survey Data and Astronomical Literature","awardID":"0612129","effectiveDate":"2006-07-15","expirationDate":"2010-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7294","name":"SCIENCE & ENGINEERING INFORMAT"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":[307763,"554591"],"PO":["565136"]},"116288":{"abstract":"The current arsenal of antimicrobial or antibiotic drugs for treating bacterial infection is one of the most important public health tools available, but it is not an inexhaustible resource. The more haphazardly antimicrobial drugs are used, the more the targeted pathogens develop resistance. Once a pathogen develops resistance to all of the available drugs, treating an infected patient may become difficult or impossible. This project is a collaboration between computer scientists and health scientists aimed at developing data mining tools for discovering when and why antimicrobial resistance appears in nosocomial (hospital acquired) infections. Data mining tools are computer programs for automatically detecting important trends and patterns in very large databases that would be difficult for a human analyst to spot due to the amount and complexity of the data.<br\/><br\/>Nosocomial resistance is a particularly significant problem for two reasons. The first is the severity of the problem. Approximately 2 million of the 36 million Americans hospitalized each year will acquire a nosocomial infection, resulting in more than 90,000 deaths, many of them directly related to drug-resistant bugs. Estimates of the financial burden associated with resistance among nosocomial pathogens range from 4.5 billion dollars to 30 billion dollars annually. Unfortunately, because of constant exposure to antimicrobials, hospitals are ideal breeding grounds for \"super bugs\" resistant to most or all of the available treatments. Thus, if any progress can be made towards developing tools that can help health scientists to understand why and how problems occur, the payoff may be enormous. The second reason that studying nosocomial infection is important is that hospitals are a controlled, data rich environment where it may be relatively easy to learn the rules of effective stewardship of antimicrobial drugs.The data mining tools that the project will develop are targeted towards searching data from a hospital intensive care unit, microbiology laboratory, and pharmacy for patterns in drug-resistant microbial infections. The technical emphasis of the project is on the temporal or time-oriented nature of the data. The data mining tools the project will develop can be used to detect changes in the patterns of nosocomial infections over time, as well as to discover cause-effect relationships that might suggest to health scientists what antimicrobial use patterns seem to be linked with the development of drug-resistant microbes in the future.<br\/><br\/>Outreach to external health scientists is a vital part of the project, with the goal of disseminating the project's results to the larger community in order to have a positive impact on the problem of antimicrobial resistance. The computer software for pattern discovery that is developed by the project will be made publicly available for use by epidemiologists, and the project will provide support and tutorials on software usage. Another goal of the project is introducing scientific research to tomorrow's scientists and engineers. A significant fraction of the project's funds will be used to support undergraduate researchers who will play a significant role in the development and application of the software the project will develop.","title":"SEI: Data Mining for Multiple Antibiotic Resistance","awardID":"0612170","effectiveDate":"2006-07-15","expirationDate":"2010-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7294","name":"SCIENCE & ENGINEERING INFORMAT"}}],"PIcoPI":["530024","543599",307792],"PO":["565136"]},"119687":{"abstract":"This Small Grant for Exploratory Research (SBER) proposes new techniques and tools to effectively manage projects that are especially difficult to execute, especially those that are large, complex, dynamic and distributed such as GENI (Global Environment for Networking Innovations). GENI is a major initiative planned by the Computer and Information Science & Engineering (CISE) Division of the National Science Foundation. GENI is an experimental facility that has a highly ambitious goal: to invent and demonstrate a global communications network and related services that will be substantially superior to today's Internet. Thus, there is an urgent need to understand how a project of this nature can be managed effectively. The goals of the research proposed are twofold: 1) to explore the extent to which both traditional and novel project management tools and techniques can be applied effectively to projects like GENI, and 2) to understand how existing project management tools and techniques may be tailored or enhanced to fit the needs of a project like GENI.<br\/><br\/>Although the literature on project management has identified specific tools or techniques that may be suited to address a particular problem or challenge, there is relatively little knowledge on how to configure a set of these techniques for projects that face multiple challenges. In addition, there is relatively little knowledge on how to effectively tailor particular processes and techniques to meet the needs of specific projects. Thus, research that considers how to put together a portfolio of practices that will be effective for a particular project context is valuable. This is especially true in the case of GENI. The scale, scope and complexity of GENI are large, as the effort will ultimately affect many areas of computer science and engineering research in addition to networking and distributed systems. GENI will also impact the broader computer science community and will need to meet the high expectations of that community as well as of numerous other stakeholders. Given the magnitude and importance of GENI, understanding how a project of this nature can be managed effectively has the potential to positively impact the project's many stakeholders as well as broader society, the ultimate beneficiaries of the innovations it stimulates.","title":"GENI:Mechanisms for Managing Large, Complex, Dynamic and Distributed Projects","awardID":"0629093","effectiveDate":"2006-07-01","expirationDate":"2008-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"024F","name":"GENI CONCEPT\/DEVELOPMENT"}}],"PIcoPI":["405531"],"PO":["468236"]},"109545":{"abstract":"This project is developing theoretical and practical<br\/>foundations for communicative agents that overtly exhibit<br\/>self-awareness. Such agents are aware of what they know<br\/>and do not know, what they can and cannot do, and what<br\/>intentions and assumptions underlie their inferences<br\/>and actions, and they show \"presence of mind\" in dialogue<br\/>interactions, recalling past experiences and reasoning<br\/>about the ongoing interactions. The theoretical ideas<br\/>under development for this purpose center around theories<br\/>of autocognitive knowledge and inference (knowing what<br\/>one knows and does not know, and how one acquires<br\/>knowledge), a new approach to integrating uncertain<br\/>inference with logic (quasi-probability theory), and<br\/>a form of \"syntactically aware\" metainference that<br\/>facilitates reasoning about a system's own knowledge<br\/>and special capabilities. The project uses the EPILOG<br\/>inference engine as a basis for experimentation, while<br\/>broadening that engine's capabilities. The knowledge<br\/>representation (episodic logic) used by EPILOG nearly<br\/>matches the expressive capabilities of ordinary language<br\/>and is thus well-suited to the inferential and dialogue<br\/>goals of this project. The results will include<br\/>demonstrable theories of self-awareness in artificial<br\/>agents, new methods of general autocognitive, uncertain,<br\/>and syntactically aware inference, and an improved<br\/>EPILOG engine. The results will be disseminated in major<br\/>conferences and journals for AI, agent and dialogue<br\/>research, and the improved EPILOG engine will be<br\/>generally available. In the longer run, the work will<br\/>help pave the way for a new generation of more human-like<br\/>interactive AI agents, in such areas as software support,<br\/>advice, tutoring, games, etc.","title":"IIS: Knowledge Representation and Reasoning Mechanisms for Explicitly Self-Aware Communicative Agents","awardID":"0535105","effectiveDate":"2006-07-01","expirationDate":"2009-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6856","name":"ARTIFICIAL INTELL & COGNIT SCI"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7495","name":"ROBUST INTELLIGENCE"}}],"PIcoPI":["450916"],"PO":["565215"]},"111481":{"abstract":"One of the main reasons for the success of the Internet is its great flexibility , people can use it in many ways: read email, browse the web, download patches for their computers, or spread viruses and worms. This extreme flexibility is often in conflict with the need of network operators to understand and to some extent control how their networks are used. Information on network usage is based on some analysis of the observable network traffic. Extracting useful information is hard because of the variety of concurrent network uses, the high volume of traffic, and sometimes the efforts of users to hide their activities.<br\/><br\/>Many types of network usage information interest the network operator: the proportion of various applications, details about ongoing flooding attacks, worm epidemics and other malicious uses, as well as any information that can be used to filter out unwanted traffic. Unfortunately many types of important information cannot be extracted by current methods, and many of the proposed methods do not work with high-speed network links because the amount of traffic is too large. The proposed research will advance this field in three ways: by developing better methods of extracting useful information from network traffic, by developing solutions that work in real time under the ever tighter memory and processing constraints imposed by high speed links, and by developing information preserving data reduction techniques that allow network devices to produce traffic summaries that can be used to extract many types of information.<br\/><br\/>Educational Plan Overview<br\/><br\/>At the undergraduate level, class projects where students work in large groups will lead to a better understanding of the software engineering issues students are likely to face in their future jobs. At the graduate level, a new class about building fast networked devices will give a multi-area perspective covering concepts and techniques from operating systems, computer architecture, circuit design and algorithms.<br\/><br\/>Intellectual Merit<br\/><br\/>The proposed research will lead to fundamentally new ideas that result in new algorithms and new types of summaries for data. These ideas, algorithms and data structures are expected to have applicability beyond computer networking. The proposed research will also lead to a deeper understanding of how the Internet is used.<br\/><br\/>Broader Impact<br\/><br\/>Accurate information on network usage allows better-informed decisions by network operators and it enables systems that filter out many types of unwanted traffic. Success in the proposed research will contribute to a more reliable and more secure Internet.","title":"CAREER: Extracting Network Usage Information from Traffic","awardID":"0546585","effectiveDate":"2006-07-01","expirationDate":"2010-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"4090","name":"ADVANCED NET INFRA & RSCH"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7363","name":"RES IN NETWORKING TECH & SYS"}}],"PIcoPI":["410016"],"PO":["565090"]},"121183":{"abstract":"This award enabled support a joint EU-US workshop for collaboration between the US and the EU and European nations, seeking to identify new technical and strategic opportunities for cooperation. The meeting was hosted in Helsinki by the Finnish science foundation, TEKES. This continues a series of joint workshops and cooperative actions.<br\/><br\/>The joint US-EU-TEKES workshop was titled Long Term Challenges in High Confidence Composable Embedded Systems (HCCES). The United States and Europe share common concerns for renewing and protecting large infrastructures such as power grids, transportation systems, telecommunication infrastructure, health-care systems, and safety-critical manufacturing systems (e.g., chemical manufacturing). The ubiquitous use of information and communication technologies has pervaded other infrastructures, rendering them more intelligent, increasingly interconnected, complex, interdependent, and therefore more vulnerable. They are global and geographically distributed beyond any jurisdictional or governmental boundary. Today's critical national and large-scale industrial systems depend on HCCES characteristic of an aging infrastructure. They exhibit rudimentary control and coordination automation, are poorly secured, and operations often are driven to hazardous safety and security practice due to the cost of adoption for needed new (and vulnerable) technologies such as wireless networking.","title":"Long Term Challenges in High Confidence Composable (Evolutionary) Embedded Systems","awardID":"0636930","effectiveDate":"2006-07-15","expirationDate":"2008-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7354","name":"COMPUTER SYSTEMS"}}],"PIcoPI":["526900"],"PO":["561889"]},"116310":{"abstract":"This project will develop a system that integrates a web-based experiment workspace environment with a flexible scientific workflow automation system supporting rapid prototyping and user-transparent distributed computing. The experiment-workspace web interface will provide biologists an extensible virtual laboratory for defining computational protocols, executing \"experiments\" based on those protocols, visualizing data in the context of their provenance, and managing projects. The KEPLER scientific workflow system will be extended to automate the enactment of these experiments on available distributed resources and will record workflow and data provenance. Bioinformatics specialists and software engineers will develop new experiment templates using the system and will share these templates with experiment-workspace users. The system will support users who can make effective use of both interfaces and will facilitate productive collaboration between biologists, bioinformatics specialists, and software developers. <br\/> A prototype of this system will integrate and accelerate computational and experimental components of research projects employing a sequential chromatin immunoprecipitation followed by DNA microarray analysis (ChIP-chip) for identifying direct transcription factor targets. The IT and CS challenges in automating ChIP-chip workflows are typical of those plaguing complex, genome-scale analyses (e.g., dealing with multiple, alternate or related analysis modules simultaneously; managing thousands of workflow runs and resulting datasets; recording workflow, data and parameter dependencies; etc.) Implementing this system will require innovative approaches for managing nested collections of scientific data, combining functional programming and stream-processing methodologies for scientific workflows, and generalizing data-typing and integration approaches for supporting interoperability of workflow components developed by different organizations.<br\/><br\/>This proposal brings together investigators recognized for their expertise in scientific workflow modeling, design, and automation; scientific data management; ChIP-chip research and data analysis; and development of collaborative computational environments for scientific research, which together will enhance student engagement in the research.","title":"SEI(BIO)+II: A Collaborative Scientific Workflow Environment for Accelerating Genome-Scale Biological Research","awardID":"0612326","effectiveDate":"2006-07-01","expirationDate":"2010-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7602","name":"INFORMATION INTEGRATION"}}],"PIcoPI":["538708","486619",307863],"PO":["565136"]},"119523":{"abstract":"The 2006 University of Washington Seattle Innovation Symposium is the second in a series that was launched to build and maintain a vibrant network of researchers focused on advancing the body of knowledge on sustainable innovation and to create materials, such as case students, educational TV programs and published papers to share research with both the academic and business communities. The Symposium builds on the earlier initiative by continuing to engage previous participants and expanding to new researchers. The meeting employs a proven methodology, moving from small teamwork to larger teams and finally, into a plenary discussion. The expanded network of participants will consider original written and video-based case studies of innovation at a number of levels of complexity. Newly developed video case studies will consider not only individual expert innovators but also innovative teams in manufacturing and complex project enterprise innovation at the level of new aircraft. The results will engage young researchers and provide a variety of platforms to make results accessible.","title":"Seattle Innovation Symposium","awardID":"0627990","effectiveDate":"2006-07-01","expirationDate":"2007-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7484","name":"IIS SPECIAL PROJECTS"}}],"PIcoPI":["523483","467913","344922","530092",317006],"PO":["565136"]},"116256":{"abstract":"New technologies for collecting genotypic data from natural populations open the possibilities of investigating many fundamental biological phenomena, including behavior, mating systems, heritabilities of adaptive traits, kin selection, and dispersal patterns. Mining the emerging genotype data for ecological and evolutionary information is one of the most challenging problems in modern biology. Yet full utilization of the genotypic data is only possible if statistical and computational approaches keep pace with our ability to sample organisms and obtain their genotypes. The power and potential of genotypic information often rests in our ability to reconstruct genealogical relationships among individuals. Current computational methods for kinship (lower order pedigree) reconstruction have been developed mainly in the context of human populations. Natural populations pose unique computational and scientific challenges for genetic research: data collection is often limited to a demographic subgroup, such as juveniles; test data for the population under study is rarely available; the number of used genetic markers is relatively small, and typical family sizes can be orders of magnitude larger than in humans. Almost all currently available kinship reconstruction methods are statistical and thus are sensitive to noisy and incomplete data and require a priori knowledge about various parameter distributions, a difficult condition to satisfy in natural populations. The goal of the proposed research is to develop a robust computational method for reconstructing kinship relationships from microsatellite genetic data. The proposed method uses the fundamental genetic laws of inheritance to limit the genetic configurations of possible kinship relationships and powerful optimization techniques to find among those the most parsimonious. The resulting familial reconstruction method requires sampling a minimal number of generations, uses few assumptions about the structure of the data, and relies on little prior knowledge about the sampled population. The diverse tasks of this project include biological modeling, algorithm design and implementation, optimization integration, and experimental validation, many of which may be of use beyond the scope of genetics. The research team will leverage diverse expertise of its members in molecular genetics, mathematical modeling, experimental and theoretical computer sciences to develop accurate and effective methods for familial relationships reconstruction. The proposed interdisciplinary research will have broader impacts on diverse research communities. Improved methods of analysis and inference of kinship relationships open the door to asking new biological questions. The combined advantages of the proposed approach would be applicable to and useful not only for population biology but to various areas of the life sciences, including conservation and management of endangered species, animal behavior, evolutionary genetics, human genealogy, forensics, and epidemiology, any time familial relationships must be inferred from genetic data. The research and software resulting from the proposed project will be disseminated both in computational and biological communities and enhanced by cross-disciplinary training activities. The diverse scientific tasks that comprised the proposed research are suitable for a wide range of students in biology and computer science and will serve to train a new generation of interdisciplinary scientists.","title":"Collaborative Research: SEI: Computational Methods for Kinship Reconstruction","awardID":"0612044","effectiveDate":"2006-07-01","expirationDate":"2010-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7294","name":"SCIENCE & ENGINEERING INFORMAT"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7602","name":"INFORMATION INTEGRATION"}}],"PIcoPI":["475088","516991","533275"],"PO":["565136"]},"124671":{"abstract":"This CAREER proposal will investigate how companies use Internet-based digital infrastructure to transform the way they do business, with a focus on two related isseus: adoption and value creation of Internet-based e-business at the firm level. Instead of focusing on the direct relationship betweeen information technology and firm performance, we propose that actual usage may be the missing link in explaining the impact of technology on firm performance. The study will use quantitative and qualitative methods, including surveys, statistical analysis, and case studies. The longitudinal research will be conducted over five years and will focus on three industry sectors, manufacturing, retailing, and financial services. The study will draw managerial implications about the transformation process in which the Internet is used and value is created. The project will study the role of government regulation and competition on e-business transformation and will offer implications for public policies. The project will involve graduate and undergraduate students in the research process. New curriculum and courses on digital business will be developed for undergraduates and MBA students.","title":"CAREER: Digital Transformation of Enterprises -- A Process-Oriented Study of Internet Adoption, Usage, and Value Creation at the Firm Level","awardID":"0654400","effectiveDate":"2006-07-01","expirationDate":"2011-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6850","name":"DIGITAL SOCIETY&TECHNOLOGIES"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}}],"PIcoPI":[330863],"PO":["564456"]},"116311":{"abstract":"A number of scientific endeavors are generating data that can be modeled as graphs: high-throughput biological experiments on protein interactions, high-throughput screening of chemical compounds, social networks, ecological networks and food webs, database schemas and ontologies. Mining and analysis of these annotated and probabilistic graphs is crucial for advancing the state of scientific research, accurate modeling and analysis of existing systems, and engineering of new systems. The goal of this research project is to develop a set of scalable querying and mining tools for graph databases by integrating techniques from the fields of databases, bioinformatics, machine learning, and algorithms. New algorithms are being developed, and these are being examined for their quality and running time on real datasets. The first set of algorithms addresses subgraph and similarity querying in graph databases. The second set considers the mining of significant subgraphs or motifs. A novel significance model which transforms graphs into histograms of primitive components and examines the significance of motifs in the transformed domain is being developed. The third set of algorithms targets the discovery of well-connected clusters in large probabilistic graphs. The project integrates research and education by introducing the results of the research into undergraduate and graduate courses. Robust open-source tools based on the developed algorithms will be released for other researchers. These will be helpful in the study of the structure and organization of large networks that are becoming increasingly common.","title":"Scalable Querying and Mining of Graphs","awardID":"0612327","effectiveDate":"2006-07-15","expirationDate":"2010-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7602","name":"INFORMATION INTEGRATION"}}],"PIcoPI":["536697"],"PO":["565136"]},"116268":{"abstract":"Independent component analysis (ICA) has emerged as an attractive analysis tool for discovering hidden factors in observed data and has been successfully applied for data analysis in a wide array of applications such as biomedicine, communications, finance, and remote sensing. In a good number of these application domains, the data are typically complex valued. This is also the case in biomedical image analysis where ICA has been recognized as a promising tool for studying the brain function. Most biomedical image analysis techniques, however, use only the magnitude information and discard the phase, resulting in an unnecessary loss of information. Moreover, most brain imaging studies collect multiple data types where each existing modality for imaging the brain reports upon a limited domain and provides complementary information. Thus processing of imaging data in its native, complex form and by utilizing multiple modality images promises significant advances in our understanding of the brain function. We propose to develop a class of complex ICA algorithms, in particular for analysis of biomedical imaging data and demonstrate the power of joint data analysis as well as performing the analysis on the complete set of data, i.e., by utilizing both the magnitude and the phase information. We focus upon three image types, functional magnetic resonance imaging (fMRI), structural MRI (sMRI) and diffusion tensor imaging (DTI). These three imaging data provide complementary information about brain connectivity, and all can benefit from the incorporation of a complex-valued data processing approach.<br\/><br\/>The broad impact of the proposed work lies in its potential to substantially impact science and information technology as well as in its educational features. Study of human brain connectivity is a very challenging and rich problem. The ICA-based fusion approach as well as the use of imaging data in its native, complex form, we believe is the key for achieving significant advances in the field. Successful demonstration of our approach for medical imaging data will also benefit other areas of science and technology where data from multiple sources and\/or data in complex form need to be jointly analyzed for inferences. A significant broader impact of our proposal is to stimulate research at the interface between medical imaging and information processing by making the tools for the study of brain connectivity widely available through a toolbox and a medical imaging database.","title":"Collaborative Research: SEI: Independent Component Analysis of Complex-Valued Brain Imaging Data","awardID":"0612076","effectiveDate":"2006-07-15","expirationDate":"2011-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7294","name":"SCIENCE & ENGINEERING INFORMAT"}}],"PIcoPI":["486076"],"PO":["565136"]},"119007":{"abstract":"Proposal ID: IIS-0624725<br\/>PI: Garcia-Molina, Hector<br\/>Institution: Stanford University<br\/>Title: SGER: A Web Sociologist's Workbench<br\/><br\/><br\/>Abstract<br\/><br\/>This proposal is to design and build integrated software tools that will help social scientists analyze large time series snapshots of World Wide Web materials. The researchers' WebBase facility has been generating such topic specific Web collections since 2001. During the aftermath of the Katrina hurricane disaster pages were collected from a set of 400 Web sites every day. The site set was selected by personnel at the Library of Congress and the California Digital Library. The proposed tools will help social scientists track the development of topics across a time series such as the Katrina collections. The software architecture proposed is modular. Requirements, attributes, and associated functionalities were identified from discussions between the Computer Science researchers and faculty at Stanford's Communications Department where such social science applications and analyses are pursued. This project is inherently cross disciplinary, challenging and innovative. As such, it involves risk in pushing the boundaries of research capability. Successful outcome will broadly impact the social sciences by providing new means for conducting research over World Wide Web content. Data collected will be publicly available., as well as the new software tools coming out of this effort.","title":"SGER: A Web Sociologist's Workbench","awardID":"0624725","effectiveDate":"2006-07-01","expirationDate":"2007-12-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6857","name":"DIGITAL LIBRARIES AND ARCHIVES"}}],"PIcoPI":["447448"],"PO":["433760"]},"121031":{"abstract":"The science of Intelligence and Security Informatics (ISI) focuses on the development and use of advanced information technologies, including methodologies, models and algorithms, infrastructure, systems, and tools for national\/international and homeland security related applications through an integrated technological, organizational, and policy-based approach. ISI also encompasses the areas of terrorism research, biosurveillance, and intelligence analysis as well as security-related public policy. The ISI conferences have been instituted to provide an intellectual forum for discussion among disparate and often separated communities: academic researchers in information technologies, computer science, public policy, and the social sciences; local, state, and federal law enforcement and intelligence experts; epidemiologists and other public health community members; and information technology industry consultants and practitioners.<br\/><br\/>This grant will support the 2006 International Conference on Intelligence and Security Informatics (ISI-2006) May 23-24, 2006, in order to bring together noted informatics, computer science, and policy researchers as well as members of the public health, law enforcement and security communities to engage in dialogue and explore potential avenues of collaboration. ISI-2006 will be co-located with the 7th Annual National Conference on Digital Government Research and will be cosponsored by the US intelligence agencies and Dept. of Homeland Security. This should further broaden the possibilities for participation in this still-emerging scientific discipline. Additional events and meetings may be held both before and after the conference to facilitate planning and community dialogue. The meeting will solicit high-quality research papers of relevance to intelligence and security research, which will be peer reviewed by both researchers and practitioners for presentation as well as publication. The expectation is that active intelligence and security informatics research will improve knowledge discovery and dissemination, and enhance information sharing and collaboration across law enforcement communities.","title":"International Conference on Intelligence and Security Informatics (ISI 2006)","awardID":"0636210","effectiveDate":"2006-07-15","expirationDate":"2009-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"T471","name":"CIA-KDD WORKING GROUP"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0501","name":"Division of COMPUTER & COMMUNICATION FOUND","abbr":"CCF"},"pgm":{"id":"T832","name":"CIA-ITIC KDD WORK GROUP"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"1706","name":"DIGITAL GOVERNMENT"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"T474","name":"HOMELAND SEC-INTNL CONF ON INT"}}],"PIcoPI":["548216","387279"],"PO":["565136"]},"112440":{"abstract":"Abstract<br\/><br\/>Program: NSF 04-588 CISE Computing Research Infrastructure<br\/>Title: CRI: Acquisition of Research Instrumentation Infrastructure for Next-Generation Broadband Communication Systems <br\/><br\/>Lead Proposal: CNS-0551686<br\/>PI: Henderson, Thomas R.<br\/>Institution: University of Washington<br\/><br\/>Proposal: : CNS-0551378 <br\/>PI : Riley, George F.<br\/>Institution: Georgia Tech Research Corporation - GA Institute of Technology <br\/><br\/>Proposal: : CNS-0551706<br\/>PI : Floyd, Sally<br\/>Institution: International Computer Science Institute<br\/><br\/> <br\/>Investigators at the University of Washington, the Georgia Institute of Technology and the International Computer Science Institute will re-design, enhance and maintain the Network Simulator to address research and education challenges for the next generation of data networks. Improvements will include a new simulator architecture, new models for wireless networks, provide for software encapsulation, and integration of the tools with virtual network testbeds. The changes will enhance scalability, extensibility, and new application program interfaces that open the simulator to open source networking software. Emulation capability will be improved to allow integration with testbeds.Wireless modules will be rewritten to track advances in wireless networking. Educational scripts will be facilitated in the enhanced version. The Network Simulator is heavily used in research; these improvements will allow it to continue to be a leading resource for","title":"CRI: Collaborative Proposal: Developing the Next-Generation Open-Source Network Simulator","awardID":"0551378","effectiveDate":"2006-07-01","expirationDate":"2011-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"7359","name":"COMPUTING RES INFRASTRUCTURE"}}],"PIcoPI":["434457"],"PO":["564778"]},"121064":{"abstract":"The workshops supported by NSF as part of the Robotics: Science and Systems conference will focus on human-oriented robotics including rehabilitation, exoskeleton and prosthetics, human-robot interaction, robots manipulating in human environments, and socially assistive robotics. The breadth of human-oriented robotics is large, and is becoming more important for the viable transfer of robot technology to real human applications as well as understanding the science of the interaction between the two. The workshops will bring together a large number of researchers in these related fields. The NSF support will enable students to attend these workshops, learning issues in these growing fields and training them to be researchers. Robotics: Science and Systems is a new conference that brings together researchers working on algorithmic or mathematical foundations of robotics, robotics applications, and analysis of robotic systems.","title":"Support for Graduate Student Participation in Various Workshops at Robotics: Science and Systems 2006","awardID":"0636394","effectiveDate":"2006-07-15","expirationDate":"2007-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6840","name":"ROBOTICS"}}],"PIcoPI":["526896","553516"],"PO":["335186"]},"116631":{"abstract":"Markets for interchangeable components exert pressure on manufacturers to improve their products. This is especially true if the market comes with fast dissemination of information about the quality of the components. But existing markets for software components lack quality assurance mechanisms. In this exploratory project, the PIs will study the relationship between software markets, quality assurance, and design. The PIs conjecture that if a market for software components is equipped with a uniformly enforced quality control mechanism, it will force software producers to continuously overhaul their product designs. To test this hypothesis, the PIs will conduct experiments with small controllable component markets, in which products come with explicit software contracts and the underlying software platforms monitor these contracts and publicly report violations. Producers may choose to react to these reports with technical contributions (test cases, improved contracts, etc). In this context, the PIs will validate their conjecture by conducting code inspections and interviews with producers. The outcomes of this exploratory investigation will help others construct similar markets and mechanisms; some may even directly benefit from the software developed as part of the project.<br\/><br\/>Broader Impacts: This project has the potential to change the way software components are produced and the way software reuse is taught. If the PIs' conjecture about markets is confirmed, it will provide arguments to the promoters of both public markets and markets that are internal to organizations. The very creation of a market with quality assurance mechanisms is bound to make the production of software more efficient, and to improve the quality of the components that are traded on the market. Independently of the outcome of the experiments, the idea of using a market for courses may help instructors deal with the teaching of software reuse in classes. They can use the PIs' experience and possibly their software as well to create course-focused markets; and they can use these markets to demonstrate the value of software reuse.","title":"SoD-HCER: Collaborative Research: Using Market Forces to Improve the Design of Software","awardID":"0613805","effectiveDate":"2006-07-15","expirationDate":"2008-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7372","name":"ITR-SCIENCE OF DESIGN"}}],"PIcoPI":["475166"],"PO":["565227"]},"116642":{"abstract":"A significant amount of the software written today interacts with naturally occurring (sensor) data such as text, speech, images and video, streams of financial data, and biological sequences, and needs to reason with respect to concepts that are complex and often difficult to define explicitly in terms of the raw data observed (e.g., determining the gender of a person in an image, determining the topic of an article, determining whether more than three people are currently meeting in someone's office, scheduling a computation in a grid in a way that adapts to a multitude of properties of the resources and links. Applications that require such abilities are expected to rapidly grow even more important in future years. While conventional programming languages rely on a programmer to explicitly define all the concepts and relations involved, programming with naturally occurring data that is highly variable and ambiguous at the measurement level necessitates a programming model in which some of the variables, concepts and relations may not be known at programming time, may be defined only in a data driven way, or may not be unambiguously defined without relying on other concepts acquired this way. It must be possible to reason with respect to variables that do not depend on tight assumptions on the environment in which the measurements are taken, and needs to center around a semantic level interaction model made possible via components that are data-dependent and support abstractions over real-world observations. Today's programming paradigms, and the corresponding programming languages, are not conducive to that goal. Consequently, despite two decades of progress in machine learning, and a clear need for systems with significant trainable (data dependent) components, few systems today incorporate significant machine learning components, and even fewer use more than a single classifier. In this project on Learning Based Programming (LBP), the PI will explore a novel software engineering paradigm that allows a programmer seamless incorporation of trainable variables into the program and, consequently, the ability to reason using high-level concepts without the need to explicitly define them in terms of all the variables they might depend on, or the functional dependencies among them; these may be determined in a data-driven way, via learning operators whose details are abstracted away from the programmer. In this work, the PI will flesh out the details of the LBP paradigm he envisages, and implement an LBP language and study it via the development of applications in two areas: ubiquitous computing and natural language processing.<br\/><br\/>Broader Impacts: This project will lead to cross-fertilization and mutual reinvigoration of the software engineering and machine learning fields. Enabling the development of computer systems that interact and cope with the variability of naturally occurring (sensor) data will require fundamental advances in compilation and software engineering issues. Conversely, availability of the LBP vehicle will motivate researchers in machine learning to explore the process of making inferences that rely on a large number of mutually dependent learners as a means to providing programmers with better abstractions so that they can more effectively tackle a broad range of increasingly complex applications involving such data.","title":"SoD-HCER: Learning Based Programming","awardID":"0613885","effectiveDate":"2006-07-15","expirationDate":"2010-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7367","name":"HUMAN-CENTERED COMPUTING"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7372","name":"ITR-SCIENCE OF DESIGN"}}],"PIcoPI":["318715"],"PO":["565227"]},"116258":{"abstract":"There are two barriers to the automatic data collection and analysis from video microscopy. The algorithms grow more sophisticated and the current implementations fall short of real-time analysis, which requires a speedup of three or four orders of magnitude over current implementations. The traditional design methodology is inherently limited in the quality of systems it can produce, restricting the capabilities of both the engineers and the application experts. This projects co-optimizes both algorithms and custom system architectures in a collaborative space, where changes in implementation can be considered at the same time as changes in the algorithms, leading to enhanced performance. The system uses hierarchical dependency graphs as a common language to establish the bi-directional relationship between and algorithm and an implementation. The interdisciplinary team from design, biomedical image analysis, computer architecture and medicine, is developing a prototype system for in vivo leukocyte detection and tracking and establishment of a collaborative space optimization design. This research will facilitate a new approach and design infrastructure for designing systems that will have dramatic improvements in system efficiency and speeds. The work will be publicly released and lead not only to training of students but a new collaborative approach to design of algorithms and implementations.","title":"SEI: Hierarchical Dependency Graphs for Col-Space Design with Application to Leukocyte Detection and Tracking","awardID":"0612049","effectiveDate":"2006-07-15","expirationDate":"2010-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7294","name":"SCIENCE & ENGINEERING INFORMAT"}},{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"7364","name":"INFO INTEGRATION & INFORMATICS"}}],"PIcoPI":["473946","489873","527785"],"PO":["550329"]},"120152":{"abstract":"The Directorate for Computer and Information Science and Engineering (CISE) and the CISE research community are planning an initiative called Global Environment for Networking Innovations or GENI to explore new networking capabilities that will advance science and stimulate innovation and economic growth. The GENI Initiative responds to an urgent and important challenge of the 21st Century to advance significantly the capabilities provided by networking and distributed system architectures.<br\/>To have significant impact, innovative research and design ideas must be implemented, deployed, and tested in realistic environments involving significant numbers of users and hosts. The initiative includes the deployment of a state-of-the-art, global experimental GENI Facility that will permit exploration and evaluation under realistic conditions. The GENI Facility will permit a range of researchers, including network engineers, policy analysts, protocol designers, system architects, and economic modelers to contribute to and study innovative new capabilities for the global network of the future. Assuming the concept proves to be as promising as currently anticipated, GENI construction will be considered for funding from NSF's MREFC account.<br\/><br\/>In support of making the case for GENI as a MREFC project, the PIs propose to undertake a set of tasks to advance the GENI project definition from the Conceptual Design, through the MREFC Readiness Stage, to Preliminary Design. This will involve addressing a set of design issues; taking the definition of various components of the facility to the next level of specificity; creating a detailed work breakdown structure (WBS), bottom up budget, schedule, contingency, and critical path analysis for each component and the facility as a whole; and taking the project management definition for construction and operation to the next level of specificity with due considerations to special requirements of GENI.","title":"Collaborative Proposal: Facility for Experimental Network Architecture Research","awardID":"0631587","effectiveDate":"2006-07-01","expirationDate":"2008-06-30","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0505","name":"Division of COMPUTER AND NETWORK SYSTEMS","abbr":"CNS"},"pgm":{"id":"024F","name":"GENI CONCEPT\/DEVELOPMENT"}}],"PIcoPI":["463055"],"PO":["495796"]},"121021":{"abstract":"SGER: Human-MAV Team Processes for Effective Hurricane Response<br\/><br\/><br\/>This project will enable scientists to immediately respond to four hurricanes in 2006 with rotary-wing micro air vehicles (rMAVs), or miniature helicopters carrying cameras. It is expected that the rMAV team will be able to directly contribute to the response effort, as well as conduct research. Miniature backpackable helicopters are transformational to search and rescue, but little is known about how responders can be trained to use them effectively under stressful conditions. Ephemeral data on rMAV and team processes and performance during the actual disaster response will be collected and archived for use by the scientific, especially human-robot interaction, and emergency response communities. The data will be used to validate a model of team processes for effective and safe flying of rMAVs under emergency response conditions generated during our previous work at Hurricanes Katrina and Wilma. This project will also create a quick-time cognitive work analysis field method which will allow team roles and strategies to be identified and modified after each shift. While this quick-time method is unlikely to be optimal, it is expected to foster immediate improvements- which could mean life and death for disaster victims. In addition, the project will have significant broader impacts spanning the emergency response, civil and mechanical, insurance, and robotics communities.","title":"SGER: Human-MAV Team Processes for Effective Hurricane Response","awardID":"0636173","effectiveDate":"2006-07-01","expirationDate":"2007-12-31","fundingAgent":[{"dir":{"id":"05","name":"Directorate for DIRECT FOR COMPUTER & INFO SCIE & ENGINR","abbr":"CSE"},"div":{"id":"0502","name":"Division of INFORMATION & INTELLIGENT SYST","abbr":"IIS"},"pgm":{"id":"6840","name":"ROBOTICS"}}],"PIcoPI":[321538,"372103","565226"],"PO":["335186"]}}